{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PyTorch Module: Comprehensive Guide**\n",
    "\n",
    "**PyTorch** is an open-source deep learning library developed by Facebook's AI Research lab (FAIR). It provides powerful tools for building neural networks and performing numerical computations with ease. PyTorch is widely known for its dynamic computation graph, which allows for greater flexibility during model development and training.\n",
    "\n",
    "This guide will cover all major concepts and functionalities of PyTorch, from basic to advanced, to give you a thorough understanding of this popular deep learning framework.\n",
    "\n",
    "---\n",
    "\n",
    "## **Table of Contents**\n",
    "\n",
    "1. [Introduction to PyTorch](#introduction-to-pytorch)\n",
    "2. [Installation](#installation)\n",
    "3. [Tensors in PyTorch](#tensors-in-pytorch)\n",
    "4. [PyTorch Autograd (Automatic Differentiation)](#pytorch-autograd-automatic-differentiation)\n",
    "5. [Building Neural Networks](#building-neural-networks)\n",
    "6. [Training Neural Networks](#training-neural-networks)\n",
    "7. [Optimizers in PyTorch](#optimizers-in-pytorch)\n",
    "8. [Working with Datasets and DataLoaders](#working-with-datasets-and-dataloaders)\n",
    "9. [Advanced Concepts](#advanced-concepts)\n",
    "   - Transfer Learning\n",
    "   - Custom Layers and Modules\n",
    "   - Saving and Loading Models\n",
    "10. [Applications of PyTorch](#applications-of-pytorch)\n",
    "11. [Conclusion](#conclusion)\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Introduction to PyTorch**\n",
    "\n",
    "**PyTorch** is a flexible deep learning framework that makes it easier to build and train complex neural networks, especially for research and production applications. It is widely used for tasks like:\n",
    "\n",
    "- **Computer Vision** (image classification, segmentation)\n",
    "- **Natural Language Processing** (text classification, translation)\n",
    "- **Reinforcement Learning** (game playing, robotics)\n",
    "\n",
    "Key features of PyTorch:\n",
    "\n",
    "- **Dynamic Computation Graph**: Unlike TensorFlow, PyTorch builds computation graphs on the fly (eager execution). This allows for flexibility in designing models and debugging.\n",
    "- **GPU Support**: PyTorch integrates seamlessly with GPUs, significantly speeding up training and inference.\n",
    "- **Large Ecosystem**: PyTorch has numerous libraries, such as **TorchVision** for computer vision, **TorchText** for NLP, and **TorchAudio** for audio processing.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Installation**\n",
    "\n",
    "To install PyTorch, you can use `pip` or `conda`. You should check the [official PyTorch website](https://pytorch.org/get-started/locally/) for the correct installation command based on your OS and CUDA version.\n",
    "\n",
    "### **Install using pip:**\n",
    "\n",
    "```bash\n",
    "pip install torch torchvision torchaudio\n",
    "```\n",
    "\n",
    "### **Install using conda (recommended for GPU support):**\n",
    "\n",
    "```bash\n",
    "conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Tensors in PyTorch**\n",
    "\n",
    "A **Tensor** is a multi-dimensional array, similar to NumPy arrays, but with the added benefit of being able to run on GPUs.\n",
    "\n",
    "### **Creating Tensors**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "# Create a tensor from a list\n",
    "x = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Create a tensor with zeros\n",
    "y = torch.zeros(3, 3)\n",
    "\n",
    "# Create a tensor with ones\n",
    "z = torch.ones(2, 2)\n",
    "\n",
    "# Create a random tensor\n",
    "random_tensor = torch.rand(3, 3)\n",
    "```\n",
    "\n",
    "### **Tensor Operations**\n",
    "\n",
    "Tensors support various mathematical operations, including element-wise operations.\n",
    "\n",
    "```python\n",
    "# Element-wise addition\n",
    "sum_tensor = x + y\n",
    "\n",
    "# Matrix multiplication\n",
    "dot_product = torch.matmul(x, y)\n",
    "\n",
    "# Reshaping tensor\n",
    "reshaped_tensor = x.view(3, 1)\n",
    "```\n",
    "\n",
    "### **CUDA Tensors (GPU support)**\n",
    "\n",
    "```python\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move tensor to GPU\n",
    "x_gpu = x.to(device)\n",
    "\n",
    "# Perform operations on GPU\n",
    "y_gpu = torch.ones_like(x_gpu)\n",
    "result = x_gpu + y_gpu\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **4. PyTorch Autograd (Automatic Differentiation)**\n",
    "\n",
    "One of PyTorchâ€™s most powerful features is its ability to automatically compute gradients during backpropagation using the **Autograd** module. This is crucial for training neural networks using gradient-based optimization algorithms.\n",
    "\n",
    "### **Autograd in Action**\n",
    "\n",
    "```python\n",
    "# Tensors that track gradients\n",
    "x = torch.randn(3, 3, requires_grad=True)\n",
    "\n",
    "# Define a simple operation\n",
    "y = x + 2\n",
    "\n",
    "# Compute the gradients\n",
    "y.backward(torch.ones_like(x))\n",
    "\n",
    "# Print the gradients\n",
    "print(x.grad)\n",
    "```\n",
    "\n",
    "- **requires_grad=True** indicates that PyTorch should track operations on the tensor.\n",
    "- **backward()** computes the gradients for the tensor.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Building Neural Networks**\n",
    "\n",
    "PyTorch makes it easy to define neural networks using the `torch.nn` module. It provides pre-built layers (e.g., linear layers, convolutional layers) and functions to define forward and backward passes.\n",
    "\n",
    "### **Creating a Simple Feedforward Neural Network**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a simple feedforward neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 3)  # Fully connected layer\n",
    "        self.fc2 = nn.Linear(3, 1)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))  # Apply ReLU activation\n",
    "        x = self.fc2(x)  # Output layer\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleNN()\n",
    "```\n",
    "\n",
    "- **`nn.Module`**: All models in PyTorch should inherit from `nn.Module`.\n",
    "- **`forward()`**: Defines how data flows through the network.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Training Neural Networks**\n",
    "\n",
    "### **Loss Functions**\n",
    "\n",
    "PyTorch provides a variety of loss functions, including Mean Squared Error (MSE) for regression tasks and Cross Entropy for classification.\n",
    "\n",
    "```python\n",
    "criterion = nn.MSELoss()  # For regression tasks\n",
    "\n",
    "# Compute the loss\n",
    "loss = criterion(output, target)\n",
    "```\n",
    "\n",
    "### **Optimizers**\n",
    "\n",
    "PyTorch provides several optimization algorithms, including **SGD** (Stochastic Gradient Descent), **Adam**, and **RMSprop**.\n",
    "\n",
    "```python\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Zero the gradients, perform the backward pass, and update the weights\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "```\n",
    "\n",
    "### **Training Loop Example**\n",
    "\n",
    "```python\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    model.train()  # Set model to training mode\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(inputs)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(output, target)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Optimize the weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print progress\n",
    "    print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Optimizers in PyTorch**\n",
    "\n",
    "PyTorch supports many optimizers for training deep learning models. The most common ones are:\n",
    "\n",
    "- **SGD**: Stochastic Gradient Descent\n",
    "- **Adam**: Adaptive Moment Estimation (often used for deep learning)\n",
    "- **RMSprop**: Root Mean Square Propagation (suitable for recurrent networks)\n",
    "\n",
    "### **Example of Adam Optimizer:**\n",
    "\n",
    "```python\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "```\n",
    "\n",
    "- The Adam optimizer is widely used in practice due to its adaptive learning rate mechanism.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Working with Datasets and DataLoaders**\n",
    "\n",
    "### **Custom Dataset Class**\n",
    "\n",
    "To work with datasets, PyTorch provides the `Dataset` and `DataLoader` classes. You can create a custom dataset by subclassing the `Dataset` class and defining how to load and access the data.\n",
    "\n",
    "```python\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "# Create dataset and dataloaders\n",
    "dataset = MyDataset(data, targets)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "```\n",
    "\n",
    "- **`DataLoader`**: Helps to load the data in batches and shuffle it.\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Advanced Concepts**\n",
    "\n",
    "### **Transfer Learning**\n",
    "\n",
    "Transfer learning involves using a pre-trained model and fine-tuning it on a new dataset. PyTorch makes this easy using pre-trained models from `torchvision.models`.\n",
    "\n",
    "```python\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load a pre-trained ResNet model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze all layers except the final one\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the final layer\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "```\n",
    "\n",
    "### **Custom Layers and Modules**\n",
    "\n",
    "You can define custom layers by subclassing `nn.Module` and implementing the `forward()` method.\n",
    "\n",
    "```python\n",
    "class MyLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.fc = nn.Linear(3, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.relu(self.fc(x))\n",
    "```\n",
    "\n",
    "### **Saving and Loading Models**\n",
    "\n",
    "You can save and load your trained models for later use:\n",
    "\n",
    "```python\n",
    "# Save model\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# Load model\n",
    "model = SimpleNN()\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "model.eval()  # Set model to evaluation mode\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **10. Applications of PyTorch**\n",
    "\n",
    "- **Computer Vision**: Object detection, image classification, semantic segmentation using models like CNNs.\n",
    "- **Natural Language Processing**: Text generation, sentiment analysis, machine translation using models like RNNs, LSTMs, and transformers.\n",
    "- **Reinforcement Learning**: Training intelligent agents in environments using RL algorithms like DQN, A3C, etc.\n",
    "- **Generative Models**: GANs (Generative Adversarial Networks), VAEs (Variational Autoencoders).\n",
    "\n",
    "---\n",
    "\n",
    "## **11. Conclusion**\n",
    "\n",
    "PyTorch is a versatile, user-friendly, and powerful framework for deep learning. Its flexible nature, dynamic computation graph, and efficient GPU support make it ideal for both research and production applications. Whether youâ€™re working with simple neural networks or complex models, PyTorch provides a straightforward approach to model creation, training, and optimization. With its growing ecosystem of libraries and tools, PyTorch continues to be one of the leading choices for building machine learning models in Python.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
