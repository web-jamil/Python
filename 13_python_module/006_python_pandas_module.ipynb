{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Python `pandas` Module: Overview, Concepts, and Theory**\n",
    "\n",
    "The `pandas` module is a powerful, fast, and flexible open-source data analysis and manipulation library for Python. It is widely used in data science, machine learning, financial analysis, and other areas where large datasets need to be analyzed and manipulated. At its core, `pandas` provides two main data structures — **Series** and **DataFrame** — which allow for efficient and intuitive manipulation of data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Concepts of the `pandas` Module:**\n",
    "\n",
    "1. **Data Structures:**\n",
    "\n",
    "   - The two primary data structures in `pandas` are **Series** and **DataFrame**.\n",
    "   - A **Series** is a one-dimensional array-like object that can hold any data type (integers, strings, floats, etc.).\n",
    "   - A **DataFrame** is a two-dimensional table (similar to a spreadsheet or SQL table) where each column is a Series, and all columns share the same index.\n",
    "\n",
    "2. **Data Manipulation:**\n",
    "\n",
    "   - `pandas` offers robust functionality for data manipulation, such as filtering, selecting, and grouping data. It supports operations like merging, reshaping, pivoting, and aggregating data.\n",
    "\n",
    "3. **Missing Data Handling:**\n",
    "\n",
    "   - `pandas` provides extensive tools for handling missing data (e.g., `NaN` values). It allows for easy imputation, removal, and identification of missing values.\n",
    "\n",
    "4. **Data Cleaning:**\n",
    "\n",
    "   - You can clean data by removing duplicates, renaming columns, changing data types, handling missing values, and normalizing or transforming data to fit specific needs.\n",
    "\n",
    "5. **Time Series Analysis:**\n",
    "\n",
    "   - `pandas` has specialized functions for working with time series data, including date parsing, resampling, shifting, and time-based indexing.\n",
    "\n",
    "6. **Data Import and Export:**\n",
    "   - `pandas` can read and write data from a variety of file formats, including CSV, Excel, SQL databases, JSON, Parquet, and many others.\n",
    "\n",
    "---\n",
    "\n",
    "### **Main Data Structures in `pandas`:**\n",
    "\n",
    "#### 1. **Series:**\n",
    "\n",
    "- A `Series` is essentially a one-dimensional labeled array capable of holding any data type. It is similar to a list or an array but comes with added functionality, such as indexing and vectorized operations.\n",
    "\n",
    "- **Creating a Series:**\n",
    "\n",
    "  ```python\n",
    "  import pandas as pd\n",
    "  data = [1, 2, 3, 4, 5]\n",
    "  s = pd.Series(data)\n",
    "  print(s)\n",
    "  ```\n",
    "\n",
    "  Output:\n",
    "\n",
    "  ```\n",
    "  0    1\n",
    "  1    2\n",
    "  2    3\n",
    "  3    4\n",
    "  4    5\n",
    "  dtype: int64\n",
    "  ```\n",
    "\n",
    "- **Accessing Data in Series:**\n",
    "\n",
    "  ```python\n",
    "  # Access by index\n",
    "  print(s[0])  # Output: 1\n",
    "\n",
    "  # Access by label (if the Series has labels)\n",
    "  s = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "  print(s['a'])  # Output: 1\n",
    "  ```\n",
    "\n",
    "#### 2. **DataFrame:**\n",
    "\n",
    "- A `DataFrame` is a two-dimensional labeled data structure with columns of potentially different types. It can be thought of as a table or a spreadsheet with rows and columns.\n",
    "\n",
    "- **Creating a DataFrame:**\n",
    "\n",
    "  ```python\n",
    "  data = {'name': ['Alice', 'Bob', 'Charlie'],\n",
    "          'age': [25, 30, 35],\n",
    "          'city': ['New York', 'San Francisco', 'Los Angeles']}\n",
    "  df = pd.DataFrame(data)\n",
    "  print(df)\n",
    "  ```\n",
    "\n",
    "  Output:\n",
    "\n",
    "  ```\n",
    "      name  age           city\n",
    "  0    Alice   25       New York\n",
    "  1      Bob   30  San Francisco\n",
    "  2  Charlie   35    Los Angeles\n",
    "  ```\n",
    "\n",
    "- **Accessing Data in DataFrame:**\n",
    "\n",
    "  ```python\n",
    "  # Accessing columns\n",
    "  print(df['name'])  # Accessing a single column\n",
    "\n",
    "  # Accessing rows by index\n",
    "  print(df.iloc[1])  # Access the second row (index starts at 0)\n",
    "\n",
    "  # Accessing data by label (rows and columns)\n",
    "  print(df.loc[1, 'age'])  # Access the 'age' column for the second row\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Data Manipulation with `pandas`:**\n",
    "\n",
    "1. **Selecting Data:**\n",
    "\n",
    "   - You can select rows and columns using labels or indices.\n",
    "\n",
    "   - **Selecting columns:**\n",
    "\n",
    "     ```python\n",
    "     # Single column\n",
    "     df['name']\n",
    "\n",
    "     # Multiple columns\n",
    "     df[['name', 'age']]\n",
    "     ```\n",
    "\n",
    "   - **Selecting rows:**\n",
    "\n",
    "     ```python\n",
    "     # By index position (using iloc)\n",
    "     df.iloc[0]  # First row\n",
    "\n",
    "     # By index label (using loc)\n",
    "     df.loc[0]  # First row\n",
    "     ```\n",
    "\n",
    "2. **Filtering Data:**\n",
    "\n",
    "   - Filtering can be done using boolean indexing.\n",
    "\n",
    "   ```python\n",
    "   # Filter rows where age > 30\n",
    "   df[df['age'] > 30]\n",
    "   ```\n",
    "\n",
    "3. **Sorting Data:**\n",
    "\n",
    "   - You can sort data by one or more columns.\n",
    "\n",
    "   ```python\n",
    "   # Sort by age\n",
    "   df.sort_values(by='age', ascending=False)\n",
    "   ```\n",
    "\n",
    "4. **Merging and Joining:**\n",
    "\n",
    "   - You can combine multiple data frames using functions like `merge()`, `join()`, and `concat()`.\n",
    "\n",
    "   ```python\n",
    "   df1 = pd.DataFrame({'key': ['A', 'B', 'C'], 'value': [1, 2, 3]})\n",
    "   df2 = pd.DataFrame({'key': ['A', 'B', 'D'], 'value': [4, 5, 6]})\n",
    "   merged = pd.merge(df1, df2, on='key', how='inner')\n",
    "   ```\n",
    "\n",
    "5. **Grouping Data:**\n",
    "\n",
    "   - The `groupby()` method is used to group data and perform aggregations, such as sum, mean, or count.\n",
    "\n",
    "   ```python\n",
    "   df.groupby('city')['age'].mean()  # Get the average age by city\n",
    "   ```\n",
    "\n",
    "6. **Applying Functions:**\n",
    "\n",
    "   - You can apply functions across columns or rows using `apply()`.\n",
    "\n",
    "   ```python\n",
    "   # Apply a function to each column\n",
    "   df['age'] = df['age'].apply(lambda x: x + 1)\n",
    "   ```\n",
    "\n",
    "7. **Handling Missing Data:**\n",
    "   - `pandas` provides various methods for dealing with missing data, such as filling or dropping missing values.\n",
    "   ```python\n",
    "   df.fillna(0)  # Replace NaN with 0\n",
    "   df.dropna()   # Remove rows with NaN values\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Time Series with `pandas`:**\n",
    "\n",
    "1. **Datetime Objects:**\n",
    "\n",
    "   - `pandas` has rich support for datetime operations, such as creating a datetime index or converting strings to `datetime` objects.\n",
    "\n",
    "   ```python\n",
    "   # Converting string to datetime\n",
    "   df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "   # Setting a datetime column as index\n",
    "   df.set_index('date', inplace=True)\n",
    "   ```\n",
    "\n",
    "2. **Resampling:**\n",
    "\n",
    "   - Resampling is useful for changing the frequency of time-series data (e.g., daily to monthly).\n",
    "\n",
    "   ```python\n",
    "   df.resample('M').mean()  # Resample to monthly frequency and calculate the mean\n",
    "   ```\n",
    "\n",
    "3. **Shifting:**\n",
    "   - Shifting allows you to shift time-series data forward or backward.\n",
    "   ```python\n",
    "   df['shifted'] = df['value'].shift(1)  # Shift data forward by 1 time unit\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Data Import and Export with `pandas`:**\n",
    "\n",
    "1. **Reading Data:**\n",
    "\n",
    "   - `pandas` supports reading from a variety of file formats, including CSV, Excel, JSON, SQL databases, and more.\n",
    "\n",
    "   ```python\n",
    "   # Reading from CSV\n",
    "   df = pd.read_csv('data.csv')\n",
    "\n",
    "   # Reading from Excel\n",
    "   df = pd.read_excel('data.xlsx')\n",
    "   ```\n",
    "\n",
    "2. **Writing Data:**\n",
    "   - You can also write data to different formats.\n",
    "   ```python\n",
    "   df.to_csv('output.csv', index=False)\n",
    "   df.to_excel('output.xlsx', index=False)\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Common `pandas` Functions Summary:**\n",
    "\n",
    "| Function           | Description                                                           |\n",
    "| ------------------ | --------------------------------------------------------------------- |\n",
    "| `pd.Series()`      | Creates a pandas Series (1D array).                                   |\n",
    "| `pd.DataFrame()`   | Creates a pandas DataFrame (2D table).                                |\n",
    "| `df.head()`        | Returns the first 5 rows of the DataFrame.                            |\n",
    "| `df.tail()`        | Returns the last 5 rows of the DataFrame.                             |\n",
    "| `df.describe()`    | Returns summary statistics of numerical columns.                      |\n",
    "| `df.info()`        | Provides information about the DataFrame (e.g., columns, data types). |\n",
    "| `df.isnull()`      | Checks for missing values.                                            |\n",
    "| `df.dropna()`      | Drops rows with missing values.                                       |\n",
    "| `df.fillna()`      | Fills missing values with a specified value.                          |\n",
    "| `df.groupby()`     | Groups data for aggregation.                                          |\n",
    "| `df.sort_values()` | Sorts the DataFrame by specified column(s).                           |\n",
    "| `df.merge()`       | Merges DataFrames by common columns or indices.                       |\n",
    "\n",
    "---\n",
    "\n",
    "### **Use Cases of `pandas`:**\n",
    "\n",
    "1. **Data Cleaning:**\n",
    "\n",
    "   - `pandas` is commonly used in data preprocessing tasks, including handling missing data, removing duplicates, and normalizing data.\n",
    "\n",
    "2. **Exploratory Data Analysis (EDA):**\n",
    "\n",
    "   - It is often the first step in data analysis workflows, where you inspect the data, generate summary statistics, and visualize patterns.\n",
    "\n",
    "3. **Time Series Analysis:**\n",
    "\n",
    "   - `pandas` is widely used in time-series analysis, such as financial data analysis, sales forecasting, and sensor data processing.\n",
    "\n",
    "4. **Machine Learning Pipelines:**\n",
    "\n",
    "   - `pandas` is essential in building machine learning pipelines, where data is loaded, cleaned, and prepared before feeding it into machine learning algorithms.\n",
    "\n",
    "5. **Business Intelligence:**\n",
    "   - It is used for analyzing business data, such as customer behavior analysis, sales reporting, and financial modeling.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion:**\n",
    "\n",
    "The `pandas` module is an indispensable tool for data manipulation and analysis in Python. With its powerful data structures (Series and DataFrame) and extensive functionality for handling, cleaning, and analyzing data, it has become the standard tool for data science and analytics. Whether you are working with small datasets or big data, `pandas` provides efficient methods for data manipulation, making it a must-have in your Python data toolkit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data manipulation with **Pandas** is one of the most important skills in data science and analysis. **Pandas** is a powerful, open-source data manipulation and analysis library built on top of **Python**. It provides easy-to-use data structures and data analysis tools, such as **DataFrames** and **Series**, to handle structured data and perform various operations like filtering, sorting, reshaping, merging, grouping, and much more.\n",
    "\n",
    "Below is a comprehensive guide covering all concepts and theoretical understanding related to **data manipulation with Pandas**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Introduction to Pandas**\n",
    "\n",
    "Pandas is designed to work with data in a tabular form (i.e., rows and columns). It provides two primary data structures:\n",
    "\n",
    "- **Series**: One-dimensional labeled array, similar to a list or a column in a table.\n",
    "- **DataFrame**: Two-dimensional labeled data structure, like a table or a spreadsheet.\n",
    "\n",
    "Pandas allows easy data manipulation, including operations like filtering, reshaping, merging, joining, and time series analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Installing Pandas**\n",
    "\n",
    "To install pandas, you can use the following command:\n",
    "\n",
    "```bash\n",
    "pip install pandas\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Pandas Data Structures**\n",
    "\n",
    "#### **3.1 Series**\n",
    "\n",
    "A **Series** is a one-dimensional labeled array capable of holding any data type (integers, strings, floats, etc.).\n",
    "\n",
    "- **Creating a Series**:\n",
    "\n",
    "  ```python\n",
    "  import pandas as pd\n",
    "\n",
    "  # From a list\n",
    "  series1 = pd.Series([10, 20, 30, 40])\n",
    "\n",
    "  # From a dictionary\n",
    "  series2 = pd.Series({'a': 1, 'b': 2, 'c': 3})\n",
    "\n",
    "  print(series1)\n",
    "  print(series2)\n",
    "  ```\n",
    "\n",
    "- **Operations**: You can perform operations such as element-wise arithmetic, slicing, and indexing on a Series.\n",
    "  ```python\n",
    "  # Arithmetic operation\n",
    "  series1 = pd.Series([1, 2, 3])\n",
    "  series2 = pd.Series([4, 5, 6])\n",
    "  result = series1 + series2  # Adding element-wise\n",
    "  ```\n",
    "\n",
    "#### **3.2 DataFrame**\n",
    "\n",
    "A **DataFrame** is a two-dimensional labeled data structure with columns potentially of different types.\n",
    "\n",
    "- **Creating a DataFrame**:\n",
    "\n",
    "  ```python\n",
    "  import pandas as pd\n",
    "\n",
    "  # From a dictionary\n",
    "  data = {'Name': ['John', 'Anna', 'Peter'],\n",
    "          'Age': [28, 24, 35]}\n",
    "  df = pd.DataFrame(data)\n",
    "\n",
    "  print(df)\n",
    "  ```\n",
    "\n",
    "- **Accessing Data**:\n",
    "  - **By column**: `df['Name']`\n",
    "  - **By row**: `df.iloc[0]` (by index) or `df.loc[0]` (by label)\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Data Manipulation Operations in Pandas**\n",
    "\n",
    "Pandas offers a wide variety of operations for manipulating data, including filtering, sorting, grouping, and merging datasets.\n",
    "\n",
    "#### **4.1 Selecting Data**\n",
    "\n",
    "- **Selecting Columns**:\n",
    "\n",
    "  ```python\n",
    "  df['Age']  # Accessing a single column\n",
    "  df[['Name', 'Age']]  # Accessing multiple columns\n",
    "  ```\n",
    "\n",
    "- **Selecting Rows**:\n",
    "  - By **index**:\n",
    "    ```python\n",
    "    df.iloc[0]  # First row (index 0)\n",
    "    df.iloc[1:3]  # Rows from index 1 to 3 (exclusive)\n",
    "    ```\n",
    "  - By **label**:\n",
    "    ```python\n",
    "    df.loc[0]  # Row with label 0\n",
    "    ```\n",
    "\n",
    "#### **4.2 Filtering Data**\n",
    "\n",
    "You can filter rows based on conditions:\n",
    "\n",
    "- **Filter rows where Age is greater than 25**:\n",
    "\n",
    "  ```python\n",
    "  df[df['Age'] > 25]\n",
    "  ```\n",
    "\n",
    "- **Filter based on multiple conditions**:\n",
    "  ```python\n",
    "  df[(df['Age'] > 25) & (df['Name'] == 'John')]\n",
    "  ```\n",
    "\n",
    "#### **4.3 Sorting Data**\n",
    "\n",
    "- **Sort by one or more columns**:\n",
    "  ```python\n",
    "  df.sort_values(by='Age')  # Sort by Age in ascending order\n",
    "  df.sort_values(by=['Age', 'Name'], ascending=[True, False])  # Multi-column sorting\n",
    "  ```\n",
    "\n",
    "#### **4.4 Adding/Removing Columns**\n",
    "\n",
    "- **Adding a new column**:\n",
    "\n",
    "  ```python\n",
    "  df['Gender'] = ['Male', 'Female', 'Male']\n",
    "  ```\n",
    "\n",
    "- **Removing a column**:\n",
    "  ```python\n",
    "  df.drop('Gender', axis=1, inplace=True)  # axis=1 means column, inplace modifies the DataFrame\n",
    "  ```\n",
    "\n",
    "#### **4.5 Handling Missing Data**\n",
    "\n",
    "Pandas provides multiple ways to handle missing data (`NaN` values).\n",
    "\n",
    "- **Checking for missing data**:\n",
    "\n",
    "  ```python\n",
    "  df.isna()  # Returns a DataFrame of boolean values (True for NaN)\n",
    "  df.notna()  # Returns the inverse (True for non-NaN values)\n",
    "  ```\n",
    "\n",
    "- **Filling missing data**:\n",
    "\n",
    "  ```python\n",
    "  df.fillna(value=0)  # Replace all NaN values with 0\n",
    "  df['Age'].fillna(df['Age'].mean(), inplace=True)  # Replace NaN in Age column with mean value\n",
    "  ```\n",
    "\n",
    "- **Dropping missing data**:\n",
    "  ```python\n",
    "  df.dropna()  # Drop rows with NaN values\n",
    "  ```\n",
    "\n",
    "#### **4.6 Changing Data**\n",
    "\n",
    "- **Replacing values**:\n",
    "\n",
    "  ```python\n",
    "  df['Age'] = df['Age'].replace(24, 25)  # Replace 24 with 25 in the 'Age' column\n",
    "  ```\n",
    "\n",
    "- **Renaming columns**:\n",
    "  ```python\n",
    "  df.rename(columns={'Name': 'Full Name', 'Age': 'Years'}, inplace=True)\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Data Aggregation and Grouping**\n",
    "\n",
    "Pandas makes it easy to aggregate data and perform group operations.\n",
    "\n",
    "#### **5.1 Grouping Data**\n",
    "\n",
    "You can group data based on certain columns and then perform aggregate functions like `sum`, `mean`, `count`, etc.\n",
    "\n",
    "- **Group by a column and calculate mean**:\n",
    "\n",
    "  ```python\n",
    "  df.groupby('Gender')['Age'].mean()  # Group by 'Gender' and compute the average 'Age'\n",
    "  ```\n",
    "\n",
    "- **Multiple aggregations**:\n",
    "  ```python\n",
    "  df.groupby('Gender').agg({'Age': ['mean', 'max', 'min']})\n",
    "  ```\n",
    "\n",
    "#### **5.2 Aggregation Functions**\n",
    "\n",
    "- **Sum**:\n",
    "\n",
    "  ```python\n",
    "  df['Age'].sum()  # Total sum of the 'Age' column\n",
    "  ```\n",
    "\n",
    "- **Count**:\n",
    "\n",
    "  ```python\n",
    "  df['Gender'].count()  # Count non-null values in 'Gender' column\n",
    "  ```\n",
    "\n",
    "- **Other functions**: `mean()`, `median()`, `std()` (standard deviation), `min()`, `max()`\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Merging, Joining, and Concatenating DataFrames**\n",
    "\n",
    "Pandas offers various methods to combine data from different sources.\n",
    "\n",
    "#### **6.1 Concatenating DataFrames**\n",
    "\n",
    "You can concatenate DataFrames along rows (axis=0) or columns (axis=1).\n",
    "\n",
    "- **Concatenate along rows**:\n",
    "  ```python\n",
    "  df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
    "  df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})\n",
    "  result = pd.concat([df1, df2], axis=0)\n",
    "  ```\n",
    "\n",
    "#### **6.2 Merging DataFrames**\n",
    "\n",
    "Merging is similar to SQL JOIN operations. You can merge on specific columns or indexes.\n",
    "\n",
    "- **Merge on a column**:\n",
    "  ```python\n",
    "  df1 = pd.DataFrame({'ID': [1, 2, 3], 'Value': ['A', 'B', 'C']})\n",
    "  df2 = pd.DataFrame({'ID': [1, 2, 4], 'Score': [85, 90, 88]})\n",
    "  merged_df = pd.merge(df1, df2, on='ID', how='inner')  # Inner join on 'ID'\n",
    "  ```\n",
    "\n",
    "#### **6.3 Joining DataFrames**\n",
    "\n",
    "- **Join based on index**:\n",
    "  ```python\n",
    "  df1 = pd.DataFrame({'Value': ['A', 'B', 'C']}, index=[1, 2, 3])\n",
    "  df2 = pd.DataFrame({'Score': [85, 90, 88]}, index=[1, 2, 3])\n",
    "  joined_df = df1.join(df2)\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Pivot Tables**\n",
    "\n",
    "A **pivot table** is a data summarization tool, commonly used for reorganization of data into a table format.\n",
    "\n",
    "- **Creating a Pivot Table**:\n",
    "  ```python\n",
    "  df = pd.DataFrame({'Date': ['2021-01-01', '2021-01-01', '2021-01-02'],\n",
    "                     'City': ['New York', 'Los Angeles', 'New York'],\n",
    "                     'Sales': [100, 200, 150]})\n",
    "  pivot_df = pd.pivot_table(df, values='Sales', index='Date', columns='City', aggfunc='sum')\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Time Series Manipulation**\n",
    "\n",
    "Pandas has powerful tools for time series analysis.\n",
    "\n",
    "- **Convert a column to a DateTime object**:\n",
    "\n",
    "  ```python\n",
    "  df['Date'] = pd.to_datetime(df['Date'])\n",
    "  ```\n",
    "\n",
    "- **Setting a DateTime index**:\n",
    "\n",
    "  ```python\n",
    "  df.set_index('Date', inplace=True)\n",
    "  ```\n",
    "\n",
    "- **Resampling (e.g., to daily, monthly)**:\n",
    "  ```python\n",
    "  df.resample('M').mean()  # Resample to monthly frequency and calculate mean\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Conclusion**\n",
    "\n",
    "Pandas is an incredibly versatile library for handling and manipulating structured data. From simple operations like filtering and sorting to advanced techniques like merging, pivoting, and time series analysis, **Pandas** provides all the tools necessary for efficient data manipulation. Understanding how to leverage its capabilities will help you perform data analysis, wrangle data, and prepare it for machine learning models or other tasks.\n",
    "\n",
    "---\n",
    "\n",
    "The above concepts should give you a solid foundation in **data manipulation** using **Pandas**. Practice these concepts with real-world datasets to build a deeper understanding and mastery of the library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pandas DataFrame: All Concepts and Theory**\n",
    "\n",
    "The **DataFrame** is one of the most powerful and widely used data structures in the **Pandas** library. It is designed to handle 2-dimensional data, such as tables, where each row represents an observation, and each column represents a feature or variable.\n",
    "\n",
    "A **DataFrame** can hold data of different types (integer, float, string, etc.) across columns, and it allows for easy manipulation and analysis of structured data.\n",
    "\n",
    "Here is a detailed guide to understanding **Pandas DataFrame** and its concepts:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. What is a DataFrame?**\n",
    "\n",
    "A **DataFrame** in Pandas is a two-dimensional, size-mutable, and potentially heterogeneous tabular data structure with labeled axes (rows and columns). It can be thought of as a collection of **Series** objects (one for each column) sharing the same index.\n",
    "\n",
    "#### Key Features of DataFrame:\n",
    "\n",
    "- **Rows and Columns**: Data in a table-like structure where each row represents an observation, and each column represents a feature.\n",
    "- **Indexing**: Each row and column can have labels (indices) which allow for easy data manipulation and access.\n",
    "- **Heterogeneous**: Columns can contain different types of data (integers, floats, strings, etc.).\n",
    "- **Size-Mutable**: You can modify the size of the DataFrame by adding/removing rows or columns.\n",
    "- **Arithmetic Operations**: You can perform arithmetic and aggregation operations on entire DataFrames.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Creating a DataFrame**\n",
    "\n",
    "#### **2.1 From Lists or Arrays**\n",
    "\n",
    "You can create a DataFrame from lists or NumPy arrays.\n",
    "\n",
    "- **From Lists**:\n",
    "\n",
    "  ```python\n",
    "  import pandas as pd\n",
    "\n",
    "  data = [['John', 28], ['Anna', 24], ['Peter', 35]]\n",
    "  df = pd.DataFrame(data, columns=['Name', 'Age'])\n",
    "  print(df)\n",
    "  ```\n",
    "\n",
    "- **From NumPy Arrays**:\n",
    "\n",
    "  ```python\n",
    "  import numpy as np\n",
    "\n",
    "  arr = np.array([['John', 28], ['Anna', 24], ['Peter', 35]])\n",
    "  df = pd.DataFrame(arr, columns=['Name', 'Age'])\n",
    "  print(df)\n",
    "  ```\n",
    "\n",
    "#### **2.2 From a Dictionary**\n",
    "\n",
    "A common way to create a DataFrame is by passing a dictionary, where keys are column names and values are data.\n",
    "\n",
    "- **Example**:\n",
    "  ```python\n",
    "  data = {'Name': ['John', 'Anna', 'Peter'], 'Age': [28, 24, 35]}\n",
    "  df = pd.DataFrame(data)\n",
    "  print(df)\n",
    "  ```\n",
    "\n",
    "#### **2.3 From a CSV or Excel File**\n",
    "\n",
    "You can read data from external sources like CSV or Excel files directly into a DataFrame.\n",
    "\n",
    "- **CSV**:\n",
    "\n",
    "  ```python\n",
    "  df = pd.read_csv('data.csv')\n",
    "  ```\n",
    "\n",
    "- **Excel**:\n",
    "  ```python\n",
    "  df = pd.read_excel('data.xlsx', sheet_name='Sheet1')\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Accessing Data in a DataFrame**\n",
    "\n",
    "#### **3.1 Selecting Columns**\n",
    "\n",
    "- **Single Column**: You can access a column by specifying its name.\n",
    "\n",
    "  ```python\n",
    "  df['Name']\n",
    "  ```\n",
    "\n",
    "- **Multiple Columns**: Use double brackets to select multiple columns.\n",
    "  ```python\n",
    "  df[['Name', 'Age']]\n",
    "  ```\n",
    "\n",
    "#### **3.2 Selecting Rows**\n",
    "\n",
    "- **By Index**: Use `iloc` for positional index-based access.\n",
    "\n",
    "  ```python\n",
    "  df.iloc[0]  # First row\n",
    "  df.iloc[1:3]  # Rows from index 1 to 3 (exclusive)\n",
    "  ```\n",
    "\n",
    "- **By Label**: Use `loc` for label-based access.\n",
    "  ```python\n",
    "  df.loc[0]  # First row by label (if using default integer indexing)\n",
    "  ```\n",
    "\n",
    "#### **3.3 Selecting Specific Elements**\n",
    "\n",
    "- **By Row and Column**:\n",
    "  ```python\n",
    "  df.loc[0, 'Name']  # Value in the first row and 'Name' column\n",
    "  df.iloc[0, 1]  # Value in the first row and second column (0-indexed)\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Modifying a DataFrame**\n",
    "\n",
    "#### **4.1 Adding a Column**\n",
    "\n",
    "You can add a new column to a DataFrame by simply assigning a value to a new column label.\n",
    "\n",
    "- **Example**:\n",
    "  ```python\n",
    "  df['Gender'] = ['Male', 'Female', 'Male']\n",
    "  print(df)\n",
    "  ```\n",
    "\n",
    "#### **4.2 Removing a Column**\n",
    "\n",
    "To remove a column, use the `drop()` method.\n",
    "\n",
    "- **Example**:\n",
    "  ```python\n",
    "  df.drop('Gender', axis=1, inplace=True)  # axis=1 means column\n",
    "  ```\n",
    "\n",
    "#### **4.3 Renaming Columns**\n",
    "\n",
    "To rename columns, use the `rename()` method.\n",
    "\n",
    "- **Example**:\n",
    "  ```python\n",
    "  df.rename(columns={'Name': 'Full Name', 'Age': 'Years'}, inplace=True)\n",
    "  ```\n",
    "\n",
    "#### **4.4 Changing Data in a Column**\n",
    "\n",
    "You can modify the data in a column by directly accessing the column and assigning new values.\n",
    "\n",
    "- **Example**:\n",
    "  ```python\n",
    "  df['Age'] = df['Age'] + 1  # Increase all ages by 1\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Handling Missing Data**\n",
    "\n",
    "Pandas provides multiple methods for handling missing data (NaN values).\n",
    "\n",
    "#### **5.1 Checking for Missing Data**\n",
    "\n",
    "You can check for missing values using `isna()` or `isnull()`.\n",
    "\n",
    "- **Example**:\n",
    "  ```python\n",
    "  df.isna()  # Returns a DataFrame with True for NaN and False for non-NaN values\n",
    "  ```\n",
    "\n",
    "#### **5.2 Dropping Missing Data**\n",
    "\n",
    "To drop rows with missing values, use `dropna()`.\n",
    "\n",
    "- **Example**:\n",
    "  ```python\n",
    "  df.dropna(inplace=True)  # Drop rows with any missing value\n",
    "  ```\n",
    "\n",
    "#### **5.3 Filling Missing Data**\n",
    "\n",
    "You can fill missing data using `fillna()`.\n",
    "\n",
    "- **Example**:\n",
    "  ```python\n",
    "  df['Age'] = df['Age'].fillna(df['Age'].mean())  # Replace NaN with the mean of the Age column\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Sorting and Ordering Data**\n",
    "\n",
    "#### **6.1 Sorting by Columns**\n",
    "\n",
    "You can sort data by one or more columns using `sort_values()`.\n",
    "\n",
    "- **Example**:\n",
    "  ```python\n",
    "  df.sort_values(by='Age', ascending=False, inplace=True)  # Sort by Age in descending order\n",
    "  ```\n",
    "\n",
    "#### **6.2 Sorting by Index**\n",
    "\n",
    "You can sort data based on the DataFrame's index.\n",
    "\n",
    "- **Example**:\n",
    "  ```python\n",
    "  df.sort_index(axis=0, ascending=True, inplace=True)  # Sort by index\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Aggregating and Grouping Data**\n",
    "\n",
    "Pandas allows grouping and aggregation of data using the `groupby()` method.\n",
    "\n",
    "#### **7.1 Grouping by Columns**\n",
    "\n",
    "You can group data based on one or more columns and perform aggregations like `sum`, `mean`, `count`, etc.\n",
    "\n",
    "- **Example**:\n",
    "  ```python\n",
    "  df.groupby('Gender')['Age'].mean()  # Group by 'Gender' and calculate the mean age\n",
    "  ```\n",
    "\n",
    "#### **7.2 Multiple Aggregations**\n",
    "\n",
    "You can apply multiple aggregation functions to grouped data.\n",
    "\n",
    "- **Example**:\n",
    "  ```python\n",
    "  df.groupby('Gender').agg({'Age': ['mean', 'max', 'min']})\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Merging and Joining DataFrames**\n",
    "\n",
    "You can combine multiple DataFrames using merge, join, and concatenate methods.\n",
    "\n",
    "#### **8.1 Merging DataFrames**\n",
    "\n",
    "The `merge()` function is used to merge two DataFrames on a column or index.\n",
    "\n",
    "- **Example**:\n",
    "  ```python\n",
    "  df1 = pd.DataFrame({'ID': [1, 2, 3], 'Value': ['A', 'B', 'C']})\n",
    "  df2 = pd.DataFrame({'ID': [1, 2, 4], 'Score': [85, 90, 88]})\n",
    "  result = pd.merge(df1, df2, on='ID', how='inner')  # Merge using 'ID' column\n",
    "  ```\n",
    "\n",
    "#### **8.2 Concatenating DataFrames**\n",
    "\n",
    "You can concatenate DataFrames along rows (axis=0) or columns (axis=1).\n",
    "\n",
    "- **Example**:\n",
    "  ```python\n",
    "  df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
    "  df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})\n",
    "  result = pd.concat([df1, df2], axis=0)  # Concatenate along rows\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Pivot Tables**\n",
    "\n",
    "A **pivot table** is a way of summarizing data in a tabular form.\n",
    "\n",
    "- **Example**:\n",
    "\n",
    "  ```python\n",
    "  df = pd.DataFrame({\n",
    "      'Date': ['2021-01-01', '2021-01-01', '2021-01-02'],\n",
    "      'City': ['New York', 'Los Angeles', 'New York'],\n",
    "      'Sales': [100, 200, 150]\n",
    "  })\n",
    "\n",
    "  pivot_df = pd.pivot_table(df, values='Sales', index='Date', columns='City', aggfunc='sum')\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Time Series in DataFrame**\n",
    "\n",
    "Pandas provides powerful time series functionality, such as handling DateTime indexes, resampling, and time-based indexing.\n",
    "\n",
    "#### **10.1 Converting to DateTime**\n",
    "\n",
    "To work with time series, convert a column to a DateTime object.\n",
    "\n",
    "- **Example**:\n",
    "  ```python\n",
    "  df['Date'] = pd.to_datetime(df['Date'])\n",
    "  ```\n",
    "\n",
    "#### **10.2 Resampling Time Series Data**\n",
    "\n",
    "You can resample data at different time frequencies (e.g., monthly, daily).\n",
    "\n",
    "- **Example**:\n",
    "  ```python\n",
    "  df.set_index('Date', inplace=True)\n",
    "  df.resample('M').mean()  # Resample by month and calculate mean\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **11. Conclusion**\n",
    "\n",
    "A **Pandas DataFrame** is an incredibly flexible and powerful data structure for working with structured data in Python. Whether you are cleaning, filtering, grouping, merging, or analyzing data, the DataFrame is the cornerstone of data manipulation in Pandas. Understanding the various functionalities provided by Pandas, such as indexing, filtering, aggregation, and joining, will greatly enhance your ability to analyze and manipulate large datasets efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating DataFrame from Lists in Pandas: All Concepts and Theory**\n",
    "\n",
    "In **Pandas**, the **DataFrame** is one of the most common and versatile data structures. It represents tabular data, and you can easily create a DataFrame from various data sources, including lists, dictionaries, or external files. Here, we'll focus on creating a **DataFrame** from **lists**.\n",
    "\n",
    "A **DataFrame** created from a list can hold a collection of data that can be organized into rows and columns. The list itself can be structured in different ways, and each structure will affect the way the DataFrame is created.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Basics of DataFrame Creation**\n",
    "\n",
    "The basic syntax for creating a **Pandas DataFrame** from a list is:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "Where:\n",
    "\n",
    "- `data`: A list, list of lists, or a list of tuples.\n",
    "- `pd.DataFrame()`: The constructor that converts the provided data into a DataFrame.\n",
    "\n",
    "#### **Key Concepts**:\n",
    "\n",
    "- **Data**: The input data for the DataFrame (a list, list of lists, list of tuples, etc.).\n",
    "- **Columns**: The names of the columns that you want in the DataFrame (optional).\n",
    "- **Index**: The row labels for the DataFrame (optional).\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Creating DataFrame from Single List**\n",
    "\n",
    "If you create a DataFrame from a single list, it will create a DataFrame with one column, where the list items become the rows.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = ['Alice', 'Bob', 'Charlie']\n",
    "df = pd.DataFrame(data, columns=['Name'])\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "      Name\n",
    "0    Alice\n",
    "1      Bob\n",
    "2  Charlie\n",
    "```\n",
    "\n",
    "#### Key Points:\n",
    "\n",
    "- Here, `data` is a simple list.\n",
    "- **Columns** parameter is used to label the column.\n",
    "- The DataFrame has a single column labeled `Name` with the list items as rows.\n",
    "- **Index** is auto-generated (0, 1, 2, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Creating DataFrame from List of Lists**\n",
    "\n",
    "When the data is a list of lists, each inner list becomes a row in the DataFrame. The outer list represents the rows, and the inner lists represent the columns.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = [['Alice', 24], ['Bob', 25], ['Charlie', 23]]\n",
    "df = pd.DataFrame(data, columns=['Name', 'Age'])\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "      Name  Age\n",
    "0    Alice   24\n",
    "1      Bob   25\n",
    "2  Charlie   23\n",
    "```\n",
    "\n",
    "#### Key Points:\n",
    "\n",
    "- **Inner lists** represent rows of data.\n",
    "- Each inner list is split into columns based on the `columns` argument.\n",
    "- `columns=['Name', 'Age']` assigns labels to the DataFrame's columns.\n",
    "- By default, Pandas assigns an index starting from `0`.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Creating DataFrame from List of Tuples**\n",
    "\n",
    "A list of tuples can also be used in the same way as a list of lists. Each tuple represents a row, and elements within each tuple correspond to values in the columns.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = [('Alice', 24), ('Bob', 25), ('Charlie', 23)]\n",
    "df = pd.DataFrame(data, columns=['Name', 'Age'])\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "      Name  Age\n",
    "0    Alice   24\n",
    "1      Bob   25\n",
    "2  Charlie   23\n",
    "```\n",
    "\n",
    "#### Key Points:\n",
    "\n",
    "- The tuples are processed in the same way as lists to create rows.\n",
    "- The **columns** are assigned as specified (`['Name', 'Age']`).\n",
    "- Index is auto-generated by default (0, 1, 2, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Creating DataFrame with Index**\n",
    "\n",
    "You can manually define an index (row labels) while creating a DataFrame from a list.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = [['Alice', 24], ['Bob', 25], ['Charlie', 23]]\n",
    "df = pd.DataFrame(data, columns=['Name', 'Age'], index=['a', 'b', 'c'])\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "      Name  Age\n",
    "a    Alice   24\n",
    "b      Bob   25\n",
    "c  Charlie   23\n",
    "```\n",
    "\n",
    "#### Key Points:\n",
    "\n",
    "- **Index** is specified explicitly (`['a', 'b', 'c']`).\n",
    "- The DataFrame now uses these custom index labels instead of the default 0, 1, 2, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Creating DataFrame from Nested Lists with Different Lengths**\n",
    "\n",
    "If you provide a list of lists where each inner list has a different length, Pandas will fill the missing values with `NaN` (Not a Number).\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = [['Alice', 24], ['Bob', 25], ['Charlie']]  # Charlie does not have an Age\n",
    "df = pd.DataFrame(data, columns=['Name', 'Age'])\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "      Name   Age\n",
    "0    Alice  24.0\n",
    "1      Bob  25.0\n",
    "2  Charlie   NaN\n",
    "```\n",
    "\n",
    "#### Key Points:\n",
    "\n",
    "- Pandas will automatically handle rows with missing data (like `Charlie` in the example) and fill the missing value with `NaN`.\n",
    "- The **NaN** value indicates the absence of data in the `Age` column for the \"Charlie\" row.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Creating DataFrame from List of Dictionaries**\n",
    "\n",
    "You can also create a DataFrame from a list of dictionaries. Each dictionary represents a row, and the keys are the column labels.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = [{'Name': 'Alice', 'Age': 24}, {'Name': 'Bob', 'Age': 25}, {'Name': 'Charlie', 'Age': 23}]\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "      Name  Age\n",
    "0    Alice   24\n",
    "1      Bob   25\n",
    "2  Charlie   23\n",
    "```\n",
    "\n",
    "#### Key Points:\n",
    "\n",
    "- Each dictionary is considered a row in the DataFrame.\n",
    "- Keys in the dictionaries correspond to the column names.\n",
    "- If the dictionaries have different keys, missing columns will be filled with `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Additional Parameters in `DataFrame` Constructor**\n",
    "\n",
    "#### **8.1 Specifying Data Types**\n",
    "\n",
    "You can specify the data types for columns by using the `dtype` parameter.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = [['Alice', 24], ['Bob', 25], ['Charlie', 23]]\n",
    "df = pd.DataFrame(data, columns=['Name', 'Age'], dtype='object')\n",
    "\n",
    "print(df.dtypes)  # Check the data types of columns\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Name    object\n",
    "Age     object\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "- **dtype** can be set to 'int', 'float', 'str', 'object', or other valid Pandas types to ensure specific column types.\n",
    "\n",
    "#### **8.2 Handling Missing Data**\n",
    "\n",
    "You can manage missing data during DataFrame creation by filling it or replacing it after creation.\n",
    "\n",
    "- **Example** (Filling missing data):\n",
    "  ```python\n",
    "  df.fillna('N/A', inplace=True)\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Summary of Key Methods for Creating DataFrame from Lists**\n",
    "\n",
    "- **From List of Lists**:\n",
    "\n",
    "  ```python\n",
    "  df = pd.DataFrame([['Alice', 24], ['Bob', 25]], columns=['Name', 'Age'])\n",
    "  ```\n",
    "\n",
    "- **From List of Tuples**:\n",
    "\n",
    "  ```python\n",
    "  df = pd.DataFrame([('Alice', 24), ('Bob', 25)], columns=['Name', 'Age'])\n",
    "  ```\n",
    "\n",
    "- **With Custom Index**:\n",
    "\n",
    "  ```python\n",
    "  df = pd.DataFrame([['Alice', 24], ['Bob', 25]], columns=['Name', 'Age'], index=['a', 'b'])\n",
    "  ```\n",
    "\n",
    "- **From List of Dictionaries**:\n",
    "\n",
    "  ```python\n",
    "  df = pd.DataFrame([{'Name': 'Alice', 'Age': 24}, {'Name': 'Bob', 'Age': 25}])\n",
    "  ```\n",
    "\n",
    "- **From Nested Lists of Unequal Lengths**:\n",
    "  ```python\n",
    "  df = pd.DataFrame([['Alice', 24], ['Bob', 25], ['Charlie']])\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Conclusion**\n",
    "\n",
    "Creating a **Pandas DataFrame** from lists is a fundamental and powerful method to organize and manipulate data in Python. Understanding how to create DataFrames from different structures such as single lists, lists of lists, or lists of dictionaries provides great flexibility in handling diverse datasets. Once the DataFrame is created, you can perform various operations like indexing, modifying, filtering, grouping, and analyzing data efficiently with the Pandas library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating DataFrame from Arrays in Pandas: All Concepts and Theory**\n",
    "\n",
    "In **Pandas**, the **DataFrame** is the primary data structure used to hold tabular data. You can create a DataFrame from various data types such as lists, dictionaries, or arrays (including **NumPy arrays**). **NumPy arrays** are particularly useful when you have numerical data, as they are optimized for mathematical operations.\n",
    "\n",
    "Here, we will explore how to create a **DataFrame** from **arrays**, particularly focusing on **NumPy arrays** and regular Python arrays, and explain the associated concepts.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Pandas DataFrame from NumPy Arrays**\n",
    "\n",
    "The most common use case for creating a DataFrame from an array is using **NumPy arrays**. A **NumPy array** is a powerful, homogeneous multidimensional array, which can be passed directly to Pandas to create a DataFrame.\n",
    "\n",
    "#### **1.1 Creating a DataFrame from a 1D NumPy Array**\n",
    "\n",
    "If you have a 1D NumPy array, it will be converted into a single column DataFrame.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a 1D NumPy array\n",
    "data = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# Create DataFrame from 1D array\n",
    "df = pd.DataFrame(data, columns=['Number'])\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   Number\n",
    "0       1\n",
    "1       2\n",
    "2       3\n",
    "3       4\n",
    "4       5\n",
    "```\n",
    "\n",
    "#### **Key Points**:\n",
    "\n",
    "- **1D array** becomes a **single column** in the DataFrame.\n",
    "- The **columns** are defined using the `columns` parameter.\n",
    "\n",
    "---\n",
    "\n",
    "#### **1.2 Creating a DataFrame from a 2D NumPy Array**\n",
    "\n",
    "When you use a **2D NumPy array**, each row of the array will be converted into a row in the DataFrame, and each column in the array will become a column in the DataFrame.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a 2D NumPy array\n",
    "data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# Create DataFrame from 2D array\n",
    "df = pd.DataFrame(data, columns=['A', 'B', 'C'])\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   A  B  C\n",
    "0  1  2  3\n",
    "1  4  5  6\n",
    "2  7  8  9\n",
    "```\n",
    "\n",
    "#### **Key Points**:\n",
    "\n",
    "- **2D array** results in a **multi-column DataFrame**.\n",
    "- The **rows** are indexed by default starting from 0.\n",
    "- The **columns** are labeled according to the provided list (`['A', 'B', 'C']` in this case).\n",
    "\n",
    "If no column names are provided, Pandas will automatically assign integer-based column names (`0, 1, 2, ...`).\n",
    "\n",
    "#### **1.3 Creating DataFrame from 2D NumPy Array with Custom Index**\n",
    "\n",
    "You can also define a custom index while creating a DataFrame.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a 2D NumPy array\n",
    "data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# Define custom row labels (index)\n",
    "index_labels = ['Row1', 'Row2', 'Row3']\n",
    "\n",
    "# Create DataFrame from 2D array with custom index\n",
    "df = pd.DataFrame(data, columns=['A', 'B', 'C'], index=index_labels)\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "       A  B  C\n",
    "Row1   1  2  3\n",
    "Row2   4  5  6\n",
    "Row3   7  8  9\n",
    "```\n",
    "\n",
    "#### **Key Points**:\n",
    "\n",
    "- **Index** is manually specified using `index`.\n",
    "- The **columns** are still specified using the `columns` parameter.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Pandas DataFrame from a Python List of Arrays**\n",
    "\n",
    "You can also create a DataFrame from a **list of arrays** (which are often lists themselves). This will be treated as a list of rows, where each element in the list corresponds to a row in the DataFrame.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a list of NumPy arrays\n",
    "data = [np.array([1, 2, 3]), np.array([4, 5, 6]), np.array([7, 8, 9])]\n",
    "\n",
    "# Create DataFrame from list of arrays\n",
    "df = pd.DataFrame(data, columns=['A', 'B', 'C'])\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   A  B  C\n",
    "0  1  2  3\n",
    "1  4  5  6\n",
    "2  7  8  9\n",
    "```\n",
    "\n",
    "#### **Key Points**:\n",
    "\n",
    "- A list of arrays results in a **multi-row DataFrame**.\n",
    "- Each **array** in the list corresponds to a **row** in the DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Pandas DataFrame from a Regular Python List of Lists**\n",
    "\n",
    "A regular Python list of lists can also be used, and it will behave similarly to a **NumPy 2D array**. The lists inside the outer list will be treated as rows, and the inner elements will be treated as columns.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a list of lists (similar to 2D array)\n",
    "data = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "\n",
    "# Create DataFrame from list of lists\n",
    "df = pd.DataFrame(data, columns=['A', 'B', 'C'])\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   A  B  C\n",
    "0  1  2  3\n",
    "1  4  5  6\n",
    "2  7  8  9\n",
    "```\n",
    "\n",
    "#### **Key Points**:\n",
    "\n",
    "- A list of lists behaves the same as a **2D NumPy array** for creating DataFrames.\n",
    "- Columns are named as specified (`['A', 'B', 'C']`).\n",
    "- The **index** is generated automatically (0, 1, 2,...).\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Creating DataFrame from Arrays with Custom Index**\n",
    "\n",
    "You can assign custom row labels (index) while creating a DataFrame from a list of lists or arrays.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a list of lists\n",
    "data = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "\n",
    "# Define custom index labels\n",
    "index_labels = ['Row1', 'Row2', 'Row3']\n",
    "\n",
    "# Create DataFrame from list of lists with custom index\n",
    "df = pd.DataFrame(data, columns=['A', 'B', 'C'], index=index_labels)\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "       A  B  C\n",
    "Row1   1  2  3\n",
    "Row2   4  5  6\n",
    "Row3   7  8  9\n",
    "```\n",
    "\n",
    "#### **Key Points**:\n",
    "\n",
    "- **Custom index labels** are applied to the rows.\n",
    "- **Column names** are defined via `columns`.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Advanced DataFrame Creation from Arrays (Handling Missing Data)**\n",
    "\n",
    "Sometimes your array data might have missing values or inconsistent shapes. Pandas handles this gracefully by filling missing values with `NaN` (Not a Number).\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a 2D NumPy array with missing data\n",
    "data = np.array([[1, 2, 3], [4, 5, 6], [7, 8]])\n",
    "\n",
    "# Create DataFrame from 2D array with missing values\n",
    "df = pd.DataFrame(data, columns=['A', 'B', 'C'])\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B    C\n",
    "0  1.0  2.0  3.0\n",
    "1  4.0  5.0  6.0\n",
    "2  7.0  8.0  NaN\n",
    "```\n",
    "\n",
    "#### **Key Points**:\n",
    "\n",
    "- The missing value in the last row (for column `C`) is filled with `NaN`.\n",
    "- Pandas automatically handles missing data during DataFrame creation, making it suitable for real-world datasets that may have gaps or irregularities.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Summary of Key Methods for Creating DataFrame from Arrays**\n",
    "\n",
    "- **From 1D NumPy Array**:\n",
    "\n",
    "  ```python\n",
    "  df = pd.DataFrame(np.array([1, 2, 3, 4]), columns=['Number'])\n",
    "  ```\n",
    "\n",
    "- **From 2D NumPy Array**:\n",
    "\n",
    "  ```python\n",
    "  df = pd.DataFrame(np.array([[1, 2], [3, 4]]), columns=['A', 'B'])\n",
    "  ```\n",
    "\n",
    "- **From List of Lists**:\n",
    "\n",
    "  ```python\n",
    "  df = pd.DataFrame([[1, 2], [3, 4]], columns=['A', 'B'])\n",
    "  ```\n",
    "\n",
    "- **With Custom Index**:\n",
    "\n",
    "  ```python\n",
    "  df = pd.DataFrame(np.array([[1, 2], [3, 4]]), columns=['A', 'B'], index=['row1', 'row2'])\n",
    "  ```\n",
    "\n",
    "- **With Missing Values**:\n",
    "  ```python\n",
    "  df = pd.DataFrame(np.array([[1, 2], [3, 4], [5]]), columns=['A', 'B'])\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Conclusion**\n",
    "\n",
    "Creating **Pandas DataFrames** from **arrays** is a common operation, especially when dealing with numerical data. The ability to create DataFrames from **NumPy arrays**, **Python lists**, and **other array-like structures** allows for flexible data manipulation and analysis. Whether you're using 1D or 2D arrays, or handling missing data, Pandas provides an efficient and user-friendly interface for transforming arrays into a powerful DataFrame structure for data analysis and manipulation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating DataFrame from Dictionary in Pandas: All Concepts and Theory**\n",
    "\n",
    "In **Pandas**, a **DataFrame** can be created from a dictionary where the keys are the column names, and the values are the data associated with each column. This method of creating a DataFrame is very common because dictionaries provide a clear and intuitive way to represent tabular data.\n",
    "\n",
    "Here, we will go through the concepts and theory related to creating a DataFrame from a **dictionary** in **Pandas**, and provide different use cases and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Basic Structure of a Dictionary in Pandas DataFrame Creation**\n",
    "\n",
    "When you pass a dictionary to the **`pd.DataFrame()`** function, each key-value pair in the dictionary is interpreted as a column. The **keys** represent the **column names**, and the **values** represent the **data** in those columns.\n",
    "\n",
    "#### **1.1 Example of Creating DataFrame from a Simple Dictionary**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a dictionary\n",
    "data = {'Name': ['John', 'Anna', 'Peter', 'Linda'],\n",
    "        'Age': [28, 24, 35, 32],\n",
    "        'City': ['New York', 'Paris', 'Berlin', 'London']}\n",
    "\n",
    "# Creating a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    Name  Age      City\n",
    "0   John   28  New York\n",
    "1   Anna   24     Paris\n",
    "2  Peter   35    Berlin\n",
    "3  Linda   32    London\n",
    "```\n",
    "\n",
    "#### **Key Points**:\n",
    "\n",
    "- The dictionary `data` contains three keys: `'Name'`, `'Age'`, and `'City'`.\n",
    "- These keys become the **column names** in the DataFrame.\n",
    "- The values corresponding to each key become the **data** for each column.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. DataFrame with Custom Index**\n",
    "\n",
    "By default, when you create a DataFrame from a dictionary, **Pandas automatically assigns an integer index** (0, 1, 2, …). However, you can provide a custom **index** to the DataFrame by passing a list of labels to the `index` parameter.\n",
    "\n",
    "#### **2.1 Example of Creating DataFrame with Custom Index**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a dictionary\n",
    "data = {'Name': ['John', 'Anna', 'Peter', 'Linda'],\n",
    "        'Age': [28, 24, 35, 32],\n",
    "        'City': ['New York', 'Paris', 'Berlin', 'London']}\n",
    "\n",
    "# Custom index\n",
    "index_labels = ['A', 'B', 'C', 'D']\n",
    "\n",
    "# Creating a DataFrame from the dictionary with custom index\n",
    "df = pd.DataFrame(data, index=index_labels)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    Name  Age      City\n",
    "A   John   28  New York\n",
    "B   Anna   24     Paris\n",
    "C  Peter   35    Berlin\n",
    "D  Linda   32    London\n",
    "```\n",
    "\n",
    "#### **Key Points**:\n",
    "\n",
    "- The index has been changed to `['A', 'B', 'C', 'D']`, instead of the default integer index.\n",
    "- This is useful for labeling rows in a way that makes more sense for your data, such as using custom identifiers.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Handling Missing Data (NaN) in a Dictionary**\n",
    "\n",
    "If the lists in the dictionary have different lengths, Pandas will automatically fill the missing data with `NaN` (Not a Number).\n",
    "\n",
    "#### **3.1 Example of Handling Missing Data**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a dictionary with different list lengths\n",
    "data = {'Name': ['John', 'Anna', 'Peter'],\n",
    "        'Age': [28, 24],\n",
    "        'City': ['New York', 'Paris', 'Berlin']}\n",
    "\n",
    "# Creating a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    Name   Age      City\n",
    "0   John  28.0  New York\n",
    "1   Anna  24.0     Paris\n",
    "2  Peter   NaN    Berlin\n",
    "```\n",
    "\n",
    "#### **Key Points**:\n",
    "\n",
    "- The missing `Age` value for `\"Peter\"` is filled with `NaN` automatically.\n",
    "- Pandas allows for flexible handling of missing data by using `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Creating DataFrame from a Dictionary with Different Data Types**\n",
    "\n",
    "The dictionary can contain a mix of **different data types**, such as integers, floats, strings, and booleans. Pandas will automatically infer the data type of each column based on the values in the dictionary.\n",
    "\n",
    "#### **4.1 Example of DataFrame with Mixed Data Types**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a dictionary with mixed data types\n",
    "data = {'Name': ['John', 'Anna', 'Peter'],\n",
    "        'Age': [28, 24, 35],\n",
    "        'Salary': [50000.5, 60000.0, 75000.25],\n",
    "        'Married': [True, False, True]}\n",
    "\n",
    "# Creating a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    Name  Age   Salary  Married\n",
    "0   John   28  50000.5     True\n",
    "1   Anna   24  60000.0    False\n",
    "2  Peter   35  75000.25    True\n",
    "```\n",
    "\n",
    "#### **Key Points**:\n",
    "\n",
    "- Columns have different data types (`int`, `float`, `bool`).\n",
    "- Pandas automatically handles different data types in each column.\n",
    "- This feature makes Pandas highly versatile in handling datasets with varied data types.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. DataFrame from Dictionary with Different Column Lengths**\n",
    "\n",
    "If the lengths of the data lists differ across columns, Pandas will align them by the index, and for the shorter columns, it will fill the missing values with `NaN`.\n",
    "\n",
    "#### **5.1 Example of Different Column Lengths**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a dictionary with columns of different lengths\n",
    "data = {'Name': ['John', 'Anna', 'Peter'],\n",
    "        'Age': [28, 24],\n",
    "        'City': ['New York', 'Paris', 'Berlin']}\n",
    "\n",
    "# Creating a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    Name   Age      City\n",
    "0   John  28.0  New York\n",
    "1   Anna  24.0     Paris\n",
    "2  Peter   NaN    Berlin\n",
    "```\n",
    "\n",
    "#### **Key Points**:\n",
    "\n",
    "- The shorter list for the `Age` column results in `NaN` in the corresponding row for `\"Peter\"`.\n",
    "- Pandas handles this by filling the missing values with `NaN` for the shorter column.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Creating DataFrame from Dictionary with Nested Dictionaries**\n",
    "\n",
    "You can also create a DataFrame from a **nested dictionary** (a dictionary of dictionaries), where each inner dictionary represents a row, and the keys of the outer dictionary represent the index.\n",
    "\n",
    "#### **6.1 Example of Creating DataFrame from Nested Dictionary**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a nested dictionary\n",
    "data = {'row1': {'Name': 'John', 'Age': 28, 'City': 'New York'},\n",
    "        'row2': {'Name': 'Anna', 'Age': 24, 'City': 'Paris'},\n",
    "        'row3': {'Name': 'Peter', 'Age': 35, 'City': 'Berlin'}}\n",
    "\n",
    "# Creating a DataFrame from the nested dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "      row1   row2   row3\n",
    "Name   John   Anna  Peter\n",
    "Age     28     24     35\n",
    "City  New York Paris Berlin\n",
    "```\n",
    "\n",
    "#### **Key Points**:\n",
    "\n",
    "- **Keys of the outer dictionary (`'row1', 'row2', 'row3'`)** represent the **index**.\n",
    "- **Inner dictionaries** represent **rows** in the DataFrame, with their keys being the column names.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Creating DataFrame from Dictionary with List of Lists (Nested Lists)**\n",
    "\n",
    "Sometimes, you may want to create a DataFrame from a dictionary where the values are lists, and each list represents a list of values for that column.\n",
    "\n",
    "#### **7.1 Example of Dictionary with List of Lists**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a dictionary with lists of lists\n",
    "data = {\n",
    "    'Name': ['John', 'Anna', 'Peter'],\n",
    "    'Age': [28, 24, 35],\n",
    "    'City': ['New York', 'Paris', 'Berlin']\n",
    "}\n",
    "\n",
    "# Creating a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    Name  Age      City\n",
    "0   John   28  New York\n",
    "1   Anna   24     Paris\n",
    "2  Peter   35    Berlin\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Summary of Key Points for Creating DataFrame from Dictionary**\n",
    "\n",
    "- **Basic Dictionary**: The keys become **column names** and the values become **column data**.\n",
    "- **Custom Index**: Use the `index` parameter to define custom row labels.\n",
    "- **Missing Data**: Pandas handles missing data by filling with `NaN`.\n",
    "- **Mixed Data Types**: Pandas automatically handles different data types in columns.\n",
    "- **Different Lengths**: If the columns have different lengths, missing values will be filled with `NaN`.\n",
    "- **Nested Dictionaries**: A nested dictionary can be used to define rows, and the outer keys represent the row labels.\n",
    "- **Lists of Lists**: Lists can be used as values in the dictionary to create DataFrames.\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Conclusion**\n",
    "\n",
    "Creating a **Pandas DataFrame from a dictionary** is a powerful and common approach to structuring data. This method allows for intuitive handling of tabular data, with automatic handling of various data types, missing values, and index alignment. It is particularly useful when working with structured data where column names and their associated values are clearly defined in a dictionary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Working with CSV Files in Python: All Concepts and Theory**\n",
    "\n",
    "In Python, **CSV (Comma Separated Values)** files are a common way of storing tabular data in plain text. Each line in a CSV file represents a row of data, and each value in the row is separated by commas (or other delimiters). Python provides several ways to interact with CSV files, and the most common and powerful library used for this purpose is **`csv`**. Other libraries, like **`pandas`**, also offer additional functionality when working with CSV files.\n",
    "\n",
    "Let's explore the core concepts and theory around working with CSV files in Python.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Basics of CSV Files**\n",
    "\n",
    "A **CSV file** consists of:\n",
    "\n",
    "- Rows of data.\n",
    "- Columns separated by commas (`,`), or other delimiters (like semicolons, tabs).\n",
    "- Text data is often enclosed in quotes (if commas are part of the data itself).\n",
    "\n",
    "Example of a CSV file (data.csv):\n",
    "\n",
    "```\n",
    "Name, Age, City\n",
    "John, 28, New York\n",
    "Anna, 24, Paris\n",
    "Peter, 35, Berlin\n",
    "```\n",
    "\n",
    "### **2. Reading CSV Files**\n",
    "\n",
    "#### **2.1 Using Python's `csv` Module**\n",
    "\n",
    "To read CSV files, Python’s built-in `csv` module is commonly used. The `csv.reader` method can be used to read the CSV file.\n",
    "\n",
    "```python\n",
    "import csv\n",
    "\n",
    "# Open the CSV file\n",
    "with open('data.csv', mode='r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "\n",
    "    # Reading each row\n",
    "    for row in csv_reader:\n",
    "        print(row)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "['Name', ' Age', ' City']\n",
    "['John', ' 28', ' New York']\n",
    "['Anna', ' 24', ' Paris']\n",
    "['Peter', ' 35', ' Berlin']\n",
    "```\n",
    "\n",
    "- `csv.reader(file)` reads the file and returns an iterator that will return each row as a list.\n",
    "- The rows are split by commas.\n",
    "- This method is useful for simple CSV reading.\n",
    "\n",
    "#### **2.2 Skipping Header Row**\n",
    "\n",
    "In some cases, the CSV file has a header row (column names), and you might want to skip it while reading data.\n",
    "\n",
    "```python\n",
    "import csv\n",
    "\n",
    "# Open the CSV file\n",
    "with open('data.csv', mode='r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "\n",
    "    # Skip the header row\n",
    "    next(csv_reader)\n",
    "\n",
    "    # Reading each row\n",
    "    for row in csv_reader:\n",
    "        print(row)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "['John', ' 28', ' New York']\n",
    "['Anna', ' 24', ' Paris']\n",
    "['Peter', ' 35', ' Berlin']\n",
    "```\n",
    "\n",
    "#### **2.3 Using `csv.DictReader` for Dictionary Format**\n",
    "\n",
    "To handle data in a more structured manner, you can use **`csv.DictReader`**, which reads each row as a dictionary with the header row as the keys.\n",
    "\n",
    "```python\n",
    "import csv\n",
    "\n",
    "# Open the CSV file\n",
    "with open('data.csv', mode='r') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "\n",
    "    # Reading each row as a dictionary\n",
    "    for row in csv_reader:\n",
    "        print(row)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "{'Name': 'John', ' Age': ' 28', ' City': ' New York'}\n",
    "{'Name': 'Anna', ' Age': ' 24', ' City': ' Paris'}\n",
    "{'Name': 'Peter', ' Age': ' 35', ' City': ' Berlin'}\n",
    "```\n",
    "\n",
    "- This approach makes it easier to refer to columns by name, such as `row['Name']` or `row['City']`.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Writing CSV Files**\n",
    "\n",
    "You can write to CSV files using the `csv.writer` or `csv.DictWriter` classes.\n",
    "\n",
    "#### **3.1 Writing Rows with `csv.writer`**\n",
    "\n",
    "```python\n",
    "import csv\n",
    "\n",
    "# Data to write\n",
    "data = [['Name', 'Age', 'City'],\n",
    "        ['John', 28, 'New York'],\n",
    "        ['Anna', 24, 'Paris'],\n",
    "        ['Peter', 35, 'Berlin']]\n",
    "\n",
    "# Open a CSV file in write mode\n",
    "with open('output.csv', mode='w', newline='') as file:\n",
    "    csv_writer = csv.writer(file)\n",
    "\n",
    "    # Writing rows\n",
    "    csv_writer.writerows(data)\n",
    "```\n",
    "\n",
    "- The `csv.writer(file)` writes data into the file.\n",
    "- `writerows(data)` writes multiple rows at once.\n",
    "- The `newline=''` ensures that no extra blank lines are added between rows.\n",
    "\n",
    "#### **3.2 Writing Rows with `csv.DictWriter`**\n",
    "\n",
    "If you're working with dictionaries, you can use `csv.DictWriter`, which allows you to write dictionaries to a CSV file.\n",
    "\n",
    "```python\n",
    "import csv\n",
    "\n",
    "# Data to write\n",
    "data = [\n",
    "    {'Name': 'John', 'Age': 28, 'City': 'New York'},\n",
    "    {'Name': 'Anna', 'Age': 24, 'City': 'Paris'},\n",
    "    {'Name': 'Peter', 'Age': 35, 'City': 'Berlin'}\n",
    "]\n",
    "\n",
    "# Field names (header)\n",
    "fields = ['Name', 'Age', 'City']\n",
    "\n",
    "# Open a CSV file in write mode\n",
    "with open('output_dict.csv', mode='w', newline='') as file:\n",
    "    csv_writer = csv.DictWriter(file, fieldnames=fields)\n",
    "\n",
    "    # Writing the header\n",
    "    csv_writer.writeheader()\n",
    "\n",
    "    # Writing data rows\n",
    "    csv_writer.writerows(data)\n",
    "```\n",
    "\n",
    "- `writeheader()` writes the header row using the dictionary keys.\n",
    "- `writerows(data)` writes the list of dictionaries.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Working with CSV Files Using `pandas`**\n",
    "\n",
    "For more advanced handling of CSV files, the **`pandas`** library provides more flexibility and features. Pandas can handle large datasets more efficiently and allows for data manipulation and analysis directly.\n",
    "\n",
    "#### **4.1 Reading CSV Files with Pandas**\n",
    "\n",
    "Pandas uses `pd.read_csv()` to read CSV files into a DataFrame.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Reading CSV file into DataFrame\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Displaying the DataFrame\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    Name  Age      City\n",
    "0   John   28  New York\n",
    "1   Anna   24     Paris\n",
    "2  Peter   35    Berlin\n",
    "```\n",
    "\n",
    "- The CSV file is automatically converted into a Pandas DataFrame, where each column becomes a **DataFrame column**.\n",
    "\n",
    "#### **4.2 Writing CSV Files with Pandas**\n",
    "\n",
    "You can use the **`to_csv()`** method to write a DataFrame back to a CSV file.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'Name': ['John', 'Anna', 'Peter'],\n",
    "        'Age': [28, 24, 35],\n",
    "        'City': ['New York', 'Paris', 'Berlin']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Writing DataFrame to a CSV file\n",
    "df.to_csv('output_pandas.csv', index=False)\n",
    "```\n",
    "\n",
    "- The `index=False` argument ensures that the index of the DataFrame is not written to the CSV file.\n",
    "- Pandas also handles more complex data types such as `NaN` values, mixed types, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Handling Delimiters and Other Variations**\n",
    "\n",
    "CSV files do not always use commas as delimiters. Some may use semicolons (`;`), tabs (`\\t`), or other characters. You can specify a delimiter in both the `csv` module and `pandas`.\n",
    "\n",
    "#### **5.1 Using a Custom Delimiter with `csv.reader`**\n",
    "\n",
    "```python\n",
    "import csv\n",
    "\n",
    "# Open the CSV file with a custom delimiter\n",
    "with open('data.csv', mode='r') as file:\n",
    "    csv_reader = csv.reader(file, delimiter=';')\n",
    "\n",
    "    # Reading each row\n",
    "    for row in csv_reader:\n",
    "        print(row)\n",
    "```\n",
    "\n",
    "#### **5.2 Using a Custom Delimiter with Pandas**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Reading a CSV file with semicolon as delimiter\n",
    "df = pd.read_csv('data.csv', delimiter=';')\n",
    "\n",
    "# Displaying the DataFrame\n",
    "print(df)\n",
    "```\n",
    "\n",
    "- `delimiter=';'` allows you to use semicolons instead of commas.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Additional CSV File Operations**\n",
    "\n",
    "#### **6.1 Handling Encoding**\n",
    "\n",
    "Sometimes, CSV files may have special characters that require specific encoding. You can specify encoding using the `encoding` parameter when reading or writing files.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Reading CSV with a specific encoding\n",
    "df = pd.read_csv('data.csv', encoding='utf-8')\n",
    "```\n",
    "\n",
    "#### **6.2 Handling Missing Data**\n",
    "\n",
    "Both the `csv` module and Pandas handle missing data (NaN values) in CSV files automatically. In Pandas, you can explicitly handle missing values using `na_values` or `fillna()`.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Reading a CSV and filling missing values with a default value\n",
    "df = pd.read_csv('data.csv', na_values=['NA', 'NULL'])\n",
    "df.fillna('Unknown', inplace=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Summary of Concepts**\n",
    "\n",
    "- **Reading CSV files**: Use `csv.reader` or `csv.DictReader` for simple reading. Use `pd.read_csv()` for more advanced handling.\n",
    "- **Writing CSV files**: Use `csv.writer` or `csv.DictWriter` for writing data from lists or dictionaries. Use `df.to_csv()` for writing DataFrames from Pandas.\n",
    "- **Custom delimiters**: Handle different delimiters such as semicolons, tabs, etc., by specifying the `delimiter` parameter.\n",
    "- **Missing Data**: Both the `csv` module and Pandas handle missing data, but Pandas offers more advanced options like `fillna()` and `dropna()`.\n",
    "- **Pandas advantages**: Use Pandas for advanced data manipulation, efficient handling of large datasets, and easier data analysis.\n",
    "\n",
    "By using the right tools (either `csv` or `pandas`), you can easily read, write, and manipulate CSV files in Python for various data analysis tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Working with Excel Files in Python: All Concepts and Theory**\n",
    "\n",
    "In Python, working with Excel files is a common task for data processing, analysis, and automation. The primary library used for interacting with Excel files is **`openpyxl`** for `.xlsx` files (Excel 2010 and later) and **`xlrd`** for `.xls` files (Excel 2003 and earlier). For advanced data manipulation, the **`pandas`** library can also be used to read and write Excel files, offering powerful tools for data analysis.\n",
    "\n",
    "### **Key Libraries for Working with Excel Files in Python**\n",
    "\n",
    "1. **`openpyxl`**: Used for reading and writing `.xlsx` files.\n",
    "2. **`xlrd`**: Used for reading `.xls` files (older format).\n",
    "3. **`pandas`**: A high-level library for working with data that can read and write both `.xlsx` and `.xls` files, often used for data analysis and manipulation.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Installing Libraries**\n",
    "\n",
    "Before using these libraries, you need to install them. Here's how to install them using `pip`:\n",
    "\n",
    "```bash\n",
    "pip install openpyxl  # For .xlsx files\n",
    "pip install xlrd  # For .xls files\n",
    "pip install pandas  # For working with both .xls and .xlsx files\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Working with Excel Files Using `openpyxl`**\n",
    "\n",
    "#### **2.1 Reading Excel Files with `openpyxl`**\n",
    "\n",
    "```python\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Load the workbook\n",
    "workbook = load_workbook('example.xlsx')\n",
    "\n",
    "# Select the active sheet\n",
    "sheet = workbook.active\n",
    "\n",
    "# Accessing a cell\n",
    "cell_value = sheet['A1'].value\n",
    "print(cell_value)\n",
    "\n",
    "# Accessing a specific row and column\n",
    "for row in sheet.iter_rows(min_row=2, max_row=5, min_col=1, max_col=3):\n",
    "    for cell in row:\n",
    "        print(cell.value)\n",
    "```\n",
    "\n",
    "**Key Points**:\n",
    "\n",
    "- **`load_workbook()`**: Loads an Excel workbook.\n",
    "- **`workbook.active`**: Accesses the active sheet.\n",
    "- **`sheet['A1'].value`**: Accesses the value in cell `A1`.\n",
    "- **`iter_rows()`**: Iterates through a specific range of rows and columns.\n",
    "\n",
    "#### **2.2 Writing Data to Excel**\n",
    "\n",
    "```python\n",
    "from openpyxl import Workbook\n",
    "\n",
    "# Create a new workbook and select the active sheet\n",
    "workbook = Workbook()\n",
    "sheet = workbook.active\n",
    "\n",
    "# Writing to a specific cell\n",
    "sheet['A1'] = 'Hello'\n",
    "sheet['A2'] = 'World'\n",
    "\n",
    "# Writing multiple rows and columns\n",
    "data = [\n",
    "    ['Name', 'Age', 'City'],\n",
    "    ['John', 28, 'New York'],\n",
    "    ['Anna', 24, 'Paris'],\n",
    "    ['Peter', 35, 'Berlin']\n",
    "]\n",
    "\n",
    "for row in data:\n",
    "    sheet.append(row)\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save('output.xlsx')\n",
    "```\n",
    "\n",
    "**Key Points**:\n",
    "\n",
    "- **`Workbook()`**: Creates a new workbook.\n",
    "- **`sheet.append(row)`**: Adds rows of data.\n",
    "- **`workbook.save()`**: Saves the workbook to a file.\n",
    "\n",
    "#### **2.3 Modifying Cells**\n",
    "\n",
    "```python\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Load the existing workbook\n",
    "workbook = load_workbook('example.xlsx')\n",
    "\n",
    "# Select a sheet\n",
    "sheet = workbook.active\n",
    "\n",
    "# Modify a specific cell\n",
    "sheet['A1'] = 'Updated Value'\n",
    "\n",
    "# Save the workbook with changes\n",
    "workbook.save('example_updated.xlsx')\n",
    "```\n",
    "\n",
    "**Key Points**:\n",
    "\n",
    "- You can directly assign values to specific cells and then save the workbook.\n",
    "\n",
    "#### **2.4 Formatting Cells**\n",
    "\n",
    "```python\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font, Color, PatternFill\n",
    "\n",
    "# Load the existing workbook\n",
    "workbook = load_workbook('example.xlsx')\n",
    "\n",
    "# Select a sheet\n",
    "sheet = workbook.active\n",
    "\n",
    "# Apply bold font to a cell\n",
    "sheet['A1'].font = Font(bold=True)\n",
    "\n",
    "# Apply background color to a cell\n",
    "sheet['A2'].fill = PatternFill(start_color='FFFF00', end_color='FFFF00', fill_type='solid')\n",
    "\n",
    "# Save the workbook with formatting\n",
    "workbook.save('formatted_example.xlsx')\n",
    "```\n",
    "\n",
    "**Key Points**:\n",
    "\n",
    "- **Font**: Can be used to apply formatting like bold, italic, underline, etc.\n",
    "- **PatternFill**: Used for filling cells with colors.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Working with Excel Files Using `pandas`**\n",
    "\n",
    "`pandas` is a powerful library for data manipulation and analysis. It provides simple methods to read and write Excel files directly into a `DataFrame`.\n",
    "\n",
    "#### **3.1 Reading Excel Files with `pandas`**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Reading an Excel file into a DataFrame\n",
    "df = pd.read_excel('example.xlsx')\n",
    "\n",
    "# Displaying the DataFrame\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Key Points**:\n",
    "\n",
    "- **`pd.read_excel()`**: Reads the Excel file into a `pandas` DataFrame.\n",
    "- By default, it reads the first sheet, but you can specify a sheet name.\n",
    "\n",
    "#### **3.2 Writing Data to Excel**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a DataFrame\n",
    "data = {\n",
    "    'Name': ['John', 'Anna', 'Peter'],\n",
    "    'Age': [28, 24, 35],\n",
    "    'City': ['New York', 'Paris', 'Berlin']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Writing the DataFrame to an Excel file\n",
    "df.to_excel('output_pandas.xlsx', index=False)\n",
    "```\n",
    "\n",
    "**Key Points**:\n",
    "\n",
    "- **`df.to_excel()`**: Writes the DataFrame to an Excel file.\n",
    "- The `index=False` argument prevents the index from being written.\n",
    "\n",
    "#### **3.3 Reading a Specific Sheet**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Reading a specific sheet from an Excel file\n",
    "df = pd.read_excel('example.xlsx', sheet_name='Sheet2')\n",
    "\n",
    "# Displaying the DataFrame\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Key Points**:\n",
    "\n",
    "- You can specify the `sheet_name` parameter to read a specific sheet.\n",
    "\n",
    "#### **3.4 Handling Multiple Sheets**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Reading multiple sheets from an Excel file into a dictionary of DataFrames\n",
    "dfs = pd.read_excel('example.xlsx', sheet_name=None)\n",
    "\n",
    "# Iterate over the sheets and print the DataFrame for each\n",
    "for sheet_name, df in dfs.items():\n",
    "    print(f\"Sheet: {sheet_name}\")\n",
    "    print(df)\n",
    "```\n",
    "\n",
    "**Key Points**:\n",
    "\n",
    "- **`sheet_name=None`**: Reads all sheets into a dictionary where keys are sheet names and values are DataFrames.\n",
    "\n",
    "#### **3.5 Working with Excel Files with Multiple Sheets (Writing)**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating DataFrames for multiple sheets\n",
    "df1 = pd.DataFrame({'Name': ['John', 'Anna'], 'Age': [28, 24]})\n",
    "df2 = pd.DataFrame({'Name': ['Peter'], 'Age': [35]})\n",
    "\n",
    "# Writing to an Excel file with multiple sheets\n",
    "with pd.ExcelWriter('multiple_sheets.xlsx') as writer:\n",
    "    df1.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "    df2.to_excel(writer, sheet_name='Sheet2', index=False)\n",
    "```\n",
    "\n",
    "**Key Points**:\n",
    "\n",
    "- **`pd.ExcelWriter()`**: Used to write multiple DataFrames to multiple sheets in a single Excel file.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Handling Excel Files with `xlrd` and `xlwt` (Older Formats)**\n",
    "\n",
    "If you need to work with older `.xls` files (Excel 2003 and earlier), you'll need to use **`xlrd`** for reading and **`xlwt`** for writing.\n",
    "\n",
    "#### **4.1 Reading `.xls` Files with `xlrd`**\n",
    "\n",
    "```python\n",
    "import xlrd\n",
    "\n",
    "# Open an existing .xls file\n",
    "workbook = xlrd.open_workbook('example.xls')\n",
    "\n",
    "# Select the first sheet\n",
    "sheet = workbook.sheet_by_index(0)\n",
    "\n",
    "# Accessing a cell\n",
    "cell_value = sheet.cell_value(0, 0)\n",
    "print(cell_value)\n",
    "```\n",
    "\n",
    "#### **4.2 Writing `.xls` Files with `xlwt`**\n",
    "\n",
    "```python\n",
    "import xlwt\n",
    "\n",
    "# Create a new workbook\n",
    "workbook = xlwt.Workbook()\n",
    "\n",
    "# Add a sheet\n",
    "sheet = workbook.add_sheet('Sheet1')\n",
    "\n",
    "# Write data to cells\n",
    "sheet.write(0, 0, 'Hello')\n",
    "sheet.write(1, 0, 'World')\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save('output.xls')\n",
    "```\n",
    "\n",
    "**Note**: `xlrd` and `xlwt` are used for handling `.xls` files (Excel 2003 and earlier). For `.xlsx` files, `openpyxl` and `pandas` are preferred.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Summary of Concepts**\n",
    "\n",
    "1. **Reading Excel Files**:\n",
    "\n",
    "   - Use **`openpyxl`** for `.xlsx` files, **`xlrd`** for `.xls` files, and **`pandas`** for both formats.\n",
    "   - **`openpyxl`**: Use `load_workbook()` to read `.xlsx` files, and access sheets with `workbook.active`.\n",
    "   - **`pandas`**: Use `pd.read_excel()` to read Excel files into DataFrames.\n",
    "\n",
    "2. **Writing Excel Files**:\n",
    "\n",
    "   - Use **`openpyxl`** or **`pandas`** to write data to `.xlsx` files.\n",
    "   - **`openpyxl`**: Use `sheet.append()` to add rows and `workbook.save()` to save the workbook.\n",
    "   - **`pandas`**: Use `df.to_excel()` to write DataFrames to Excel files.\n",
    "\n",
    "3. **Multiple Sheets**:\n",
    "\n",
    "   - Both **`openpyxl`** and **`pandas`** support writing and reading multiple sheets in Excel files.\n",
    "   - **`pandas`** makes handling multiple sheets simpler with the `sheet_name=None` option.\n",
    "\n",
    "4. **Formatting and Styling**:\n",
    "\n",
    "   - **`openpyxl`** allows for formatting cells with fonts, colors, and styles.\n",
    "   - **`pandas`** is used primarily for reading and writing data, but it doesn't directly handle cell formatting.\n",
    "\n",
    "5. **Advanced Operations**:\n",
    "   - **`openpyxl`** supports cell merging, adding charts, and more complex operations.\n",
    "   - **`pandas`** is ideal for manipulating large datasets once they are loaded into DataFrames.\n",
    "\n",
    "By understanding these concepts and libraries, you can efficiently work with Excel files in Python for a wide variety of tasks, including data analysis, automation, and reporting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **How to Work with Excel Files in Pandas: All Concepts and Theory**\n",
    "\n",
    "Pandas is one of the most popular libraries in Python for data manipulation, and it provides robust functionality for working with Excel files. In Pandas, you can read, write, and manipulate Excel files using built-in functions that make it easier to interact with Excel data.\n",
    "\n",
    "Here’s a comprehensive guide on how to work with Excel files in Pandas, including all key concepts, syntax, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Installing Necessary Libraries**\n",
    "\n",
    "Before you start working with Excel files in Pandas, you need to install `pandas` and `openpyxl`.\n",
    "\n",
    "The `openpyxl` library is used by Pandas to read and write `.xlsx` files. For `.xls` files (Excel 2003 and earlier), you will need to install `xlrd`.\n",
    "\n",
    "Use the following commands to install the required libraries:\n",
    "\n",
    "```bash\n",
    "pip install pandas\n",
    "pip install openpyxl  # for .xlsx files\n",
    "pip install xlrd  # for .xls files\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Reading Excel Files in Pandas**\n",
    "\n",
    "Pandas provides the function **`pd.read_excel()`** for reading Excel files. You can read data from both `.xls` and `.xlsx` files using this function.\n",
    "\n",
    "#### **2.1 Reading a Single Sheet**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Reading a single sheet from an Excel file\n",
    "df = pd.read_excel('example.xlsx')\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "- **`pd.read_excel()`** reads an Excel file into a Pandas DataFrame.\n",
    "- By default, it reads the first sheet of the Excel file.\n",
    "\n",
    "#### **2.2 Reading a Specific Sheet**\n",
    "\n",
    "You can specify the sheet you want to read by name or by index.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Reading a specific sheet by name\n",
    "df = pd.read_excel('example.xlsx', sheet_name='Sheet2')\n",
    "\n",
    "# Reading a sheet by index (0 for the first sheet)\n",
    "df = pd.read_excel('example.xlsx', sheet_name=0)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "- **`sheet_name`** can take either the sheet name (string) or the index (int).\n",
    "- If you don’t specify `sheet_name`, it defaults to the first sheet.\n",
    "\n",
    "#### **2.3 Reading All Sheets**\n",
    "\n",
    "If your Excel file contains multiple sheets, you can load all sheets at once into a dictionary of DataFrames.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Reading all sheets from an Excel file\n",
    "dfs = pd.read_excel('example.xlsx', sheet_name=None)\n",
    "\n",
    "# Print the names of the sheets and the first few rows of each sheet\n",
    "for sheet_name, df in dfs.items():\n",
    "    print(f\"Sheet name: {sheet_name}\")\n",
    "    print(df.head())\n",
    "```\n",
    "\n",
    "- **`sheet_name=None`** loads all sheets into a dictionary where keys are sheet names and values are DataFrames.\n",
    "\n",
    "#### **2.4 Handling Missing Data While Reading**\n",
    "\n",
    "Pandas allows you to handle missing data when reading Excel files.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Reading an Excel file and treating empty cells as NaN\n",
    "df = pd.read_excel('example.xlsx', na_values=[\"\", \"NA\", \"null\"])\n",
    "\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "- **`na_values`** allows you to specify additional values (such as empty strings or \"NA\") that should be treated as `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Writing Data to Excel Files**\n",
    "\n",
    "Pandas allows you to write DataFrames to Excel files using the **`df.to_excel()`** function.\n",
    "\n",
    "#### **3.1 Writing to a New Excel File**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {\n",
    "    'Name': ['John', 'Anna', 'Peter'],\n",
    "    'Age': [28, 24, 35],\n",
    "    'City': ['New York', 'Paris', 'Berlin']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df.to_excel('output.xlsx', index=False)\n",
    "```\n",
    "\n",
    "- **`index=False`** prevents the DataFrame index from being written to the Excel file.\n",
    "\n",
    "#### **3.2 Writing Multiple Sheets**\n",
    "\n",
    "You can write multiple DataFrames to different sheets in the same Excel file.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create two DataFrames\n",
    "df1 = pd.DataFrame({'Name': ['John', 'Anna'], 'Age': [28, 24]})\n",
    "df2 = pd.DataFrame({'Name': ['Peter'], 'Age': [35]})\n",
    "\n",
    "# Writing both DataFrames to separate sheets in one Excel file\n",
    "with pd.ExcelWriter('multiple_sheets.xlsx') as writer:\n",
    "    df1.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "    df2.to_excel(writer, sheet_name='Sheet2', index=False)\n",
    "```\n",
    "\n",
    "- **`pd.ExcelWriter()`** is used to create an Excel file with multiple sheets.\n",
    "\n",
    "#### **3.3 Writing to an Existing Excel File**\n",
    "\n",
    "You can append data to an existing Excel file by using the `openpyxl` engine.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a new DataFrame\n",
    "data = {'Name': ['Alice', 'Bob'], 'Age': [30, 25]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Append DataFrame to an existing Excel file\n",
    "with pd.ExcelWriter('existing_file.xlsx', engine='openpyxl', mode='a') as writer:\n",
    "    df.to_excel(writer, sheet_name='NewSheet', index=False)\n",
    "```\n",
    "\n",
    "- **`mode='a'`** opens the file in append mode to add new data.\n",
    "- **`engine='openpyxl'`** is required for `.xlsx` files.\n",
    "\n",
    "#### **3.4 Writing Excel with Formatted Data**\n",
    "\n",
    "While Pandas doesn’t directly support Excel formatting, you can write raw data using `pandas` and then use **`openpyxl`** to apply formatting afterward.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Working with Excel Files Using Pandas: Additional Concepts**\n",
    "\n",
    "#### **4.1 Reading and Writing Excel Files with Multiple Indexes**\n",
    "\n",
    "Pandas also supports Excel files with hierarchical row or column indexes.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a sample multi-index DataFrame\n",
    "arrays = [['A', 'A', 'B', 'B'], [1, 2, 1, 2]]\n",
    "index = pd.MultiIndex.from_arrays(arrays, names=('letter', 'number'))\n",
    "df = pd.DataFrame({'Value': [10, 20, 30, 40]}, index=index)\n",
    "\n",
    "# Writing the DataFrame with multi-level index to Excel\n",
    "df.to_excel('multi_index.xlsx')\n",
    "```\n",
    "\n",
    "- **`pd.MultiIndex`** creates multi-level indexing for rows or columns.\n",
    "\n",
    "#### **4.2 Using `openpyxl` for More Advanced Excel Features**\n",
    "\n",
    "If you need to perform more complex Excel operations such as styling, chart creation, or cell merging, you can use the `openpyxl` library. For example:\n",
    "\n",
    "```python\n",
    "from openpyxl import load_workbook\n",
    "import pandas as pd\n",
    "\n",
    "# Write DataFrame to Excel first\n",
    "df = pd.DataFrame({'Name': ['John', 'Anna', 'Peter'], 'Age': [28, 24, 35]})\n",
    "df.to_excel('output_with_style.xlsx', index=False)\n",
    "\n",
    "# Use openpyxl to style the Excel file\n",
    "wb = load_workbook('output_with_style.xlsx')\n",
    "ws = wb.active\n",
    "\n",
    "# Set the font color and size for the header\n",
    "from openpyxl.styles import Font\n",
    "ws['A1'].font = Font(color=\"FF0000\", size=12)\n",
    "\n",
    "wb.save('output_with_style.xlsx')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Handling Missing Data in Excel Files**\n",
    "\n",
    "When working with Excel files, there may be cases where some values are missing (represented as `NaN` in Pandas). You can clean and process these missing values in the following ways:\n",
    "\n",
    "#### **5.1 Dropping Rows or Columns with Missing Data**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Read data from Excel\n",
    "df = pd.read_excel('example.xlsx')\n",
    "\n",
    "# Drop rows with any missing values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Drop columns with missing values\n",
    "df_cleaned = df.dropna(axis=1)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(df_cleaned)\n",
    "```\n",
    "\n",
    "#### **5.2 Filling Missing Data**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Read data from Excel\n",
    "df = pd.read_excel('example.xlsx')\n",
    "\n",
    "# Fill missing values with a specified value\n",
    "df_filled = df.fillna('Unknown')\n",
    "\n",
    "# Fill missing values with the column mean\n",
    "df_filled = df.fillna(df.mean())\n",
    "\n",
    "# Display the filled DataFrame\n",
    "print(df_filled)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Advanced Excel Operations with Pandas**\n",
    "\n",
    "#### **6.1 Data Filtering and Sorting**\n",
    "\n",
    "You can filter and sort data in your Excel file directly in Pandas once it’s loaded into a DataFrame.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Read data from Excel\n",
    "df = pd.read_excel('example.xlsx')\n",
    "\n",
    "# Filter rows where age is greater than 30\n",
    "df_filtered = df[df['Age'] > 30]\n",
    "\n",
    "# Sort by Age in descending order\n",
    "df_sorted = df.sort_values(by='Age', ascending=False)\n",
    "\n",
    "# Display the results\n",
    "print(df_filtered)\n",
    "print(df_sorted)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Summary of Key Concepts**\n",
    "\n",
    "1. **Reading Excel Files**:\n",
    "\n",
    "   - **`pd.read_excel()`**: Reads Excel files into a Pandas DataFrame.\n",
    "   - **`sheet_name`**: Specifies which sheet(s) to read from the Excel file.\n",
    "\n",
    "2. **Writing to Excel Files**:\n",
    "\n",
    "   - **`df.to_excel()`**: Writes DataFrame to an Excel file.\n",
    "   - Supports writing to multiple sheets using `pd.ExcelWriter()`.\n",
    "\n",
    "3. **Handling Missing Data**:\n",
    "\n",
    "   - **`dropna()`**: Removes rows/columns with missing data.\n",
    "   - **`fillna()`**: Fills missing data with a specific value or statistical measure.\n",
    "\n",
    "4. **Multiple Sheets**:\n",
    "\n",
    "   - Use **`sheet_name=None`** to read multiple sheets into a dictionary of DataFrames.\n",
    "   - Use **`pd.ExcelWriter()`** to write multiple DataFrames to different sheets.\n",
    "\n",
    "5. **Advanced Operations**:\n",
    "   - Pandas provides tools for filtering, sorting, and cleaning data before exporting it to Excel.\n",
    "   - For complex formatting (e.g., styling, charts), use **`openpyxl`** alongside Pandas.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "Pandas makes it easy to interact with Excel files, whether you are reading data, writing new data, or performing data manipulations. By combining Pandas with other libraries like `openpyxl`, you can create powerful solutions for automating Excel file processing, analyzing data, and exporting results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **How to Work with JSON and SQL Files in Pandas: All Concepts and Theory**\n",
    "\n",
    "Pandas provides powerful tools to work with both **JSON** and **SQL** files, making it easy to load, process, manipulate, and export data. In this guide, we’ll explore how to interact with these two formats, covering all the key concepts, syntaxes, and examples for loading and working with JSON and SQL data in Pandas.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Working with JSON Files in Pandas**\n",
    "\n",
    "JSON (JavaScript Object Notation) is a widely used data format for representing structured data. Pandas makes it easy to work with JSON files by providing functions for reading and writing JSON data.\n",
    "\n",
    "---\n",
    "\n",
    "#### **1.1 Loading JSON Data**\n",
    "\n",
    "To load JSON data into a Pandas DataFrame, use the **`pd.read_json()`** function.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load JSON data from a file into a DataFrame\n",
    "df = pd.read_json('data.json')\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "- **`pd.read_json()`**: Reads JSON data and loads it into a Pandas DataFrame.\n",
    "- The JSON file can either be in **JSON array format** or **JSON object format**.\n",
    "  - **JSON array format**: Each entry in the array represents a row in the DataFrame.\n",
    "  - **JSON object format**: Key-value pairs are used where the key represents column names.\n",
    "\n",
    "#### **1.2 Loading JSON from a String**\n",
    "\n",
    "You can also load JSON data from a string using the same function:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# JSON data as a string\n",
    "json_string = '{\"name\":[\"John\", \"Anna\"], \"age\":[28, 24]}'\n",
    "\n",
    "# Load the JSON string into a DataFrame\n",
    "df = pd.read_json(json_string)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "```\n",
    "\n",
    "- **`pd.read_json()`** can handle JSON data from both files and strings.\n",
    "\n",
    "#### **1.3 Normalizing JSON Data (Nested JSON)**\n",
    "\n",
    "Often, JSON data can be deeply nested. To normalize such JSON data (convert it into a flat table), Pandas provides the **`json_normalize()`** function.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "\n",
    "# Sample nested JSON data\n",
    "nested_json = [\n",
    "    {\"name\": \"John\", \"location\": {\"city\": \"New York\", \"state\": \"NY\"}},\n",
    "    {\"name\": \"Anna\", \"location\": {\"city\": \"Paris\", \"state\": \"IDF\"}}\n",
    "]\n",
    "\n",
    "# Flatten the nested JSON data\n",
    "df = json_normalize(nested_json, sep='_')\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "```\n",
    "\n",
    "- **`json_normalize()`**: Flattens nested JSON objects into a tabular structure, making it easier to work with.\n",
    "\n",
    "#### **1.4 Writing Data to a JSON File**\n",
    "\n",
    "Once you have manipulated the data in a DataFrame, you can save it back to a JSON file using **`to_json()`**.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {'name': ['John', 'Anna'], 'age': [28, 24]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Write DataFrame to a JSON file\n",
    "df.to_json('output.json', orient='records', lines=True)\n",
    "```\n",
    "\n",
    "- **`orient='records'`**: Specifies that each row is written as a separate record in the JSON file.\n",
    "- **`lines=True`**: Writes JSON data in a line-by-line format, which is useful for large datasets.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Working with SQL Files in Pandas**\n",
    "\n",
    "SQL databases (such as MySQL, PostgreSQL, SQLite, etc.) store data in tables. Pandas offers a convenient way to interact with SQL databases by using the **`pd.read_sql()`** and **`to_sql()`** functions.\n",
    "\n",
    "#### **2.1 Installing SQL Libraries**\n",
    "\n",
    "You will need a library for connecting to SQL databases, such as **`sqlite3`** (for SQLite) or **`sqlalchemy`** (for a wide variety of databases).\n",
    "\n",
    "Install **`sqlalchemy`**:\n",
    "\n",
    "```bash\n",
    "pip install sqlalchemy\n",
    "```\n",
    "\n",
    "You may also need a specific connector for your database (like **`psycopg2`** for PostgreSQL, **`pymysql`** for MySQL).\n",
    "\n",
    "#### **2.2 Connecting to a SQL Database**\n",
    "\n",
    "Pandas uses the `SQLAlchemy` library (or a direct connection for SQLite) to establish a connection to an SQL database.\n",
    "\n",
    "##### **SQLite Example**\n",
    "\n",
    "```python\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Create a connection to the SQLite database (or create the file if it doesn't exist)\n",
    "conn = sqlite3.connect('example.db')\n",
    "\n",
    "# Read data from an SQL table into a DataFrame\n",
    "df = pd.read_sql('SELECT * FROM users', conn)\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "##### **MySQL/PostgreSQL Example Using SQLAlchemy**\n",
    "\n",
    "```python\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Create an SQLAlchemy engine for MySQL/PostgreSQL\n",
    "engine = create_engine('postgresql://username:password@localhost:5432/mydatabase')\n",
    "\n",
    "# Read data from an SQL query into a DataFrame\n",
    "df = pd.read_sql('SELECT * FROM users', engine)\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "- **`create_engine()`**: Establishes the connection to the SQL database.\n",
    "- **`pd.read_sql()`**: Executes an SQL query and returns the result as a DataFrame.\n",
    "\n",
    "#### **2.3 Executing SQL Queries**\n",
    "\n",
    "You can also use **`pd.read_sql_query()`** to execute an SQL query and load the results directly into a DataFrame.\n",
    "\n",
    "```python\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Create a connection to the SQLite database\n",
    "conn = sqlite3.connect('example.db')\n",
    "\n",
    "# Execute an SQL query to retrieve specific data\n",
    "df = pd.read_sql_query('SELECT name, age FROM users WHERE age > 30', conn)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "#### **2.4 Writing Data to a SQL Database**\n",
    "\n",
    "You can also write a DataFrame back to an SQL database using the **`to_sql()`** function.\n",
    "\n",
    "```python\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Create a connection to the SQLite database\n",
    "conn = sqlite3.connect('example.db')\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {'name': ['John', 'Anna'], 'age': [28, 24]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Write DataFrame to an SQL table (if the table doesn't exist, it will be created)\n",
    "df.to_sql('users', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Display confirmation\n",
    "print(\"Data inserted successfully.\")\n",
    "```\n",
    "\n",
    "- **`if_exists='replace'`**: If the table exists, replace it.\n",
    "- **`if_exists='append'`**: Append the DataFrame data to the existing table.\n",
    "\n",
    "#### **2.5 Handling SQL Databases with Complex Queries**\n",
    "\n",
    "You can use the `pd.read_sql()` and `pd.read_sql_query()` functions to work with complex SQL queries, including joins and filtering.\n",
    "\n",
    "```python\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Create a connection to the SQLite database\n",
    "conn = sqlite3.connect('example.db')\n",
    "\n",
    "# Example of an SQL JOIN query\n",
    "query = \"\"\"\n",
    "SELECT users.name, orders.order_date\n",
    "FROM users\n",
    "JOIN orders ON users.id = orders.user_id\n",
    "WHERE users.age > 30\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Handling Missing Data in SQL/JSON Files**\n",
    "\n",
    "When loading data from SQL or JSON files, you may encounter missing values. Pandas provides several methods to handle missing data.\n",
    "\n",
    "#### **3.1 Handling Missing Data in SQL**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Create a connection to the SQLite database\n",
    "conn = sqlite3.connect('example.db')\n",
    "\n",
    "# Read data from SQL into a DataFrame\n",
    "df = pd.read_sql('SELECT * FROM users', conn)\n",
    "\n",
    "# Fill missing values with a specific value\n",
    "df_filled = df.fillna('Unknown')\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(df_filled)\n",
    "```\n",
    "\n",
    "#### **3.2 Handling Missing Data in JSON**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load JSON data\n",
    "df = pd.read_json('data.json')\n",
    "\n",
    "# Fill missing values in the DataFrame\n",
    "df_filled = df.fillna('N/A')\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(df_filled)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Summary of Key Concepts**\n",
    "\n",
    "#### **Working with JSON Files in Pandas:**\n",
    "\n",
    "- **Reading JSON**: Use `pd.read_json()` to load JSON data into a DataFrame.\n",
    "- **Normalizing Nested JSON**: Use `json_normalize()` to flatten nested JSON objects into a table.\n",
    "- **Writing JSON**: Use `df.to_json()` to write DataFrames back to JSON files.\n",
    "\n",
    "#### **Working with SQL Files in Pandas:**\n",
    "\n",
    "- **Connecting to SQL**: Use `sqlite3.connect()` for SQLite or `SQLAlchemy` for other databases like MySQL, PostgreSQL.\n",
    "- **Reading SQL**: Use `pd.read_sql()` or `pd.read_sql_query()` to execute SQL queries and load data into a DataFrame.\n",
    "- **Writing SQL**: Use `df.to_sql()` to write DataFrames to SQL tables.\n",
    "\n",
    "#### **Missing Data**:\n",
    "\n",
    "- Use `fillna()` and `dropna()` to handle missing data in both JSON and SQL-based DataFrames.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "Pandas provides a rich set of functions for loading and manipulating data from both **JSON** and **SQL** sources. Whether you're working with nested JSON or complex SQL queries, Pandas can handle the job efficiently, allowing you to perform data analysis with ease. Integrating SQL databases or JSON data with Pandas workflows enables scalable data manipulation and processing for many different applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Accessing Data in Pandas DataFrame: All Concepts and Theory**\n",
    "\n",
    "Pandas provides various methods for accessing and manipulating data within a DataFrame. Understanding these techniques is essential for performing efficient data analysis. Below, we’ll cover the different ways to access data in a Pandas DataFrame, including how to select rows, columns, and subsets of data, and how to perform various operations.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Basic Concepts of DataFrame Access**\n",
    "\n",
    "A **DataFrame** in Pandas is a two-dimensional data structure with labeled axes (rows and columns). It’s similar to a table in a relational database or an Excel spreadsheet. DataFrames are composed of **rows** and **columns** that can be accessed in various ways, depending on the task.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Accessing Columns**\n",
    "\n",
    "You can access columns in a DataFrame in several ways:\n",
    "\n",
    "#### **2.1 Accessing a Single Column by Name**\n",
    "\n",
    "You can access a column using the column name as an attribute or by using dictionary-style indexing.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {'Name': ['John', 'Anna', 'Peter'],\n",
    "        'Age': [28, 24, 35],\n",
    "        'City': ['New York', 'Paris', 'Berlin']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Access a column by name using dot notation\n",
    "print(df.Name)\n",
    "\n",
    "# Access a column by name using dictionary-style indexing\n",
    "print(df['Age'])\n",
    "```\n",
    "\n",
    "- **Dot notation (`df.Name`)**: Works well for column names that are valid Python identifiers (e.g., no spaces, no starting with numbers).\n",
    "- **Dictionary-style indexing (`df['Age']`)**: Works for all column names, including those with spaces or special characters.\n",
    "\n",
    "#### **2.2 Accessing Multiple Columns**\n",
    "\n",
    "To select multiple columns, you need to pass a list of column names.\n",
    "\n",
    "```python\n",
    "# Access multiple columns by passing a list of column names\n",
    "print(df[['Name', 'City']])\n",
    "```\n",
    "\n",
    "#### **2.3 Accessing Columns with `iloc` and `loc`**\n",
    "\n",
    "You can also access columns using the `.iloc[]` and `.loc[]` indexers, which are used for row/column selection based on integer location and label, respectively.\n",
    "\n",
    "- **`iloc[]`**: Uses integer-based indexing (position-based).\n",
    "- **`loc[]`**: Uses label-based indexing (index/column names).\n",
    "\n",
    "```python\n",
    "# Access columns using iloc (by position)\n",
    "print(df.iloc[:, 1])  # Access the second column (Age)\n",
    "\n",
    "# Access columns using loc (by label)\n",
    "print(df.loc[:, 'City'])  # Access the 'City' column\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Accessing Rows**\n",
    "\n",
    "Rows in a DataFrame can be accessed using **integer-based indexing**, **label-based indexing**, or **conditions**.\n",
    "\n",
    "#### **3.1 Accessing Rows by Index with `iloc`**\n",
    "\n",
    "The `.iloc[]` indexer allows you to select rows based on their integer index.\n",
    "\n",
    "```python\n",
    "# Access the first row using iloc\n",
    "print(df.iloc[0])  # First row\n",
    "\n",
    "# Access multiple rows (first and second)\n",
    "print(df.iloc[0:2])  # Rows 0 and 1\n",
    "```\n",
    "\n",
    "#### **3.2 Accessing Rows by Label with `loc`**\n",
    "\n",
    "The `.loc[]` indexer is used when you want to select rows based on their label (index name).\n",
    "\n",
    "```python\n",
    "# Create a DataFrame with custom index labels\n",
    "df = pd.DataFrame(data, index=['a', 'b', 'c'])\n",
    "\n",
    "# Access the row with label 'a'\n",
    "print(df.loc['a'])\n",
    "\n",
    "# Access multiple rows with labels 'a' and 'b'\n",
    "print(df.loc[['a', 'b']])\n",
    "```\n",
    "\n",
    "#### **3.3 Accessing Rows by Condition**\n",
    "\n",
    "You can also access rows based on certain conditions using **boolean indexing**.\n",
    "\n",
    "```python\n",
    "# Access rows where the 'Age' column is greater than 30\n",
    "print(df[df['Age'] > 30])\n",
    "\n",
    "# Access rows where 'City' is 'Paris'\n",
    "print(df[df['City'] == 'Paris'])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Accessing Specific Elements (Cell)**\n",
    "\n",
    "To access a specific element or cell, you can use a combination of **row and column indices** with either `.iloc[]` (integer-based) or `.loc[]` (label-based).\n",
    "\n",
    "#### **4.1 Using `iloc[]` for Row and Column Indices**\n",
    "\n",
    "```python\n",
    "# Access a specific cell (row 0, column 1)\n",
    "print(df.iloc[0, 1])  # First row, second column (Age)\n",
    "\n",
    "# Access a specific cell (row 2, column 0)\n",
    "print(df.iloc[2, 0])  # Third row, first column (Name)\n",
    "```\n",
    "\n",
    "#### **4.2 Using `loc[]` for Label-Based Indexing**\n",
    "\n",
    "```python\n",
    "# Access a specific cell (label 'a' and column 'Age')\n",
    "print(df.loc['a', 'Age'])  # Row with label 'a', column 'Age'\n",
    "\n",
    "# Access a specific cell (label 'b' and column 'City')\n",
    "print(df.loc['b', 'City'])  # Row with label 'b', column 'City'\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Slicing Data**\n",
    "\n",
    "Pandas allows for **slicing** to extract portions of the DataFrame.\n",
    "\n",
    "#### **5.1 Slicing Rows**\n",
    "\n",
    "To slice rows, you can use `.iloc[]` or `.loc[]`. This is useful when you want to select a subset of rows.\n",
    "\n",
    "```python\n",
    "# Using iloc to slice rows (first 2 rows)\n",
    "print(df.iloc[:2])\n",
    "\n",
    "# Using loc to slice rows by label (from 'a' to 'b')\n",
    "print(df.loc['a':'b'])\n",
    "```\n",
    "\n",
    "#### **5.2 Slicing Rows and Columns Together**\n",
    "\n",
    "You can also slice both rows and columns together to extract specific parts of the DataFrame.\n",
    "\n",
    "```python\n",
    "# Slice the first 2 rows and the first 2 columns using iloc\n",
    "print(df.iloc[:2, :2])\n",
    "\n",
    "# Slice rows 'a' and 'b' and columns 'Name' and 'City' using loc\n",
    "print(df.loc['a':'b', ['Name', 'City']])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Accessing Data Using `at[]` and `iat[]`**\n",
    "\n",
    "For fast access to a single element, use **`at[]`** (label-based) and **`iat[]`** (integer-based) indexers.\n",
    "\n",
    "#### **6.1 Using `at[]` for Label-Based Access**\n",
    "\n",
    "```python\n",
    "# Access a single element using at[] (row 'a', column 'Age')\n",
    "print(df.at['a', 'Age'])  # Label-based access\n",
    "```\n",
    "\n",
    "#### **6.2 Using `iat[]` for Integer-Based Access**\n",
    "\n",
    "```python\n",
    "# Access a single element using iat[] (row 0, column 1)\n",
    "print(df.iat[0, 1])  # Integer-based access\n",
    "```\n",
    "\n",
    "These methods are faster than using `.loc[]` and `.iloc[]` for a single element.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Accessing Data Using `query()`**\n",
    "\n",
    "The `query()` function allows you to access data based on SQL-like expressions. This is particularly useful for filtering data.\n",
    "\n",
    "```python\n",
    "# Access rows where Age is greater than 30 using query()\n",
    "result = df.query('Age > 30')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Sorting and Ranking Data**\n",
    "\n",
    "You can also access data in a sorted or ranked order.\n",
    "\n",
    "#### **8.1 Sorting Rows by Column Values**\n",
    "\n",
    "To sort rows based on the values of a column, use the `sort_values()` method.\n",
    "\n",
    "```python\n",
    "# Sort by Age in ascending order\n",
    "sorted_df = df.sort_values(by='Age', ascending=True)\n",
    "print(sorted_df)\n",
    "```\n",
    "\n",
    "#### **8.2 Sorting Rows by Index**\n",
    "\n",
    "To sort by the index, use the `sort_index()` method.\n",
    "\n",
    "```python\n",
    "# Sort by the index (default is ascending order)\n",
    "sorted_by_index = df.sort_index(ascending=False)\n",
    "print(sorted_by_index)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Accessing Data with `.apply()`**\n",
    "\n",
    "The `.apply()` method can be used to access and manipulate data by applying a function to the rows or columns.\n",
    "\n",
    "```python\n",
    "# Apply a function to each element in the 'Age' column\n",
    "df['Age_plus_10'] = df['Age'].apply(lambda x: x + 10)\n",
    "\n",
    "# Apply a function to each row (axis=1 means apply across columns)\n",
    "df['Name_and_Age'] = df.apply(lambda row: f\"{row['Name']} - {row['Age']}\", axis=1)\n",
    "print(df)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Summary of Key Concepts**\n",
    "\n",
    "- **Accessing Columns**: Use `df['column_name']` or `df.column_name` for single columns; `df[['col1', 'col2']]` for multiple columns.\n",
    "- **Accessing Rows**: Use `.iloc[]` for integer-based row selection, `.loc[]` for label-based row selection, or boolean indexing for condition-based row selection.\n",
    "- **Accessing Specific Elements**: Use `.iloc[]` and `.loc[]` to access a specific cell; use `.at[]` and `.iat[]` for faster single-element access.\n",
    "- **Slicing Data**: Use `.iloc[]` and `.loc[]` for slicing rows and columns.\n",
    "- **Applying Functions**: Use `.apply()` to apply custom functions to rows or columns.\n",
    "- **Sorting**: Use `.sort_values()` to sort data based on columns and `.sort_index()` to sort by index.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "Accessing and manipulating data within a Pandas DataFrame is a core skill for data analysis. Understanding the variety of ways to select, slice, and filter data allows for efficient and effective data processing. Whether you're accessing specific rows, columns, or cells, or applying transformations across your DataFrame, Pandas provides a wide range of powerful tools to manage and analyze data effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Modifying DataFrames in Pandas: All Concepts and Theory**\n",
    "\n",
    "Pandas provides powerful tools for modifying and manipulating DataFrames. Whether you're adding, removing, or updating data, there are various ways to alter the structure and values in a DataFrame. Below is a comprehensive guide to the different techniques available for modifying DataFrames in Pandas.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Adding Data to DataFrame**\n",
    "\n",
    "#### **1.1 Adding Columns**\n",
    "\n",
    "You can add new columns to a DataFrame by simply assigning a new column name with values.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {'Name': ['John', 'Anna', 'Peter'],\n",
    "        'Age': [28, 24, 35]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Add a new column with a constant value\n",
    "df['City'] = ['New York', 'Paris', 'Berlin']\n",
    "\n",
    "# Add a new column with calculated values\n",
    "df['Age_in_5_Years'] = df['Age'] + 5\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "- **Note**: You can add a column with a list, series, or even with a function that performs calculations based on other columns.\n",
    "\n",
    "#### **1.2 Adding Rows (Appends)**\n",
    "\n",
    "To add a row to a DataFrame, you can use the `loc[]` indexer, or the `append()` function (though it is deprecated in newer versions of Pandas, `concat()` is the recommended method).\n",
    "\n",
    "```python\n",
    "# Add a row using loc[]\n",
    "df.loc[3] = ['Sara', 22, 'London', 27]\n",
    "\n",
    "# Add a row using concat() (preferred method)\n",
    "new_row = pd.DataFrame({'Name': ['Sara'], 'Age': [22], 'City': ['London'], 'Age_in_5_Years': [27]})\n",
    "df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "- **Note**: When appending rows using `concat()`, make sure both DataFrames have the same columns. `ignore_index=True` reindexes the rows.\n",
    "\n",
    "#### **1.3 Adding Columns with `insert()`**\n",
    "\n",
    "The `insert()` method allows you to insert a new column at a specific position in the DataFrame.\n",
    "\n",
    "```python\n",
    "# Insert a column at position 1 (second position)\n",
    "df.insert(1, 'Gender', ['M', 'F', 'M', 'F'])\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Modifying Data in DataFrame**\n",
    "\n",
    "#### **2.1 Modifying Existing Columns**\n",
    "\n",
    "You can modify the values of an existing column by reassigning the column.\n",
    "\n",
    "```python\n",
    "# Modify the 'Age' column\n",
    "df['Age'] = df['Age'] + 1  # Increment each age by 1\n",
    "\n",
    "# Modify multiple columns\n",
    "df[['Age', 'Age_in_5_Years']] = df[['Age', 'Age_in_5_Years']].apply(lambda x: x + 2)\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "- **Note**: You can apply any function or operation to modify the values in a column.\n",
    "\n",
    "#### **2.2 Modifying Cells Using `at[]` and `iat[]`**\n",
    "\n",
    "- **`at[]`**: Used for fast access and modification of a single value (label-based).\n",
    "- **`iat[]`**: Used for fast access and modification of a single value (integer position-based).\n",
    "\n",
    "```python\n",
    "# Modify a single cell using at[]\n",
    "df.at[1, 'Age'] = 25  # Modify the 'Age' of the second row\n",
    "\n",
    "# Modify a single cell using iat[]\n",
    "df.iat[2, 3] = 40  # Modify the 'Age_in_5_Years' of the third row\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Removing Data from DataFrame**\n",
    "\n",
    "#### **3.1 Removing Columns with `drop()`**\n",
    "\n",
    "To remove a column from a DataFrame, use the `drop()` method.\n",
    "\n",
    "```python\n",
    "# Remove a column\n",
    "df = df.drop('Gender', axis=1)\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "- **`axis=1`** indicates that you are dropping a column. To drop a row, set `axis=0`.\n",
    "\n",
    "#### **3.2 Removing Rows with `drop()`**\n",
    "\n",
    "To remove rows, you can also use the `drop()` method. Specify the index or label of the row you want to remove.\n",
    "\n",
    "```python\n",
    "# Remove a row by index\n",
    "df = df.drop(0, axis=0)  # Remove the first row\n",
    "\n",
    "# Remove rows by condition (boolean indexing)\n",
    "df = df[df['Age'] > 25]\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "- **`axis=0`** indicates that you are dropping rows.\n",
    "\n",
    "#### **3.3 Removing Duplicates**\n",
    "\n",
    "You can remove duplicate rows based on one or more columns using the `drop_duplicates()` method.\n",
    "\n",
    "```python\n",
    "# Remove duplicate rows\n",
    "df = df.drop_duplicates(subset=['Age'])\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "#### **3.4 Dropping NaN Values**\n",
    "\n",
    "You can remove rows or columns containing `NaN` (missing) values using `dropna()`.\n",
    "\n",
    "```python\n",
    "# Drop rows with any NaN values\n",
    "df = df.dropna()\n",
    "\n",
    "# Drop columns with any NaN values\n",
    "df = df.dropna(axis=1)\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "- **`axis=0`** drops rows; **`axis=1`** drops columns.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Renaming Data in DataFrame**\n",
    "\n",
    "#### **4.1 Renaming Columns with `rename()`**\n",
    "\n",
    "You can rename columns using the `rename()` method.\n",
    "\n",
    "```python\n",
    "# Rename columns\n",
    "df = df.rename(columns={'Age': 'Current_Age', 'City': 'Location'})\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "- **`columns`** argument takes a dictionary where the keys are the old column names and the values are the new column names.\n",
    "\n",
    "#### **4.2 Renaming Index Labels**\n",
    "\n",
    "You can also rename row indices (index labels) using `rename()`.\n",
    "\n",
    "```python\n",
    "# Rename index labels\n",
    "df = df.rename(index={0: 'row_1', 1: 'row_2'})\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Replacing Data in DataFrame**\n",
    "\n",
    "#### **5.1 Replacing Specific Values with `replace()`**\n",
    "\n",
    "The `replace()` method allows you to replace values in the DataFrame.\n",
    "\n",
    "```python\n",
    "# Replace a specific value\n",
    "df['Location'] = df['Location'].replace('London', 'Tokyo')\n",
    "\n",
    "# Replace multiple values\n",
    "df = df.replace({'Location': {'Tokyo': 'Paris'}, 'Age': {25: 26}})\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "#### **5.2 Replacing NaN Values with `fillna()`**\n",
    "\n",
    "To replace missing values (`NaN`), use the `fillna()` method.\n",
    "\n",
    "```python\n",
    "# Replace NaN values with a specific value\n",
    "df = df.fillna({'Age': 30, 'Location': 'Unknown'})\n",
    "\n",
    "# Replace NaN with forward fill or backward fill\n",
    "df = df.fillna(method='ffill')  # Forward fill\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "- **`method='ffill'`** fills missing values using the last valid value.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Changing Data Types**\n",
    "\n",
    "You can change the data type of a column using the `astype()` method.\n",
    "\n",
    "```python\n",
    "# Convert a column to a different data type\n",
    "df['Age'] = df['Age'].astype(float)\n",
    "\n",
    "# Convert multiple columns\n",
    "df[['Age', 'Age_in_5_Years']] = df[['Age', 'Age_in_5_Years']].astype(int)\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "- **`astype()`** allows you to cast columns to any valid Pandas data type, such as `int`, `float`, `str`, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Working with Index**\n",
    "\n",
    "#### **7.1 Setting a New Index**\n",
    "\n",
    "You can set one of the columns as the DataFrame’s index using the `set_index()` method.\n",
    "\n",
    "```python\n",
    "# Set 'Name' as the index\n",
    "df = df.set_index('Name')\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "#### **7.2 Resetting the Index**\n",
    "\n",
    "You can reset the index using the `reset_index()` method, which converts the index back to a column.\n",
    "\n",
    "```python\n",
    "# Reset the index to default integer index\n",
    "df = df.reset_index()\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "- **`drop=True`** in `reset_index()` can be used if you don’t want to keep the old index as a column.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Sorting Data in DataFrame**\n",
    "\n",
    "#### **8.1 Sorting by Values**\n",
    "\n",
    "To sort by the values of one or more columns, use `sort_values()`.\n",
    "\n",
    "```python\n",
    "# Sort by 'Age' in ascending order\n",
    "df = df.sort_values(by='Age')\n",
    "\n",
    "# Sort by multiple columns\n",
    "df = df.sort_values(by=['Location', 'Age'], ascending=[True, False])\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "#### **8.2 Sorting by Index**\n",
    "\n",
    "To sort by the index (row labels), use `sort_index()`.\n",
    "\n",
    "```python\n",
    "# Sort by index\n",
    "df = df.sort_index()\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Applying Functions on DataFrame**\n",
    "\n",
    "You can apply functions to the entire DataFrame or to individual columns using the `apply()` function.\n",
    "\n",
    "```python\n",
    "# Apply a function to a column\n",
    "df['Age'] = df['Age'].apply(lambda x: x * 2)  # Double the age\n",
    "\n",
    "# Apply a function to each row\n",
    "df['Age_Description'] = df.apply(lambda row: 'Old' if row['Age'] > 50 else 'Young', axis=1)\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Conclusion**\n",
    "\n",
    "- **Adding Data**: You can add new rows, columns, or use `insert()` to add columns at specific positions.\n",
    "- **Modifying Data**: Modify data using direct assignment, `.apply()`, or element access methods like `.at[]` and `.iat[]`.\n",
    "- **Removing Data**: Remove rows and columns using `drop()`, remove duplicates with `drop_duplicates()`, and handle missing data with `dropna()` or `fillna()`.\n",
    "- **Renaming Data**: Rename columns and indices with `rename()`.\n",
    "- **Replacing Data**: Use `replace()` to replace specific values, and `fillna()` for missing values.\n",
    "- **Type Conversion**: Convert data types using `astype()`.\n",
    "- **Index Management**: Set and reset indices with `set_index()` and `reset_index()`.\n",
    "- **Sorting Data**: Use `sort_values()` and `sort_index()` to reorder data.\n",
    "- **Applying Functions**: Apply custom functions to rows or columns with `.apply()`.\n",
    "\n",
    "By mastering these techniques, you'll be able to efficiently modify and manipulate data within your Pandas DataFrames.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Handling Missing Values in Pandas**\n",
    "\n",
    "Handling missing or **NaN (Not a Number)** values is a crucial aspect of data cleaning in any data analysis task. Pandas provides various methods and techniques to detect, fill, replace, or drop missing values. In this section, we will explore various strategies and methods for handling missing values in Pandas DataFrames.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Identifying Missing Values**\n",
    "\n",
    "The first step in dealing with missing values is identifying where they are in your dataset. In Pandas, missing values are represented by `NaN` (Not a Number) or `None` for object data types.\n",
    "\n",
    "#### **1.1 Checking for Missing Values with `isna()` or `isnull()`**\n",
    "\n",
    "The `isna()` (or `isnull()`) function returns a DataFrame of the same shape as the original, with `True` for positions that have missing values and `False` for those that do not.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame with missing values\n",
    "data = {'Name': ['Alice', 'Bob', None, 'David'],\n",
    "        'Age': [24, None, 23, 30],\n",
    "        'Country': ['USA', None, 'Canada', 'UK']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isna())\n",
    "```\n",
    "\n",
    "- **`isna()`** or **`isnull()`**: Both are used interchangeably in Pandas to identify missing values.\n",
    "\n",
    "#### **1.2 Summarizing Missing Values with `sum()`**\n",
    "\n",
    "To quickly get the count of missing values per column, you can use `sum()` after applying `isna()`.\n",
    "\n",
    "```python\n",
    "# Get count of missing values in each column\n",
    "print(df.isna().sum())\n",
    "```\n",
    "\n",
    "- **`sum()`**: This will return the count of `True` values (i.e., the number of missing values) for each column.\n",
    "\n",
    "#### **1.3 Checking for Any Missing Values with `any()`**\n",
    "\n",
    "You can check if any missing values exist in the entire DataFrame or specific columns.\n",
    "\n",
    "```python\n",
    "# Check if there are any missing values in the entire DataFrame\n",
    "print(df.isna().any())\n",
    "\n",
    "# Check for missing values in a specific column\n",
    "print(df['Age'].isna().any())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Handling Missing Values**\n",
    "\n",
    "After identifying missing values, the next step is to decide how to handle them. There are several strategies you can use, such as filling, replacing, or dropping missing values.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2.1 Removing Missing Values**\n",
    "\n",
    "Removing rows or columns with missing values is one common approach when handling missing data. This can be done using the `dropna()` method.\n",
    "\n",
    "##### **2.1.1 Dropping Rows with Missing Values**\n",
    "\n",
    "You can drop rows that contain missing values using `dropna()`.\n",
    "\n",
    "```python\n",
    "# Drop rows with any missing values\n",
    "df_dropped_rows = df.dropna()\n",
    "\n",
    "print(df_dropped_rows)\n",
    "```\n",
    "\n",
    "- **`dropna()`**: By default, it drops any row that contains at least one missing value.\n",
    "\n",
    "##### **2.1.2 Dropping Columns with Missing Values**\n",
    "\n",
    "If you want to drop columns that have missing values, set the `axis` parameter to `1`.\n",
    "\n",
    "```python\n",
    "# Drop columns with any missing values\n",
    "df_dropped_columns = df.dropna(axis=1)\n",
    "\n",
    "print(df_dropped_columns)\n",
    "```\n",
    "\n",
    "- **`axis=1`**: This tells Pandas to drop columns instead of rows.\n",
    "\n",
    "##### **2.1.3 Dropping Rows or Columns with All Missing Values**\n",
    "\n",
    "You can use the `how` parameter to specify that only rows or columns with all missing values should be dropped.\n",
    "\n",
    "```python\n",
    "# Drop rows where all values are missing\n",
    "df_dropped_all_rows = df.dropna(how='all')\n",
    "\n",
    "# Drop columns where all values are missing\n",
    "df_dropped_all_columns = df.dropna(axis=1, how='all')\n",
    "\n",
    "print(df_dropped_all_rows)\n",
    "print(df_dropped_all_columns)\n",
    "```\n",
    "\n",
    "- **`how='all'`**: Only drops rows or columns where **all** values are missing.\n",
    "- **`how='any'`**: (default) Drops rows or columns with **any** missing values.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2.2 Filling Missing Values**\n",
    "\n",
    "Instead of dropping missing values, you may choose to fill them with some default value, such as the mean, median, mode, or a constant.\n",
    "\n",
    "##### **2.2.1 Filling Missing Values with a Constant**\n",
    "\n",
    "You can fill missing values with a specific value using `fillna()`.\n",
    "\n",
    "```python\n",
    "# Fill missing values with a constant value\n",
    "df_filled_constant = df.fillna({'Age': 25, 'Country': 'Unknown'})\n",
    "\n",
    "print(df_filled_constant)\n",
    "```\n",
    "\n",
    "- **`fillna(value)`**: Fills missing values with the provided constant value.\n",
    "\n",
    "##### **2.2.2 Filling Missing Values with the Mean, Median, or Mode**\n",
    "\n",
    "Filling missing values with a statistical measure like the mean, median, or mode is common when dealing with numerical data.\n",
    "\n",
    "```python\n",
    "# Fill missing values in 'Age' with the mean of the column\n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "\n",
    "# Fill missing values in 'Country' with the mode (most frequent value)\n",
    "df['Country'] = df['Country'].fillna(df['Country'].mode()[0])\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "- **`df['Age'].mean()`**: Computes the mean of the column.\n",
    "- **`df['Country'].mode()[0]`**: Returns the mode of the column (most frequent value).\n",
    "\n",
    "##### **2.2.3 Forward Fill or Backward Fill**\n",
    "\n",
    "Sometimes you may want to fill missing values with the previous or next valid value.\n",
    "\n",
    "```python\n",
    "# Forward fill missing values (fill with the previous value)\n",
    "df_filled_ffill = df.fillna(method='ffill')\n",
    "\n",
    "# Backward fill missing values (fill with the next value)\n",
    "df_filled_bfill = df.fillna(method='bfill')\n",
    "\n",
    "print(df_filled_ffill)\n",
    "print(df_filled_bfill)\n",
    "```\n",
    "\n",
    "- **`method='ffill'`**: Fills missing values with the previous non-null value.\n",
    "- **`method='bfill'`**: Fills missing values with the next non-null value.\n",
    "\n",
    "##### **2.2.4 Interpolating Missing Values**\n",
    "\n",
    "You can also use interpolation to fill missing values. Interpolation estimates missing values based on the surrounding data.\n",
    "\n",
    "```python\n",
    "# Interpolate missing values (linear interpolation by default)\n",
    "df_interpolated = df.interpolate()\n",
    "\n",
    "print(df_interpolated)\n",
    "```\n",
    "\n",
    "- **`interpolate()`**: By default, it uses linear interpolation for numeric columns.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2.3 Replacing Missing Values with Specific Conditions**\n",
    "\n",
    "In some cases, you may want to replace missing values with values based on certain conditions or logic.\n",
    "\n",
    "```python\n",
    "# Replace missing values in 'Age' with 30 if the missing value is in the 'Age' column\n",
    "df['Age'] = df['Age'].apply(lambda x: 30 if pd.isna(x) else x)\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "- **`apply(lambda x)`**: Applies a custom function to fill missing values based on conditions.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Advanced Handling Techniques**\n",
    "\n",
    "While the previous methods cover basic missing value handling, there are a few more advanced techniques that can be helpful in more complex situations.\n",
    "\n",
    "#### **3.1 Using `fillna()` with Multiple Columns**\n",
    "\n",
    "You can fill missing values in specific columns by passing a dictionary where the key is the column name and the value is the fill value.\n",
    "\n",
    "```python\n",
    "# Fill missing values with specific values for each column\n",
    "df_filled_columns = df.fillna({'Age': 30, 'Country': 'Not Provided'})\n",
    "\n",
    "print(df_filled_columns)\n",
    "```\n",
    "\n",
    "#### **3.2 Using `bfill` and `ffill` Across Rows**\n",
    "\n",
    "If you want to apply forward or backward filling across rows, you can set `axis=1`.\n",
    "\n",
    "```python\n",
    "# Forward fill across rows\n",
    "df_filled_row_ffill = df.fillna(method='ffill', axis=1)\n",
    "\n",
    "# Backward fill across rows\n",
    "df_filled_row_bfill = df.fillna(method='bfill', axis=1)\n",
    "\n",
    "print(df_filled_row_ffill)\n",
    "print(df_filled_row_bfill)\n",
    "```\n",
    "\n",
    "#### **3.3 Handling Missing Values in Time Series Data**\n",
    "\n",
    "For time series data, you may want to perform more complex interpolations or fill missing values in a way that maintains trends or seasonal patterns. Pandas has specific handling for time series data that can be done using methods like `.resample()` and `.asfreq()`.\n",
    "\n",
    "```python\n",
    "# Example of resampling time series data and filling missing values\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Resample and fill missing values\n",
    "df_resampled = df.resample('D').mean().fillna(method='ffill')\n",
    "\n",
    "print(df_resampled)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "Handling missing values is an essential part of data preprocessing. Here’s a quick summary of the common techniques for dealing with missing values in Pandas:\n",
    "\n",
    "1. **Identifying Missing Values**:\n",
    "\n",
    "   - `isna()` or `isnull()`: Detect missing values.\n",
    "   - `sum()`: Count missing values in each column.\n",
    "   - `any()`: Check if there are any missing values.\n",
    "\n",
    "2. **Removing Missing Values**:\n",
    "\n",
    "   - `dropna()`: Remove rows or columns with missing values.\n",
    "   - `dropna(how='all')`: Drop rows or columns where all values are missing.\n",
    "\n",
    "3. **Filling Missing Values**:\n",
    "\n",
    "   - `fillna(value)`: Fill missing values with a constant or computed value (mean, median, mode).\n",
    "   - `fillna(method='ffill')`: Forward fill missing values.\n",
    "   - `fillna(method='bfill')`: Backward fill missing values.\n",
    "   - `interpolate()`: Use interpolation to estimate missing values.\n",
    "\n",
    "4. **Advanced Techniques**:\n",
    "   - Fill missing values with specific logic using `apply()`.\n",
    "   - Handle time series data with resampling and forward/backward filling.\n",
    "\n",
    "By mastering these techniques, you can handle missing values effectively, ensuring the quality and consistency of your dataset for further analysis or modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sorting and Ordering in Python**\n",
    "\n",
    "Sorting and ordering are fundamental concepts in data manipulation and are critical for organizing data in a desired sequence. In Python, sorting can be performed on various data structures like lists, tuples, and even more complex data types such as Pandas DataFrames. Below is a comprehensive explanation of sorting and ordering in Python.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Sorting in Python**\n",
    "\n",
    "Sorting refers to arranging data in a specific order. By default, Python sorts data in **ascending** order, but it can also sort in **descending** order if specified.\n",
    "\n",
    "#### **1.1 Sorting Lists**\n",
    "\n",
    "In Python, lists can be sorted using two primary methods:\n",
    "\n",
    "- **`sorted()` function**\n",
    "- **`list.sort()` method**\n",
    "\n",
    "##### **1.1.1 `sorted()` Function**\n",
    "\n",
    "The `sorted()` function returns a new sorted list from the elements of any iterable (e.g., list, tuple, string, dictionary, etc.). It does not modify the original data.\n",
    "\n",
    "```python\n",
    "# Example: Sorting a list using sorted()\n",
    "numbers = [4, 1, 3, 2]\n",
    "sorted_numbers = sorted(numbers)\n",
    "print(sorted_numbers)  # Output: [1, 2, 3, 4]\n",
    "print(numbers)  # Output: [4, 1, 3, 2] (original list remains unchanged)\n",
    "```\n",
    "\n",
    "- **`sorted()`** returns a **new sorted list**.\n",
    "- The sorting is by default in **ascending** order.\n",
    "\n",
    "##### **1.1.2 `list.sort()` Method**\n",
    "\n",
    "The `sort()` method is used to sort the list in-place. It modifies the original list and does not return anything.\n",
    "\n",
    "```python\n",
    "# Example: Sorting a list using list.sort()\n",
    "numbers = [4, 1, 3, 2]\n",
    "numbers.sort()\n",
    "print(numbers)  # Output: [1, 2, 3, 4] (the original list is modified)\n",
    "```\n",
    "\n",
    "- **`sort()`** sorts the list **in-place** and does not return a value.\n",
    "- The default order is **ascending**.\n",
    "\n",
    "##### **1.1.3 Sorting in Descending Order**\n",
    "\n",
    "Both `sorted()` and `sort()` can sort data in **descending** order by using the `reverse=True` argument.\n",
    "\n",
    "```python\n",
    "# Example: Sorting in descending order\n",
    "numbers = [4, 1, 3, 2]\n",
    "sorted_numbers_desc = sorted(numbers, reverse=True)\n",
    "print(sorted_numbers_desc)  # Output: [4, 3, 2, 1]\n",
    "\n",
    "# Using list.sort()\n",
    "numbers.sort(reverse=True)\n",
    "print(numbers)  # Output: [4, 3, 2, 1]\n",
    "```\n",
    "\n",
    "- **`reverse=True`** makes the sorting **descending**.\n",
    "\n",
    "#### **1.2 Sorting Strings**\n",
    "\n",
    "Strings in Python are sorted lexicographically (alphabetical order). When sorting strings, uppercase letters are sorted before lowercase letters due to their ASCII values.\n",
    "\n",
    "```python\n",
    "# Example: Sorting a list of strings\n",
    "words = [\"apple\", \"Orange\", \"banana\", \"grape\"]\n",
    "sorted_words = sorted(words)\n",
    "print(sorted_words)  # Output: ['Orange', 'apple', 'banana', 'grape']\n",
    "\n",
    "# Sorting in reverse order\n",
    "sorted_words_desc = sorted(words, reverse=True)\n",
    "print(sorted_words_desc)  # Output: ['grape', 'banana', 'apple', 'Orange']\n",
    "```\n",
    "\n",
    "#### **1.3 Sorting with Key Function**\n",
    "\n",
    "You can use the `key` argument in both `sorted()` and `sort()` to specify a custom sorting order. The key function takes an element as input and returns a value used for sorting.\n",
    "\n",
    "```python\n",
    "# Example: Sorting by length of words\n",
    "words = [\"apple\", \"Orange\", \"banana\", \"grape\"]\n",
    "sorted_words = sorted(words, key=len)\n",
    "print(sorted_words)  # Output: ['apple', 'grape', 'Orange', 'banana']\n",
    "```\n",
    "\n",
    "- **`key`**: A function that serves as a basis for comparison.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Ordering Data in Pandas**\n",
    "\n",
    "In addition to sorting basic Python structures like lists and strings, sorting and ordering are also integral parts of data manipulation when working with **Pandas DataFrames**.\n",
    "\n",
    "#### **2.1 Sorting DataFrame by Column(s)**\n",
    "\n",
    "In Pandas, you can sort DataFrame rows by one or more columns using the `sort_values()` method.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "        'Age': [25, 30, 35, 40],\n",
    "        'Score': [85, 90, 95, 100]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Sorting DataFrame by a single column\n",
    "sorted_df = df.sort_values(by='Age')\n",
    "print(sorted_df)\n",
    "```\n",
    "\n",
    "- **`by`**: Specifies the column(s) by which to sort the DataFrame.\n",
    "\n",
    "##### **2.1.1 Sorting in Descending Order in Pandas**\n",
    "\n",
    "Just like Python's built-in sort functions, Pandas allows sorting in descending order by using the `ascending=False` argument.\n",
    "\n",
    "```python\n",
    "# Sorting DataFrame by Age in descending order\n",
    "sorted_df_desc = df.sort_values(by='Age', ascending=False)\n",
    "print(sorted_df_desc)\n",
    "```\n",
    "\n",
    "- **`ascending=False`**: Specifies descending order.\n",
    "\n",
    "##### **2.1.2 Sorting by Multiple Columns**\n",
    "\n",
    "You can sort a DataFrame by multiple columns. Just pass a list of column names to the `by` argument.\n",
    "\n",
    "```python\n",
    "# Sorting by multiple columns\n",
    "sorted_df_multiple = df.sort_values(by=['Age', 'Score'], ascending=[True, False])\n",
    "print(sorted_df_multiple)\n",
    "```\n",
    "\n",
    "- **`ascending=[True, False]`**: Specifies ascending order for 'Age' and descending order for 'Score'.\n",
    "\n",
    "#### **2.2 Sorting DataFrame by Index**\n",
    "\n",
    "In Pandas, you can also sort the DataFrame based on the index using the `sort_index()` method.\n",
    "\n",
    "```python\n",
    "# Sorting DataFrame by index\n",
    "df_sorted_by_index = df.sort_index()\n",
    "print(df_sorted_by_index)\n",
    "```\n",
    "\n",
    "- **`sort_index()`**: Sorts DataFrame by its row index.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Ordering Data**\n",
    "\n",
    "Ordering is the process of arranging items based on specific criteria, and it is often used interchangeably with sorting.\n",
    "\n",
    "#### **3.1 Reordering Data in Lists**\n",
    "\n",
    "You can reorder items in a list by using the `sorted()` or `sort()` methods with a custom key.\n",
    "\n",
    "```python\n",
    "# Reordering items in a list\n",
    "numbers = [5, 2, 8, 1, 3]\n",
    "ordered_numbers = sorted(numbers, key=lambda x: -x)  # Reversing the order\n",
    "print(ordered_numbers)  # Output: [8, 5, 3, 2, 1]\n",
    "```\n",
    "\n",
    "- **`key=lambda x: -x`**: Custom ordering by negating the number (descending).\n",
    "\n",
    "#### **3.2 Reordering Data in Pandas DataFrame**\n",
    "\n",
    "You can reorder columns in a DataFrame by specifying the column order manually.\n",
    "\n",
    "```python\n",
    "# Reorder columns in a DataFrame\n",
    "df_reordered = df[['Score', 'Age', 'Name']]\n",
    "print(df_reordered)\n",
    "```\n",
    "\n",
    "- **Reordering Columns**: Columns can be reordered by passing a list of column names in the desired order.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Performance Considerations**\n",
    "\n",
    "Sorting large datasets or performing repeated sorting operations can be time-consuming, and efficiency matters when working with big data.\n",
    "\n",
    "#### **4.1 Time Complexity**\n",
    "\n",
    "- **List sorting**: Both `sorted()` and `list.sort()` have a time complexity of **O(n log n)**, where `n` is the number of elements in the list.\n",
    "- **DataFrame sorting**: Sorting operations in Pandas also typically take **O(n log n)** time, but the exact performance depends on the dataset and sorting algorithm used.\n",
    "\n",
    "#### **4.2 In-place Sorting**\n",
    "\n",
    "In-place sorting (like `list.sort()`) can save memory, but it modifies the original data, which may not always be desirable. When memory is not a concern, using `sorted()` (which creates a new object) can be a safer option.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Conclusion**\n",
    "\n",
    "Sorting and ordering data are essential tasks in data analysis, and Python provides powerful tools for these operations across different data types:\n",
    "\n",
    "- **Sorting in Python**:\n",
    "\n",
    "  - `sorted()` and `list.sort()` methods for sorting lists.\n",
    "  - Sorting strings lexicographically (alphabetical order).\n",
    "  - Sorting with custom functions using the `key` argument.\n",
    "  - Sorting in ascending or descending order using `reverse=True`.\n",
    "\n",
    "- **Sorting Data in Pandas**:\n",
    "\n",
    "  - `sort_values()` for sorting DataFrames by column(s).\n",
    "  - `sort_index()` for sorting DataFrames by index.\n",
    "  - Sorting in ascending or descending order with `ascending=False`.\n",
    "  - Sorting DataFrames by multiple columns and handling custom sorting criteria.\n",
    "\n",
    "- **Reordering Data**:\n",
    "  - Reordering lists and DataFrames by index or column names.\n",
    "  - Reordering data with custom logic using Python's `key` argument.\n",
    "\n",
    "By mastering these concepts and techniques, you can efficiently manage and manipulate your data in a variety of situations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Aggregating and Grouping in Pandas DataFrame**\n",
    "\n",
    "Aggregation and grouping are key concepts in data analysis, especially when working with large datasets. **Pandas** provides powerful functions to group data and perform aggregate operations, enabling users to extract meaningful insights from the data efficiently. Here’s a comprehensive guide to **aggregating** and **grouping** in a Pandas DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Grouping Data in Pandas**\n",
    "\n",
    "Grouping refers to the process of splitting the data into smaller, manageable subsets based on some criteria (e.g., grouping data by a certain column). Once grouped, you can perform operations on each subset.\n",
    "\n",
    "#### **1.1 The `groupby()` Function**\n",
    "\n",
    "In Pandas, the `groupby()` function is used to group data based on one or more columns. This function splits the DataFrame into groups based on unique values in one or more columns.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Category': ['A', 'B', 'A', 'B', 'A', 'C', 'C'],\n",
    "    'Value': [10, 20, 30, 40, 50, 60, 70]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Group by 'Category'\n",
    "grouped = df.groupby('Category')\n",
    "```\n",
    "\n",
    "- **`groupby('Category')`**: Groups the data based on the 'Category' column.\n",
    "\n",
    "At this point, `grouped` is a **GroupBy** object, which holds references to the subsets of the original DataFrame based on the grouping column(s).\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Aggregating Data**\n",
    "\n",
    "Aggregation involves applying one or more functions to the groups to extract meaningful statistics such as sums, means, counts, and other custom computations.\n",
    "\n",
    "#### **2.1 Common Aggregation Functions**\n",
    "\n",
    "You can apply common aggregation functions to the grouped data using methods like **`sum()`**, **`mean()`**, **`count()`**, **`min()`**, and **`max()`**.\n",
    "\n",
    "##### **2.1.1 `sum()`**\n",
    "\n",
    "The `sum()` function calculates the sum of the values for each group.\n",
    "\n",
    "```python\n",
    "# Sum of values in each group\n",
    "sum_group = grouped['Value'].sum()\n",
    "print(sum_group)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "Category\n",
    "A    90\n",
    "B    60\n",
    "C    130\n",
    "Name: Value, dtype: int64\n",
    "```\n",
    "\n",
    "##### **2.1.2 `mean()`**\n",
    "\n",
    "The `mean()` function computes the average value for each group.\n",
    "\n",
    "```python\n",
    "# Mean of values in each group\n",
    "mean_group = grouped['Value'].mean()\n",
    "print(mean_group)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "Category\n",
    "A    30.000000\n",
    "B    30.000000\n",
    "C    65.000000\n",
    "Name: Value, dtype: float64\n",
    "```\n",
    "\n",
    "##### **2.1.3 `count()`**\n",
    "\n",
    "The `count()` function counts the number of non-null values in each group.\n",
    "\n",
    "```python\n",
    "# Count of values in each group\n",
    "count_group = grouped['Value'].count()\n",
    "print(count_group)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "Category\n",
    "A    3\n",
    "B    2\n",
    "C    2\n",
    "Name: Value, dtype: int64\n",
    "```\n",
    "\n",
    "##### **2.1.4 `min()` and `max()`**\n",
    "\n",
    "You can use `min()` and `max()` to find the smallest and largest values in each group, respectively.\n",
    "\n",
    "```python\n",
    "# Minimum value in each group\n",
    "min_group = grouped['Value'].min()\n",
    "print(min_group)\n",
    "\n",
    "# Maximum value in each group\n",
    "max_group = grouped['Value'].max()\n",
    "print(max_group)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Custom Aggregation with `agg()`**\n",
    "\n",
    "In addition to built-in aggregation functions, you can apply multiple aggregation functions at once using **`agg()`**, and even define your own custom aggregation functions.\n",
    "\n",
    "#### **3.1 Multiple Aggregations**\n",
    "\n",
    "You can pass a list of functions to the `agg()` method to apply multiple aggregations to the grouped data.\n",
    "\n",
    "```python\n",
    "# Multiple aggregation functions using agg()\n",
    "agg_group = grouped['Value'].agg(['sum', 'mean', 'max'])\n",
    "print(agg_group)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "          sum  mean  max\n",
    "Category\n",
    "A          90  30.0   50\n",
    "B          60  30.0   40\n",
    "C         130  65.0   70\n",
    "```\n",
    "\n",
    "#### **3.2 Custom Aggregation Function**\n",
    "\n",
    "You can also apply your own custom aggregation function using `agg()`.\n",
    "\n",
    "```python\n",
    "# Custom aggregation function\n",
    "custom_agg_group = grouped['Value'].agg(lambda x: x.max() - x.min())\n",
    "print(custom_agg_group)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "Category\n",
    "A    40\n",
    "B    20\n",
    "C    10\n",
    "Name: Value, dtype: int64\n",
    "```\n",
    "\n",
    "This custom function calculates the range (max - min) for each group.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Grouping by Multiple Columns**\n",
    "\n",
    "You can group the data by multiple columns by passing a list of column names to the `groupby()` function.\n",
    "\n",
    "```python\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Category': ['A', 'A', 'B', 'B', 'A', 'C', 'C'],\n",
    "    'SubCategory': ['X', 'Y', 'X', 'Y', 'X', 'X', 'Y'],\n",
    "    'Value': [10, 20, 30, 40, 50, 60, 70]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Grouping by multiple columns\n",
    "grouped_multi = df.groupby(['Category', 'SubCategory'])\n",
    "agg_group_multi = grouped_multi['Value'].sum()\n",
    "print(agg_group_multi)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "Category  SubCategory\n",
    "A         X             60\n",
    "          Y             20\n",
    "B         X             30\n",
    "          Y             40\n",
    "C         X             60\n",
    "          Y             70\n",
    "Name: Value, dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Resetting Index After Grouping**\n",
    "\n",
    "After performing a `groupby()` operation, the resulting data is indexed by the grouping columns. If you want to return the DataFrame to a default integer index, you can use `reset_index()`.\n",
    "\n",
    "```python\n",
    "# Resetting the index\n",
    "reset_group = agg_group_multi.reset_index()\n",
    "print(reset_group)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "  Category SubCategory  Value\n",
    "0        A            X     60\n",
    "1        A            Y     20\n",
    "2        B            X     30\n",
    "3        B            Y     40\n",
    "4        C            X     60\n",
    "5        C            Y     70\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Filtering Data After Grouping**\n",
    "\n",
    "You can also filter groups based on some conditions after grouping. For example, you may want to find groups where the sum of values exceeds a certain threshold.\n",
    "\n",
    "```python\n",
    "# Filter groups based on sum of values\n",
    "filtered_groups = grouped['Value'].sum().loc[lambda x: x > 50]\n",
    "print(filtered_groups)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "Category\n",
    "A     90\n",
    "C    130\n",
    "Name: Value, dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Grouping with `transform()`**\n",
    "\n",
    "The `transform()` function allows you to perform operations on each group while preserving the original DataFrame structure.\n",
    "\n",
    "```python\n",
    "# Applying transform to calculate the mean of each group and return a DataFrame of the same shape\n",
    "transformed = grouped['Value'].transform('mean')\n",
    "print(transformed)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "0     30.0\n",
    "1     30.0\n",
    "2     30.0\n",
    "3     30.0\n",
    "4     30.0\n",
    "5     65.0\n",
    "6     65.0\n",
    "Name: Value, dtype: float64\n",
    "```\n",
    "\n",
    "The `transform()` function returns a series with the same index as the original DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Combining Grouped Data**\n",
    "\n",
    "After grouping and applying aggregation, you might want to combine the aggregated results back into the original DataFrame or join them with other DataFrames.\n",
    "\n",
    "```python\n",
    "# Merging the aggregated result back into the original DataFrame\n",
    "agg_group = grouped['Value'].sum().reset_index()\n",
    "df_combined = pd.merge(df, agg_group, on='Category', suffixes=('', '_sum'))\n",
    "print(df_combined)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "  Category SubCategory  Value  Value_sum\n",
    "0        A            X     10         90\n",
    "1        A            Y     20         90\n",
    "2        B            X     30         60\n",
    "3        B            Y     40         60\n",
    "4        A            X     50         90\n",
    "5        C            X     60        130\n",
    "6        C            Y     70        130\n",
    "```\n",
    "\n",
    "Here, `Value_sum` contains the sum of values for each category, and it has been added back to the original DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Conclusion**\n",
    "\n",
    "Grouping and aggregation are powerful tools in Pandas for summarizing data, extracting statistics, and performing analysis. Key concepts include:\n",
    "\n",
    "- **`groupby()`**: Group data by one or more columns.\n",
    "- **Aggregation functions**: Apply functions like `sum()`, `mean()`, `count()`, `min()`, and `max()` to grouped data.\n",
    "- **`agg()`**: Apply multiple aggregation functions simultaneously, or even custom ones.\n",
    "- **Grouping by multiple columns**: Allows multi-level grouping to create more detailed analysis.\n",
    "- **`reset_index()`**: Resets the index of grouped data.\n",
    "- **`transform()`**: Apply operations to each group while preserving the DataFrame structure.\n",
    "- **Merging grouped data**: Combine grouped results back into the original data.\n",
    "\n",
    "These techniques allow you to manipulate and analyze your data effectively in Pandas, providing you with flexible ways to gain insights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Merging and Joining DataFrames in Pandas: A Comprehensive Guide**\n",
    "\n",
    "Merging and joining DataFrames is one of the most essential tasks in data manipulation. It enables you to combine multiple datasets based on common columns or indices, much like SQL joins. Pandas provides powerful functions to merge and join data effectively, making it an indispensable tool for data analysis.\n",
    "\n",
    "This guide will walk you through the concepts, syntax, and usage of **merging** and **joining** DataFrames in Pandas.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Merging DataFrames**\n",
    "\n",
    "Merging combines two DataFrames based on one or more keys (i.e., columns or indices). It's similar to performing a SQL **join** operation. The `merge()` function is used for merging DataFrames in Pandas.\n",
    "\n",
    "#### **1.1 Syntax of `merge()`**\n",
    "\n",
    "```python\n",
    "pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=True)\n",
    "```\n",
    "\n",
    "- **left**: The first DataFrame.\n",
    "- **right**: The second DataFrame.\n",
    "- **how**: Specifies the type of merge. It can be:\n",
    "  - `'inner'`: Default. Only matching keys are kept.\n",
    "  - `'outer'`: All keys are kept, with NaN for missing values.\n",
    "  - `'left'`: All keys from the left DataFrame, with matching rows from the right DataFrame.\n",
    "  - `'right'`: All keys from the right DataFrame, with matching rows from the left DataFrame.\n",
    "- **on**: The column(s) to join on. If not specified, it joins on the intersection of columns from both DataFrames.\n",
    "- **left_on**: Column(s) in the left DataFrame to join on.\n",
    "- **right_on**: Column(s) in the right DataFrame to join on.\n",
    "- **left_index**: Whether to use the index from the left DataFrame as a join key.\n",
    "- **right_index**: Whether to use the index from the right DataFrame as a join key.\n",
    "- **sort**: Whether to sort the result by the join keys.\n",
    "\n",
    "---\n",
    "\n",
    "#### **1.2 Types of Joins in Merging**\n",
    "\n",
    "##### **1.2.1 Inner Join (Default)**\n",
    "\n",
    "An inner join returns only the rows with matching keys from both DataFrames.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrames\n",
    "df1 = pd.DataFrame({\n",
    "    'key': ['A', 'B', 'C', 'D'],\n",
    "    'value': [1, 2, 3, 4]\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'key': ['B', 'D', 'E'],\n",
    "    'value': [20, 30, 40]\n",
    "})\n",
    "\n",
    "# Inner Join\n",
    "merged_df = pd.merge(df1, df2, on='key', how='inner')\n",
    "print(merged_df)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "  key  value_x  value_y\n",
    "0   B        2       20\n",
    "1   D        4       30\n",
    "```\n",
    "\n",
    "- Only rows where the `key` column matches in both `df1` and `df2` are included.\n",
    "\n",
    "##### **1.2.2 Left Join**\n",
    "\n",
    "A left join keeps all the rows from the left DataFrame and matches them with the right DataFrame. If there is no match, the result will have `NaN` in the columns of the right DataFrame.\n",
    "\n",
    "```python\n",
    "# Left Join\n",
    "merged_df_left = pd.merge(df1, df2, on='key', how='left')\n",
    "print(merged_df_left)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "  key  value_x  value_y\n",
    "0   A        1      NaN\n",
    "1   B        2     20.0\n",
    "2   C        3      NaN\n",
    "3   D        4     30.0\n",
    "```\n",
    "\n",
    "##### **1.2.3 Right Join**\n",
    "\n",
    "A right join keeps all the rows from the right DataFrame and matches them with the left DataFrame.\n",
    "\n",
    "```python\n",
    "# Right Join\n",
    "merged_df_right = pd.merge(df1, df2, on='key', how='right')\n",
    "print(merged_df_right)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "  key  value_x  value_y\n",
    "0   B        2       20\n",
    "1   D        4       30\n",
    "2   E      NaN       40\n",
    "```\n",
    "\n",
    "##### **1.2.4 Outer Join**\n",
    "\n",
    "An outer join keeps all rows from both DataFrames, filling in missing values with `NaN` where necessary.\n",
    "\n",
    "```python\n",
    "# Outer Join\n",
    "merged_df_outer = pd.merge(df1, df2, on='key', how='outer')\n",
    "print(merged_df_outer)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "  key  value_x  value_y\n",
    "0   A        1      NaN\n",
    "1   B        2     20.0\n",
    "2   C        3      NaN\n",
    "3   D        4     30.0\n",
    "4   E      NaN     40.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Joining DataFrames**\n",
    "\n",
    "The `join()` function is another way to combine DataFrames. It is used when you want to join two DataFrames based on their indices or a key column.\n",
    "\n",
    "#### **2.1 Syntax of `join()`**\n",
    "\n",
    "```python\n",
    "df1.join(df2, on=None, how='left', lsuffix='', rsuffix='', sort=False)\n",
    "```\n",
    "\n",
    "- **df1**: The DataFrame to join with.\n",
    "- **df2**: The DataFrame to be joined.\n",
    "- **on**: The column(s) to join on (only used when joining by column).\n",
    "- **how**: The type of join (`left`, `right`, `outer`, `inner`).\n",
    "- **lsuffix**: Suffix to add to columns from the left DataFrame if there are overlapping column names.\n",
    "- **rsuffix**: Suffix to add to columns from the right DataFrame if there are overlapping column names.\n",
    "- **sort**: Whether to sort the result by the join key.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2.2 Example of `join()`**\n",
    "\n",
    "```python\n",
    "# Sample DataFrames with index\n",
    "df1 = pd.DataFrame({\n",
    "    'value1': [1, 2, 3],\n",
    "}, index=['A', 'B', 'C'])\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'value2': [10, 20, 30],\n",
    "}, index=['B', 'C', 'D'])\n",
    "\n",
    "# Left Join by index\n",
    "joined_df = df1.join(df2, how='left')\n",
    "print(joined_df)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "   value1  value2\n",
    "A       1     NaN\n",
    "B       2    10.0\n",
    "C       3    20.0\n",
    "```\n",
    "\n",
    "- The `join()` method joins `df2` to `df1` based on the index.\n",
    "\n",
    "#### **2.3 Join by Column**\n",
    "\n",
    "You can also join by columns in both DataFrames, similar to the `merge()` function:\n",
    "\n",
    "```python\n",
    "# Sample DataFrames with columns\n",
    "df1 = pd.DataFrame({\n",
    "    'key': ['A', 'B', 'C'],\n",
    "    'value1': [1, 2, 3]\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'key': ['B', 'C', 'D'],\n",
    "    'value2': [20, 30, 40]\n",
    "})\n",
    "\n",
    "# Join by 'key' column\n",
    "joined_df_col = df1.set_index('key').join(df2.set_index('key'), how='inner')\n",
    "print(joined_df_col)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "   value1  value2\n",
    "key\n",
    "B       2      20\n",
    "C       3      30\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Merging and Joining on Multiple Columns**\n",
    "\n",
    "Both `merge()` and `join()` allow you to combine DataFrames based on multiple columns or indices.\n",
    "\n",
    "#### **3.1 Multiple Columns in `merge()`**\n",
    "\n",
    "```python\n",
    "df1 = pd.DataFrame({\n",
    "    'key1': ['A', 'B', 'C'],\n",
    "    'key2': ['X', 'Y', 'Z'],\n",
    "    'value': [1, 2, 3]\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'key1': ['B', 'C', 'A'],\n",
    "    'key2': ['Y', 'Z', 'X'],\n",
    "    'value': [10, 20, 30]\n",
    "})\n",
    "\n",
    "# Merge on multiple columns\n",
    "merged_multi = pd.merge(df1, df2, on=['key1', 'key2'], how='inner')\n",
    "print(merged_multi)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "  key1 key2  value_x  value_y\n",
    "0    B    Y        2       10\n",
    "1    C    Z        3       20\n",
    "2    A    X        1       30\n",
    "```\n",
    "\n",
    "#### **3.2 Multiple Indices in `join()`**\n",
    "\n",
    "```python\n",
    "df1 = pd.DataFrame({\n",
    "    'value1': [1, 2, 3],\n",
    "}, index=[['A', 'B', 'C'], ['X', 'Y', 'Z']])\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'value2': [10, 20, 30],\n",
    "}, index=[['B', 'C', 'A'], ['Y', 'Z', 'X']])\n",
    "\n",
    "# Join on multiple indices\n",
    "joined_multi_idx = df1.join(df2, how='inner')\n",
    "print(joined_multi_idx)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "       value1  value2\n",
    "A X        1     30\n",
    "B Y        2     20\n",
    "C Z        3     10\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Suffixes in Merging/Joining**\n",
    "\n",
    "When merging or joining DataFrames with overlapping column names (other than the join key), Pandas automatically adds suffixes (`_x` and `_y`) to distinguish the columns from each DataFrame. You can customize these suffixes with the `suffixes` argument.\n",
    "\n",
    "```python\n",
    "# Custom suffixes\n",
    "merged_df_custom = pd.merge(df1, df2, on='key', how='inner', suffixes=('_left', '_right'))\n",
    "print(merged_df_custom)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "  key  value_left  value_right\n",
    "0   B           2          20\n",
    "1   C           3          30\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Conclusion**\n",
    "\n",
    "- **`merge()`** is used when you want to combine DataFrames based on a common column or index, offering flexibility with different types of joins (inner, outer, left, right).\n",
    "- **`join()`** is often used for joining DataFrames based on their indices and is a simpler approach when dealing with indexed data.\n",
    "- Both methods allow you to handle **multiple columns/indices**, **suffix conflicts**, and even **custom join keys**.\n",
    "- Use **`how='left'`, `how='right'`, `how='outer'`, or `how='inner'`** to control the type of join operation you need based on your dataset.\n",
    "\n",
    "By mastering **merging** and **joining**, you can combine and manipulate datasets with great flexibility, allowing you to prepare your data for deeper analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pivot Tables in Pandas: A Comprehensive Guide**\n",
    "\n",
    "Pivot tables are one of the most powerful and useful tools in data analysis. They allow you to summarize and aggregate data in a way that helps uncover insights, patterns, and trends in a dataset. In Python, **Pandas** provides a straightforward way to create pivot tables using the `pivot_table()` function.\n",
    "\n",
    "This guide will walk you through all concepts and features related to **pivot tables** in **Pandas**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. What is a Pivot Table?**\n",
    "\n",
    "A **pivot table** is a data processing tool that allows you to aggregate data, summarize large datasets, and transform columns into rows, or vice versa. Essentially, it reorganizes the data in a way that makes it easier to analyze.\n",
    "\n",
    "In the context of Pandas, the `pivot_table()` function creates a new DataFrame where:\n",
    "\n",
    "- **Rows** represent one or more unique values from one column of the original data.\n",
    "- **Columns** represent unique values from another column.\n",
    "- **Values** are aggregated based on an aggregation function (like sum, mean, count, etc.).\n",
    "\n",
    "Pivot tables are highly useful for grouping and summarizing data, especially when you are dealing with large datasets and need to perform multi-dimensional analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Syntax of `pivot_table()`**\n",
    "\n",
    "```python\n",
    "DataFrame.pivot_table(data=None, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, margins_name='All', observed=False)\n",
    "```\n",
    "\n",
    "- **data**: The DataFrame from which you want to create the pivot table.\n",
    "- **values**: The column(s) to aggregate. This is the data that will be summarized or aggregated.\n",
    "- **index**: The column(s) to group by on the rows.\n",
    "- **columns**: The column(s) to group by on the columns.\n",
    "- **aggfunc**: The aggregation function to apply to the `values`. Common functions include:\n",
    "  - `'mean'` (default)\n",
    "  - `'sum'`\n",
    "  - `'count'`\n",
    "  - `'min'`\n",
    "  - `'max'`\n",
    "  - Custom functions (e.g., `np.median`)\n",
    "- **fill_value**: Value to replace missing values (NaN) in the table.\n",
    "- **margins**: If `True`, adds a row and column showing totals. The default is `False`.\n",
    "- **margins_name**: The name of the row and column that contains the totals.\n",
    "- **observed**: If `True`, the pivot table will only include observed values for categorical variables. It’s useful when you have categorical data with missing values.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Creating Basic Pivot Tables**\n",
    "\n",
    "#### **3.1 Example of Basic Pivot Table**\n",
    "\n",
    "Consider the following DataFrame with sales data:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Region': ['North', 'North', 'South', 'South', 'West', 'West'],\n",
    "    'Product': ['A', 'B', 'A', 'B', 'A', 'B'],\n",
    "    'Sales': [100, 200, 150, 250, 300, 350],\n",
    "    'Profit': [10, 20, 15, 25, 30, 35]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Creating a basic Pivot Table\n",
    "pivot = df.pivot_table(values='Sales', index='Region', columns='Product', aggfunc='sum')\n",
    "print(pivot)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "Product      A    B\n",
    "Region\n",
    "North      100  200\n",
    "South      150  250\n",
    "West       300  350\n",
    "```\n",
    "\n",
    "Here:\n",
    "\n",
    "- **`index='Region'`**: The `Region` values are used for row grouping.\n",
    "- **`columns='Product'`**: The `Product` values are used for column grouping.\n",
    "- **`values='Sales'`**: We are aggregating the `Sales` column.\n",
    "- **`aggfunc='sum'`**: We use the sum aggregation function to compute the total sales for each combination of `Region` and `Product`.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Aggregating Multiple Values**\n",
    "\n",
    "You can use multiple aggregation functions at once, especially if you want to analyze different statistics (e.g., mean, sum, or count) on the same dataset.\n",
    "\n",
    "#### **4.1 Example with Multiple Aggregations**\n",
    "\n",
    "```python\n",
    "pivot_multi_agg = df.pivot_table(values=['Sales', 'Profit'], index='Region', columns='Product', aggfunc={'Sales': 'sum', 'Profit': 'mean'})\n",
    "print(pivot_multi_agg)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           Sales           Profit\n",
    "Product       A    B       A    B\n",
    "Region\n",
    "North      100  200      10   20\n",
    "South      150  250      15   25\n",
    "West       300  350      30   35\n",
    "```\n",
    "\n",
    "Here:\n",
    "\n",
    "- **`values=['Sales', 'Profit']`**: We are summarizing both the `Sales` and `Profit` columns.\n",
    "- **`aggfunc={'Sales': 'sum', 'Profit': 'mean'}`**: We compute the sum of sales and the mean of profit for each combination of `Region` and `Product`.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Handling Missing Data with `fill_value`**\n",
    "\n",
    "You may encounter missing values (NaN) when some combinations of the `index` and `columns` do not exist in the data. The `fill_value` parameter can be used to replace missing values with a specified value.\n",
    "\n",
    "#### **5.1 Example with `fill_value`**\n",
    "\n",
    "```python\n",
    "pivot_fill = df.pivot_table(values='Sales', index='Region', columns='Product', aggfunc='sum', fill_value=0)\n",
    "print(pivot_fill)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "Product      A    B\n",
    "Region\n",
    "North      100  200\n",
    "South      150  250\n",
    "West       300  350\n",
    "```\n",
    "\n",
    "In this case, there are no missing values, but if there were any missing combinations (e.g., if `West` had no `A` product), those would be filled with `0`.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Adding Margins (Grand Totals)**\n",
    "\n",
    "You can add a row and column to show the totals (margins) of all values in the pivot table using the `margins=True` parameter.\n",
    "\n",
    "#### **6.1 Example with Margins**\n",
    "\n",
    "```python\n",
    "pivot_margins = df.pivot_table(values='Sales', index='Region', columns='Product', aggfunc='sum', margins=True)\n",
    "print(pivot_margins)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "Product      A    B  All\n",
    "Region\n",
    "North      100  200  300\n",
    "South      150  250  400\n",
    "West       300  350  650\n",
    "All        550  800 1350\n",
    "```\n",
    "\n",
    "Here:\n",
    "\n",
    "- **`margins=True`**: Adds a row and column that represents the sum of all values in the pivot table.\n",
    "- **`margins_name='All'`**: The default name for the row/column containing the totals is \"All,\" but you can customize this name.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Grouping by Multiple Index and Column Levels**\n",
    "\n",
    "Pivot tables can also group by multiple levels, allowing you to create multi-dimensional pivot tables.\n",
    "\n",
    "#### **7.1 Example with Multiple Indexes**\n",
    "\n",
    "```python\n",
    "pivot_multi_index = df.pivot_table(values='Sales', index=['Region', 'Product'], aggfunc='sum')\n",
    "print(pivot_multi_index)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "                  Sales\n",
    "Region Product\n",
    "North A             100\n",
    "      B             200\n",
    "South A             150\n",
    "      B             250\n",
    "West  A             300\n",
    "      B             350\n",
    "```\n",
    "\n",
    "In this case, both `Region` and `Product` are used as the multi-level index.\n",
    "\n",
    "#### **7.2 Example with Multiple Columns**\n",
    "\n",
    "You can also add multiple columns:\n",
    "\n",
    "```python\n",
    "pivot_multi_col = df.pivot_table(values='Sales', index='Region', columns=['Product'], aggfunc='sum')\n",
    "print(pivot_multi_col)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "Product      A    B\n",
    "Region\n",
    "North      100  200\n",
    "South      150  250\n",
    "West       300  350\n",
    "```\n",
    "\n",
    "This creates a pivot table where `Product` is split into multiple columns.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Using `observed` with Categorical Data**\n",
    "\n",
    "The `observed` parameter is useful when working with categorical variables that may contain missing values. It ensures that only the observed categories are included in the pivot table.\n",
    "\n",
    "#### **8.1 Example with `observed`**\n",
    "\n",
    "```python\n",
    "df['Region'] = pd.Categorical(df['Region'], categories=['North', 'South', 'West', 'East'], ordered=True)\n",
    "pivot_observed = df.pivot_table(values='Sales', index='Region', aggfunc='sum', observed=True)\n",
    "print(pivot_observed)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "         Sales\n",
    "Region\n",
    "North     100\n",
    "South     150\n",
    "West      300\n",
    "```\n",
    "\n",
    "- The `observed=True` ensures that only the `North`, `South`, and `West` regions are included in the pivot table, even though `East` was a category in the original dataset but had no data.\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Conclusion**\n",
    "\n",
    "Pivot tables in Pandas provide a flexible and powerful way to summarize and manipulate large datasets. Here’s a summary of the key concepts:\n",
    "\n",
    "- **`pivot_table()`** allows you to create pivot tables based on different **aggregation functions**, **groupings** (by columns or rows), and **multi-dimensional analysis**.\n",
    "- **Aggregation functions** like `sum()`, `mean()`, `count()`, and `max()` are commonly used to summarize data.\n",
    "- **Handling missing values** can be done using the `fill_value` parameter.\n",
    "- You can calculate **margins** (grand totals) using the `margins=True` option.\n",
    "- **Multi-level grouping** enables more complex data summaries.\n",
    "- **The `observed` parameter** is helpful when dealing with categorical data.\n",
    "\n",
    "By mastering pivot tables in Pandas, you can quickly analyze and summarize large datasets to gain meaningful insights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Time Series in Pandas DataFrame: All Concepts and Theory**\n",
    "\n",
    "Time series analysis is one of the most important types of data analysis, particularly in fields like finance, economics, and weather forecasting. Pandas provides robust tools for handling time series data, making it easier to manipulate, analyze, and visualize data that is indexed by time.\n",
    "\n",
    "In this guide, we'll explore the various concepts and techniques involved in working with time series data in Pandas DataFrames.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. What is Time Series Data?**\n",
    "\n",
    "Time series data refers to data that is collected sequentially over time. Each data point typically corresponds to a specific timestamp or time period. In Pandas, time series data is typically represented using the `DatetimeIndex` as the index of a DataFrame.\n",
    "\n",
    "Key characteristics of time series data include:\n",
    "\n",
    "- **Temporal order**: The data points are ordered by time.\n",
    "- **Regular or irregular intervals**: Data may be recorded at regular intervals (e.g., daily, monthly) or irregular intervals.\n",
    "- **Trend and seasonality**: Time series data often exhibits trends (long-term movement in data) and seasonality (repeated fluctuations at regular intervals).\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Working with DateTime in Pandas**\n",
    "\n",
    "#### **2.1 Creating a DateTime Index**\n",
    "\n",
    "You can create a DateTimeIndex by converting strings or integers to timestamps using Pandas' `pd.to_datetime()` function.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a DateTimeIndex\n",
    "dates = pd.date_range('2025-01-01', periods=5, freq='D')  # 5 dates starting from January 1st, 2025\n",
    "\n",
    "# Creating a simple DataFrame with DateTime index\n",
    "data = [100, 150, 200, 250, 300]\n",
    "df = pd.DataFrame(data, index=dates, columns=['Sales'])\n",
    "print(df)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "            Sales\n",
    "2025-01-01    100\n",
    "2025-01-02    150\n",
    "2025-01-03    200\n",
    "2025-01-04    250\n",
    "2025-01-05    300\n",
    "```\n",
    "\n",
    "In this example:\n",
    "\n",
    "- **`pd.date_range()`**: Generates a range of dates from January 1st, 2025, with a daily frequency.\n",
    "- **DateTime as the index**: The dates are used as the index for the DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2.2 Using `pd.to_datetime()` for Date Conversion**\n",
    "\n",
    "If you have date strings, you can convert them into `datetime` objects using `pd.to_datetime()`:\n",
    "\n",
    "```python\n",
    "# Converting a string to datetime\n",
    "date_str = \"2025-01-01\"\n",
    "date = pd.to_datetime(date_str)\n",
    "\n",
    "print(date)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "2025-01-01 00:00:00\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Setting the DateTime Index**\n",
    "\n",
    "A key concept in time series data is that the **index** should be of type `DatetimeIndex`. If the dataset doesn’t have a DateTime index, you can set one using:\n",
    "\n",
    "```python\n",
    "# If your DataFrame has a column with dates\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "```\n",
    "\n",
    "This sets the **'Date'** column as the index for the DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Resampling Time Series Data**\n",
    "\n",
    "Resampling is a common operation where you change the frequency of the data. You can resample data to different time frequencies (daily, monthly, yearly, etc.) using the `resample()` function.\n",
    "\n",
    "#### **4.1 Downsampling (Reducing Frequency)**\n",
    "\n",
    "You can reduce the frequency (e.g., from daily data to monthly) by using `resample()` along with an aggregation function like `sum()`, `mean()`, etc.\n",
    "\n",
    "```python\n",
    "# Downsampling: Aggregating daily data to monthly data\n",
    "df_monthly = df.resample('M').sum()  # 'M' stands for month-end frequency\n",
    "print(df_monthly)\n",
    "```\n",
    "\n",
    "Output (example):\n",
    "\n",
    "```\n",
    "            Sales\n",
    "2025-01-31    1500\n",
    "```\n",
    "\n",
    "Here, the daily sales data is aggregated to monthly data, summing the sales for each month.\n",
    "\n",
    "#### **4.2 Upsampling (Increasing Frequency)**\n",
    "\n",
    "You can also increase the frequency of the data (e.g., from monthly data to daily), using the `resample()` method with an appropriate method like `ffill()` (forward fill) or `bfill()` (backward fill) to handle missing data.\n",
    "\n",
    "```python\n",
    "# Upsampling: Going from monthly to daily data, filling with forward fill\n",
    "df_daily = df.resample('D').ffill()\n",
    "print(df_daily)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Time Shifting and Lagging**\n",
    "\n",
    "Time shifting is a technique used to shift the data forwards or backwards in time. This is useful when you need to create features like moving averages or lag features.\n",
    "\n",
    "#### **5.1 Shifting Data**\n",
    "\n",
    "The `shift()` method shifts the data by a certain number of periods.\n",
    "\n",
    "```python\n",
    "# Shift data forward by 1 day\n",
    "df_shifted = df.shift(1)\n",
    "print(df_shifted)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "            Sales\n",
    "2025-01-01    NaN\n",
    "2025-01-02    100.0\n",
    "2025-01-03    150.0\n",
    "2025-01-04    200.0\n",
    "2025-01-05    250.0\n",
    "```\n",
    "\n",
    "Here, the data is shifted forward by one day, and `NaN` is placed in the first row because there's no data for the previous day.\n",
    "\n",
    "#### **5.2 Lagging with `shift()`**\n",
    "\n",
    "You can create lag features by shifting the data and then comparing it with the original values.\n",
    "\n",
    "```python\n",
    "# Creating a lag feature (previous day's sales)\n",
    "df['Lagged_Sales'] = df['Sales'].shift(1)\n",
    "print(df)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "            Sales  Lagged_Sales\n",
    "2025-01-01    100           NaN\n",
    "2025-01-02    150         100.0\n",
    "2025-01-03    200         150.0\n",
    "2025-01-04    250         200.0\n",
    "2025-01-05    300         250.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Rolling Window and Moving Averages**\n",
    "\n",
    "A rolling window is used to calculate statistics over a fixed-sized window of observations, commonly used for time series analysis to smooth out short-term fluctuations and highlight longer-term trends.\n",
    "\n",
    "#### **6.1 Rolling Mean (Moving Average)**\n",
    "\n",
    "To calculate a rolling mean or moving average, use the `rolling()` method followed by an aggregation function (e.g., `mean()`).\n",
    "\n",
    "```python\n",
    "# 3-day rolling mean\n",
    "df['Rolling_Mean'] = df['Sales'].rolling(window=3).mean()\n",
    "print(df)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "            Sales  Rolling_Mean\n",
    "2025-01-01    100           NaN\n",
    "2025-01-02    150           NaN\n",
    "2025-01-03    200    150.000000\n",
    "2025-01-04    250    200.000000\n",
    "2025-01-05    300    250.000000\n",
    "```\n",
    "\n",
    "Here, the rolling mean is calculated over a 3-day window. The first two values are `NaN` since there aren't enough previous values to calculate the mean.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Time Series Plotting**\n",
    "\n",
    "You can visualize time series data using `matplotlib` or `seaborn` for better insight into trends, seasonality, and patterns.\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the time series data\n",
    "df['Sales'].plot(title=\"Sales Over Time\")\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Time Series Decomposition**\n",
    "\n",
    "Time series data often contains components such as trend, seasonality, and noise. You can decompose a time series into these components using **seasonal decomposition**.\n",
    "\n",
    "#### **8.1 Using `seasonal_decompose()`**\n",
    "\n",
    "```python\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Decompose time series data into trend, seasonal, and residual components\n",
    "decomposition = seasonal_decompose(df['Sales'], model='additive', period=365)\n",
    "\n",
    "decomposition.plot()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "This decomposition helps you visualize the underlying trend and seasonal components separately.\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Time Zone Handling**\n",
    "\n",
    "Handling time zones is crucial when working with time series data that spans multiple regions. Pandas provides support for time zone-aware `DatetimeIndex`.\n",
    "\n",
    "#### **9.1 Time Zone Conversion**\n",
    "\n",
    "You can convert to a different time zone using the `tz_convert()` function:\n",
    "\n",
    "```python\n",
    "# Set timezone to UTC\n",
    "df.index = df.index.tz_localize('UTC')\n",
    "\n",
    "# Convert to another timezone (e.g., 'US/Eastern')\n",
    "df.index = df.index.tz_convert('US/Eastern')\n",
    "print(df)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Resampling with `Grouper`**\n",
    "\n",
    "The `pd.Grouper()` function is used for advanced resampling when you want to group data based on a specific time frequency, like monthly or yearly.\n",
    "\n",
    "```python\n",
    "# Resampling with Grouper\n",
    "df_grouped = df.groupby(pd.Grouper(freq='M')).sum()\n",
    "print(df_grouped)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **11. Conclusion**\n",
    "\n",
    "Time series data plays a crucial role in many domains, and Pandas provides an excellent set of tools to manipulate and analyze such data. Here's a summary of the key concepts:\n",
    "\n",
    "- **DateTime Indexing**: Setting the DateTime as the index of a DataFrame to perform time series analysis.\n",
    "- **Resampling**: Changing the frequency of your data (downsampling or upsampling).\n",
    "- **Shifting and Lagging**: Shifting data to create lag features or time-based transformations.\n",
    "- **Rolling Window**: Calculating moving averages or other rolling statistics.\n",
    "- **Time Zone Handling**: Managing and converting time zones for time series data.\n",
    "- **Plotting**: Visualizing time series data to detect trends and patterns.\n",
    "- **Decomposition**: Breaking down time series data into trend, seasonality, and residuals.\n",
    "- **Grouper**: Grouping time series data by different time frequencies.\n",
    "\n",
    "By mastering these concepts, you can easily analyze and derive insights from time series data using Pandas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "> ### **1. What is a DataFrame?**\n",
    "  A DataFrame is a 2-dimensional labeled data structure commonly used in data analysis and manipulation. It is similar to a table in a relational database or an Excel spreadsheet. It allows you to store data in rows and columns, where:\n",
    "\n",
    "  - **Rows** represent observations or instances of data.\n",
    "  - **Columns** represent different variables or features.\n",
    "\n",
    "  ### **2. Key Components of a DataFrame**\n",
    "  - **Index**: Identifies the rows in the DataFrame. It's used for alignment when performing operations like merging, joining, or aggregating.\n",
    "  - **Columns**: Represent the data attributes/variables. They can be of different types (e.g., numerical, categorical).\n",
    "  - **Data**: Actual values in the table, which can be of various data types (e.g., integers, floats, strings, etc.).\n",
    "\n",
    "  ### **3. DataFrame Operations**\n",
    "\n",
    "  #### **Creation of DataFrame**\n",
    "  A DataFrame can be created from various data sources like:\n",
    "  - Lists, dictionaries, and arrays\n",
    "  - CSV, Excel, SQL databases\n",
    "  - NumPy arrays\n",
    "  - Other DataFrame objects (concatenation or merging)\n",
    "\n",
    "  #### **Example in Pandas (Python):**\n",
    "  ```python\n",
    "  import pandas as pd\n",
    "\n",
    "  # Creating a DataFrame from a dictionary\n",
    "  data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "          'Age': [24, 27, 22],\n",
    "          'City': ['New York', 'Los Angeles', 'Chicago']}\n",
    "\n",
    "  df = pd.DataFrame(data)\n",
    "  print(df)\n",
    "  ```\n",
    "\n",
    "  #### **Accessing Data**\n",
    "  - **By Column**: `df['Column Name']`\n",
    "  - **By Row**: `df.iloc[index]` or `df.loc[row_label]`\n",
    "  - **By Condition**: `df[df['column'] > value]`\n",
    "\n",
    "  ### **4. DataFrame Operations and Functions**\n",
    "\n",
    "  #### **Selection**\n",
    "  - `df.head(n)` – Returns the first `n` rows.\n",
    "  - `df.tail(n)` – Returns the last `n` rows.\n",
    "  - `df.iloc[index]` – Selects rows/columns by position.\n",
    "  - `df.loc[label]` – Selects rows/columns by label.\n",
    "\n",
    "  #### **Data Cleaning**\n",
    "  - `df.isnull()` – Identifies missing values.\n",
    "  - `df.dropna()` – Drops rows with missing values.\n",
    "  - `df.fillna(value)` – Fills missing values with a specified value.\n",
    "  - `df.replace(old, new)` – Replaces values in the DataFrame.\n",
    "\n",
    "  #### **Transformation**\n",
    "  - `df.apply(function)` – Apply a function along the axis (rows or columns).\n",
    "  - `df.applymap(function)` – Apply a function elementwise to a DataFrame.\n",
    "  - `df.rename(columns={'old': 'new'})` – Renames columns.\n",
    "\n",
    "  #### **Aggregation and Grouping**\n",
    "  - `df.groupby('column')` – Groups data by a particular column.\n",
    "  - `df.agg(func)` – Aggregates data using a function (mean, sum, etc.).\n",
    "  - `df.describe()` – Provides summary statistics (e.g., mean, median, std).\n",
    "\n",
    "  ### **5. DataFrame Indexing and Alignment**\n",
    "  - **Indexing**: This refers to selecting specific rows/columns based on a particular index.\n",
    "  - **Alignment**: Pandas ensures that data aligns based on the index during operations like addition, subtraction, etc.\n",
    "\n",
    "  #### **Examples:**\n",
    "  ```python\n",
    "  df['Age'] + df['Age']  # Addition aligns based on index\n",
    "  ```\n",
    "\n",
    "  ### **6. Handling Missing Data**\n",
    "  - **NaN (Not a Number)** is used to represent missing or undefined data.\n",
    "  - **Methods for Handling Missing Data**:\n",
    "    - Removing: `df.dropna()`\n",
    "    - Filling: `df.fillna(0)` or `df.fillna(df.mean())`\n",
    "\n",
    "  ### **7. DataFrame Merging, Joining, and Concatenation**\n",
    "  - **Merging**: Combines DataFrames based on a common column (similar to SQL JOIN).\n",
    "    ```python\n",
    "    df1.merge(df2, on='key_column')\n",
    "    ```\n",
    "  - **Concatenation**: Stacks DataFrames on top of each other (vertically) or side by side (horizontally).\n",
    "    ```python\n",
    "    pd.concat([df1, df2], axis=0)  # Axis 0: Vertically\n",
    "    pd.concat([df1, df2], axis=1)  # Axis 1: Horizontally\n",
    "    ```\n",
    "    \n",
    "  - **Joining**: Merges based on the index or a column.\n",
    "    ```python\n",
    "    df1.join(df2, on='key_column')\n",
    "    ```\n",
    "\n",
    "  ### **8. Pivoting and Reshaping**\n",
    "  - **Pivot Table**: Used for aggregating and summarizing data.\n",
    "    ```python\n",
    "    df.pivot_table(values='value', index='row', columns='col')\n",
    "    ```\n",
    "\n",
    "  - **Reshape**: Changing the shape of the DataFrame (e.g., `melt()`, `stack()`, `unstack()`).\n",
    "    ```python\n",
    "    df.melt(id_vars=['id'], value_vars=['var1', 'var2'])\n",
    "    ```\n",
    "\n",
    "  ### **9. Sorting**\n",
    "  - **Sorting by column**:\n",
    "    ```python\n",
    "    df.sort_values(by='Age', ascending=False)\n",
    "    ```\n",
    "  - **Sorting by index**:\n",
    "    ```python\n",
    "    df.sort_index(axis=1)  # Sorting by columns\n",
    "    ```\n",
    "\n",
    "  ### **10. Time Series in DataFrame**\n",
    "  - **Datetime Operations**: You can handle dates and times in DataFrames with `pd.to_datetime()`.\n",
    "  - **Resampling**: Changing the frequency of the time series (e.g., from daily to monthly).\n",
    "    ```python\n",
    "    df.resample('M').mean()  # Resample to monthly data and take the mean\n",
    "    ```\n",
    "\n",
    "  ### **11. I/O Operations**\n",
    "  - **Reading Data**:\n",
    "    - `pd.read_csv('file.csv')` – Read from a CSV file.\n",
    "    - `pd.read_excel('file.xlsx')` – Read from an Excel file.\n",
    "    \n",
    "  - **Writing Data**:\n",
    "    - `df.to_csv('file.csv')` – Write DataFrame to CSV.\n",
    "    - `df.to_excel('file.xlsx')` – Write DataFrame to Excel.\n",
    "\n",
    "  ### **12. Visualization**\n",
    "  While DataFrames are not directly for visualization, they integrate with libraries like Matplotlib or Seaborn to generate plots.\n",
    "\n",
    "  ```python\n",
    "  import matplotlib.pyplot as plt\n",
    "  df['Age'].hist()\n",
    "  plt.show()\n",
    "  ```\n",
    "\n",
    "  ### **13. Performance Considerations**\n",
    "  - **Memory Efficiency**: DataFrames can be memory-intensive. It's important to:\n",
    "    - Use appropriate data types (e.g., `int32`, `float32` instead of `int64`).\n",
    "    - Consider chunking large data into smaller pieces.\n",
    "    \n",
    "  - **Vectorization**: Instead of using loops, apply functions elementwise or use built-in Pandas functions for faster computations.\n",
    "---\n",
    "\n",
    "### **Advanced DataFrame Topics**\n",
    "\n",
    "1. **MultiIndex**: Hierarchical indexing to handle multi-level indexing.\n",
    "2. **Categorical Data**: Storing and manipulating categorical variables efficiently.\n",
    "3. **Window Functions**: Rolling windows for calculations like moving averages.\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "DataFrames are a powerful and flexible data structure in data science and analytics, particularly when using libraries like Pandas. They allow easy manipulation, cleaning, and analysis of data, making them a core component in any data-driven project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **selection** concepts in **Pandas**, which refers to how you access, filter, and manipulate data in a DataFrame or Series. Selection in Pandas is essential for extracting the data you need and performing operations based on it.\n",
    "\n",
    "### **1. Selecting Columns in Pandas**\n",
    "\n",
    "#### **By Column Name**\n",
    "\n",
    "- You can access a single column by specifying the column name as a key in the DataFrame, which returns a **Series**.\n",
    "\n",
    "  ```python\n",
    "  df['ColumnName']  # Accessing a single column\n",
    "  ```\n",
    "\n",
    "- You can access multiple columns by passing a list of column names.\n",
    "  ```python\n",
    "  df[['Column1', 'Column2']]  # Accessing multiple columns\n",
    "  ```\n",
    "\n",
    "#### **Example:**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'Age': [24, 27, 22],\n",
    "        'City': ['New York', 'Los Angeles', 'Chicago']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Selecting a single column\n",
    "print(df['Name'])\n",
    "\n",
    "# Selecting multiple columns\n",
    "print(df[['Name', 'City']])\n",
    "```\n",
    "\n",
    "### **2. Selecting Rows in Pandas**\n",
    "\n",
    "#### **By Index Position: `iloc[]`**\n",
    "\n",
    "- `.iloc[]` allows you to select rows and columns based on their integer position (zero-indexed).\n",
    "  - **Single Row**: `df.iloc[2]` selects the third row (index 2).\n",
    "  - **Range of Rows**: `df.iloc[1:3]` selects rows from index 1 to 2 (excluding 3).\n",
    "\n",
    "#### **Example:**\n",
    "\n",
    "```python\n",
    "# Selecting a row by index position\n",
    "print(df.iloc[1])\n",
    "\n",
    "# Selecting a range of rows\n",
    "print(df.iloc[1:3])\n",
    "```\n",
    "\n",
    "#### **By Index Label: `loc[]`**\n",
    "\n",
    "- `.loc[]` allows you to select rows and columns by label (index name).\n",
    "  - **Single Row**: `df.loc['row_label']` (if you have a custom index with labels).\n",
    "  - **Range of Rows**: `df.loc['row_label1':'row_label3']`\n",
    "\n",
    "#### **Example:**\n",
    "\n",
    "```python\n",
    "# Assuming a custom index for rows\n",
    "df = df.set_index('Name')\n",
    "\n",
    "# Selecting by row label\n",
    "print(df.loc['Bob'])\n",
    "\n",
    "# Selecting a range of rows\n",
    "print(df.loc['Alice':'Charlie'])\n",
    "```\n",
    "\n",
    "### **3. Conditional Selection in Pandas**\n",
    "\n",
    "You can filter rows based on a condition applied to one or more columns.\n",
    "\n",
    "#### **Example:**\n",
    "\n",
    "- **Single Condition**: Select rows where age is greater than 24.\n",
    "\n",
    "  ```python\n",
    "  df[df['Age'] > 24]\n",
    "  ```\n",
    "\n",
    "- **Multiple Conditions**: Use `&` (and) or `|` (or) for multiple conditions (with parentheses).\n",
    "  ```python\n",
    "  df[(df['Age'] > 24) & (df['City'] == 'New York')]\n",
    "  ```\n",
    "\n",
    "#### **Example:**\n",
    "\n",
    "```python\n",
    "# Condition: Age greater than 24\n",
    "print(df[df['Age'] > 24])\n",
    "\n",
    "# Condition: Age greater than 24 and City is 'New York'\n",
    "print(df[(df['Age'] > 24) & (df['City'] == 'New York')])\n",
    "```\n",
    "\n",
    "### **4. Selecting Specific Data (Row-Column Pair)**\n",
    "\n",
    "You can combine **row** and **column** selection using `.loc[]` or `.iloc[]` for more granular selection.\n",
    "\n",
    "#### **Using `loc[]` (label-based)**:\n",
    "\n",
    "- `df.loc[row_label, column_label]` selects a single data point based on row and column labels.\n",
    "- `df.loc[:, 'Column1']` selects all rows for `'Column1'`.\n",
    "\n",
    "#### **Example:**\n",
    "\n",
    "```python\n",
    "# Select specific row and column using label\n",
    "print(df.loc['Alice', 'Age'])\n",
    "\n",
    "# Select all rows for a specific column\n",
    "print(df.loc[:, 'Age'])\n",
    "```\n",
    "\n",
    "#### **Using `iloc[]` (position-based)**:\n",
    "\n",
    "- `df.iloc[row_index, column_index]` selects data by index position.\n",
    "- `df.iloc[:, 1]` selects all rows for the second column.\n",
    "\n",
    "#### **Example:**\n",
    "\n",
    "```python\n",
    "# Select specific row and column using index position\n",
    "print(df.iloc[0, 1])\n",
    "\n",
    "# Select all rows for the second column\n",
    "print(df.iloc[:, 1])\n",
    "```\n",
    "\n",
    "### **5. Selecting Data Using `.at[]` and `.iat[]`**\n",
    "\n",
    "- `.at[]` is used for **fast access** to a **single value** by label.\n",
    "- `.iat[]` is used for **fast access** to a **single value** by position.\n",
    "\n",
    "#### **Example:**\n",
    "\n",
    "```python\n",
    "# Using .at[] to get the value for a specific label-based row and column\n",
    "print(df.at['Alice', 'Age'])\n",
    "\n",
    "# Using .iat[] to get the value for a specific position-based row and column\n",
    "print(df.iat[0, 1])\n",
    "```\n",
    "\n",
    "### **6. Selecting Data by Slicing**\n",
    "\n",
    "#### **Slicing Rows**\n",
    "\n",
    "- You can slice rows using `.iloc[]` or `.loc[]`, especially when working with a range.\n",
    "  ```python\n",
    "  df.iloc[1:4]  # Get rows 1 to 3 (indexing is exclusive)\n",
    "  df.loc['row_label1':'row_label3']  # Slice using labels\n",
    "  ```\n",
    "\n",
    "#### **Slicing Columns**\n",
    "\n",
    "- Similar slicing can be applied to columns.\n",
    "  ```python\n",
    "  df.iloc[:, 1:3]  # Get all rows, columns 1 to 2\n",
    "  df.loc[:, 'Age':'City']  # Get columns 'Age' to 'City'\n",
    "  ```\n",
    "\n",
    "### **7. Selecting Data Using `.query()`**\n",
    "\n",
    "The `.query()` method allows you to select data by writing an expression in string format.\n",
    "\n",
    "#### **Example:**\n",
    "\n",
    "```python\n",
    "# Select rows where Age > 24\n",
    "print(df.query('Age > 24'))\n",
    "\n",
    "# Select rows where Age > 24 and City is 'New York'\n",
    "print(df.query('Age > 24 and City == \"New York\"'))\n",
    "```\n",
    "\n",
    "### **8. Selecting Unique/Distinct Data**\n",
    "\n",
    "You can select distinct/unique values using the `.unique()` method or `.drop_duplicates()` to remove duplicate rows.\n",
    "\n",
    "#### **Example:**\n",
    "\n",
    "```python\n",
    "# Get unique values from the 'City' column\n",
    "print(df['City'].unique())\n",
    "\n",
    "# Remove duplicate rows\n",
    "print(df.drop_duplicates())\n",
    "```\n",
    "\n",
    "### **9. Indexing with MultiIndex**\n",
    "\n",
    "**MultiIndex** allows you to have multiple levels of row and column indices. Selection and filtering become more powerful with multiple index levels.\n",
    "\n",
    "#### **Example:**\n",
    "\n",
    "```python\n",
    "# Create a MultiIndex\n",
    "df = df.set_index(['City', 'Age'])\n",
    "\n",
    "# Select by level of MultiIndex\n",
    "print(df.loc[('New York', 24)])\n",
    "```\n",
    "\n",
    "### **10. Selecting with `.isin()`**\n",
    "\n",
    "`.isin()` is useful for filtering data based on whether a value exists in a list or array.\n",
    "\n",
    "#### **Example:**\n",
    "\n",
    "```python\n",
    "# Select rows where 'City' is either 'New York' or 'Chicago'\n",
    "print(df[df['City'].isin(['New York', 'Chicago'])])\n",
    "```\n",
    "\n",
    "### **11. Selecting Data Using `.between()`**\n",
    "\n",
    "The `.between()` function is used for filtering data between two values.\n",
    "\n",
    "#### **Example:**\n",
    "\n",
    "```python\n",
    "# Select rows where 'Age' is between 22 and 25 (inclusive)\n",
    "print(df[df['Age'].between(22, 25)])\n",
    "```\n",
    "\n",
    "### **12. Random Selection**\n",
    "\n",
    "For random selection, you can use `.sample()` to get a random row or subset of data.\n",
    "\n",
    "#### **Example:**\n",
    "\n",
    "```python\n",
    "# Select a random row from the DataFrame\n",
    "print(df.sample(1))\n",
    "\n",
    "# Select a random subset of 2 rows\n",
    "print(df.sample(2))\n",
    "```\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "Pandas offers a range of powerful selection methods for efficiently accessing and filtering data in a DataFrame. By combining indexing, conditional selection, label-based and position-based slicing, and advanced techniques like `.query()` and `.isin()`, you can manipulate data in very flexible ways.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data cleaning** is a crucial step in the data analysis process. It involves identifying and correcting errors or inconsistencies in data to improve its quality and accuracy. Below is a comprehensive guide to **data cleaning concepts** and techniques, particularly using **Pandas** in Python.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. What is Data Cleaning?**\n",
    "\n",
    "Data cleaning refers to the process of:\n",
    "\n",
    "- Identifying and correcting (or removing) errors in the dataset.\n",
    "- Ensuring the dataset is accurate, consistent, and usable for analysis.\n",
    "- Handling missing values, duplicates, inconsistencies, and incorrect formats.\n",
    "\n",
    "In the context of **Pandas**, data cleaning generally involves working with **DataFrames** and **Series** to clean and prepare data for analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Common Data Quality Issues**\n",
    "\n",
    "- **Missing Data**: Some data entries might be missing or null.\n",
    "- **Duplicates**: Duplicate rows may exist in the dataset.\n",
    "- **Inconsistent Formatting**: Data might be in different formats (e.g., different date formats or inconsistent text casing).\n",
    "- **Outliers**: Extreme or unexpected values that might distort analysis.\n",
    "- **Incorrect Data Types**: Some columns may contain data that is not in the expected format (e.g., text in a numerical column).\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Key Data Cleaning Techniques in Pandas**\n",
    "\n",
    "#### **a. Handling Missing Data**\n",
    "\n",
    "Missing data can be represented by **NaN (Not a Number)** or **None** values. There are multiple ways to deal with missing data:\n",
    "\n",
    "1. **Detecting Missing Data**:\n",
    "\n",
    "   - `df.isnull()` returns a DataFrame of the same shape as the original with `True` for missing data.\n",
    "   - `df.notnull()` returns the inverse, `True` for non-missing data.\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```python\n",
    "   df.isnull()\n",
    "   ```\n",
    "\n",
    "2. **Dropping Missing Values**:\n",
    "\n",
    "   - `df.dropna()` removes rows that contain missing values.\n",
    "   - `df.dropna(axis=1)` removes columns with missing values.\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```python\n",
    "   df.dropna()  # Drop rows with any missing values\n",
    "   df.dropna(axis=1)  # Drop columns with any missing values\n",
    "   ```\n",
    "\n",
    "3. **Filling Missing Values**:\n",
    "\n",
    "   - `df.fillna(value)` fills missing values with a specific value.\n",
    "   - `df.fillna(method='ffill')` fills missing values using the **forward fill** method (propagate the last valid value forward).\n",
    "   - `df.fillna(method='bfill')` uses **backward fill** (propagate the next valid value backward).\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```python\n",
    "   df.fillna(0)  # Fill missing values with 0\n",
    "   df.fillna(df.mean())  # Fill missing values with the mean of each column\n",
    "   df.fillna(method='ffill')  # Forward fill\n",
    "   ```\n",
    "\n",
    "4. **Replacing Missing Values**:\n",
    "\n",
    "   - `df.replace()` can be used to replace specific values, including NaN.\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```python\n",
    "   df.replace(np.nan, 0)  # Replace NaN with 0\n",
    "   ```\n",
    "\n",
    "#### **b. Removing Duplicates**\n",
    "\n",
    "Duplicate rows can be identified and removed using the following methods:\n",
    "\n",
    "1. **Detecting Duplicates**:\n",
    "\n",
    "   - `df.duplicated()` returns a Boolean Series indicating whether a row is a duplicate.\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```python\n",
    "   df.duplicated()  # Returns True for duplicate rows\n",
    "   ```\n",
    "\n",
    "2. **Dropping Duplicates**:\n",
    "\n",
    "   - `df.drop_duplicates()` removes duplicate rows from the DataFrame.\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```python\n",
    "   df.drop_duplicates()  # Removes duplicate rows\n",
    "   ```\n",
    "\n",
    "3. **Removing Duplicates Based on Specific Columns**:\n",
    "\n",
    "   - You can specify a subset of columns to consider for identifying duplicates using the `subset` parameter.\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```python\n",
    "   df.drop_duplicates(subset=['Column1', 'Column2'])  # Removes duplicates based on selected columns\n",
    "   ```\n",
    "\n",
    "#### **c. Standardizing and Correcting Data Types**\n",
    "\n",
    "Sometimes, the data might not be in the correct type. For example, numerical data might be stored as strings, or dates might be stored as objects. You can use the following methods to convert and correct data types:\n",
    "\n",
    "1. **Changing Data Types**:\n",
    "\n",
    "   - `df.astype()` changes the data type of a column.\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```python\n",
    "   df['Age'] = df['Age'].astype(int)  # Change 'Age' column to integer type\n",
    "   df['Date'] = pd.to_datetime(df['Date'])  # Convert to datetime\n",
    "   ```\n",
    "\n",
    "2. **Handling Errors During Type Conversion**:\n",
    "\n",
    "   - Use `errors='coerce'` to convert invalid parsing to `NaT` (Not a Time) or `NaN`.\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```python\n",
    "   df['Age'] = pd.to_numeric(df['Age'], errors='coerce')  # Convert to numeric, invalid entries become NaN\n",
    "   ```\n",
    "\n",
    "#### **d. Handling Inconsistent or Invalid Data**\n",
    "\n",
    "1. **String Cleaning**:\n",
    "\n",
    "   - You may need to clean text data by removing unwanted spaces, handling case sensitivity, or correcting typos.\n",
    "   - `.str.strip()` removes leading and trailing spaces.\n",
    "   - `.str.lower()` converts text to lowercase for uniformity.\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```python\n",
    "   df['City'] = df['City'].str.strip()  # Remove leading/trailing spaces\n",
    "   df['City'] = df['City'].str.lower()  # Convert to lowercase\n",
    "   ```\n",
    "\n",
    "2. **Replacing Invalid Data**:\n",
    "\n",
    "   - You can replace invalid or inconsistent data using the `.replace()` method.\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```python\n",
    "   df['Gender'] = df['Gender'].replace('F', 'Female')  # Replace 'F' with 'Female'\n",
    "   ```\n",
    "\n",
    "#### **e. Handling Outliers**\n",
    "\n",
    "Outliers are extreme values that can distort statistical analysis. Methods to deal with outliers include:\n",
    "\n",
    "1. **Detecting Outliers**:\n",
    "\n",
    "   - You can use **z-scores** or **IQR (Interquartile Range)** methods to identify outliers.\n",
    "\n",
    "   Example using **z-score**:\n",
    "\n",
    "   ```python\n",
    "   from scipy.stats import zscore\n",
    "   df['zscore'] = zscore(df['Age'])\n",
    "   df[df['zscore'] > 3]  # Identifies rows where the z-score is above 3\n",
    "   ```\n",
    "\n",
    "2. **Removing or Capping Outliers**:\n",
    "\n",
    "   - Remove rows where values exceed a threshold.\n",
    "   - Cap values by replacing outliers with a maximum or minimum threshold.\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```python\n",
    "   df = df[df['Age'] < 100]  # Remove rows with age > 100\n",
    "   ```\n",
    "\n",
    "#### **f. Renaming Columns**\n",
    "\n",
    "Renaming columns can make the dataset easier to work with, especially if column names are unclear or inconsistent.\n",
    "\n",
    "1. **Renaming Columns**:\n",
    "\n",
    "   - `df.rename()` allows you to change column names.\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```python\n",
    "   df.rename(columns={'OldName': 'NewName'}, inplace=True)  # Rename a single column\n",
    "   ```\n",
    "\n",
    "2. **Renaming Multiple Columns**:\n",
    "\n",
    "   - You can rename multiple columns by passing a dictionary of old names to new names.\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```python\n",
    "   df.rename(columns={'OldName1': 'NewName1', 'OldName2': 'NewName2'}, inplace=True)\n",
    "   ```\n",
    "\n",
    "#### **g. Handling Date and Time Data**\n",
    "\n",
    "Handling **date** and **time** data types correctly is crucial for time-series analysis.\n",
    "\n",
    "1. **Converting to DateTime**:\n",
    "\n",
    "   - Use `pd.to_datetime()` to convert columns to `datetime` objects.\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```python\n",
    "   df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')  # Convert to datetime format\n",
    "   ```\n",
    "\n",
    "2. **Extracting Date Components**:\n",
    "\n",
    "   - You can extract the year, month, day, weekday, etc., from a `datetime` column.\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```python\n",
    "   df['Year'] = df['Date'].dt.year  # Extract the year\n",
    "   df['Month'] = df['Date'].dt.month  # Extract the month\n",
    "   ```\n",
    "\n",
    "#### **h. Dealing with Categorical Data**\n",
    "\n",
    "Categorical data needs to be converted to a suitable format for analysis or modeling.\n",
    "\n",
    "1. **Convert to Categorical Data Type**:\n",
    "\n",
    "   - You can convert text data into categorical data using `pd.Categorical`.\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```python\n",
    "   df['Category'] = pd.Categorical(df['Category'])\n",
    "   ```\n",
    "\n",
    "2. **One-Hot Encoding**:\n",
    "\n",
    "   - Use `pd.get_dummies()` to convert categorical variables into dummy/indicator variables (One-Hot Encoding).\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```python\n",
    "   df = pd.get_dummies(df, columns=['Category'])\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Final Steps in Data Cleaning**\n",
    "\n",
    "Once you have cleaned the data, it's important to:\n",
    "\n",
    "- **Check for consistency**: Verify that all the data types are correct and that there are no more missing values or duplicates.\n",
    "- **Save the Cleaned Data**: Once the data is cleaned, save it to a new file (e.g., CSV or Excel) for future use.\n",
    "  ```python\n",
    "  df.to_csv('cleaned_data.csv', index=False)\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "Data cleaning is an essential process in ensuring the quality and usability of your data. By handling missing data, duplicates, inconsistent formats, outliers, and incorrect data types, you can prepare your dataset for meaningful analysis. In **Pandas**, you have a wide array of tools to address each of these issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Transformation** refers to the process of converting, modifying, or reshaping data to meet specific analysis or processing requirements. In **Pandas**, data transformation can involve a variety of techniques such as scaling, encoding, aggregating, and reshaping data.\n",
    "\n",
    "Below is a comprehensive guide on **data transformation** concepts and techniques within a **Pandas DataFrame**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. What is Data Transformation?**\n",
    "\n",
    "Data transformation is the process of altering or changing the format, structure, or values of the data. It plays an essential role in preparing data for analysis, model training, or any operation where a different format or structure of data is needed.\n",
    "\n",
    "Common types of transformations:\n",
    "\n",
    "- **Scaling and Normalization**: Adjusting values to fall within a specific range.\n",
    "- **Aggregation**: Summarizing data by grouping.\n",
    "- **Encoding**: Converting categorical data to numeric or other formats.\n",
    "- **Reshaping**: Changing the structure of a DataFrame (pivot, melt, transpose, etc.).\n",
    "- **Filtering**: Modifying data based on specific criteria.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Types of Data Transformation in Pandas**\n",
    "\n",
    "#### **a. Scaling and Normalization**\n",
    "\n",
    "Scaling and normalization adjust the values of numerical columns to make them comparable or to fit within a specific range.\n",
    "\n",
    "1. **Scaling Values**:\n",
    "   You can scale values by dividing by a constant or using a transformation function.\n",
    "\n",
    "   Example (scaling by dividing by the maximum value):\n",
    "\n",
    "   ```python\n",
    "   df['scaled_age'] = df['Age'] / df['Age'].max()\n",
    "   ```\n",
    "\n",
    "2. **Min-Max Normalization**:\n",
    "   Min-Max scaling rescales the data to a [0, 1] range.\n",
    "\n",
    "   ```python\n",
    "   df['Age_normalized'] = (df['Age'] - df['Age'].min()) / (df['Age'].max() - df['Age'].min())\n",
    "   ```\n",
    "\n",
    "3. **Standardization (Z-score normalization)**:\n",
    "   Z-score normalization transforms the data to have a mean of 0 and standard deviation of 1.\n",
    "   ```python\n",
    "   df['Age_standardized'] = (df['Age'] - df['Age'].mean()) / df['Age'].std()\n",
    "   ```\n",
    "\n",
    "#### **b. Handling Categorical Data (Encoding)**\n",
    "\n",
    "Categorical data (e.g., text or labels) often need to be converted to a numeric format for machine learning or analysis.\n",
    "\n",
    "1. **Label Encoding**:\n",
    "   `LabelEncoder` from **scikit-learn** assigns unique numeric labels to each category.\n",
    "\n",
    "   ```python\n",
    "   from sklearn.preprocessing import LabelEncoder\n",
    "   le = LabelEncoder()\n",
    "   df['Gender_encoded'] = le.fit_transform(df['Gender'])\n",
    "   ```\n",
    "\n",
    "2. **One-Hot Encoding**:\n",
    "   Converts categorical values into binary columns. This is useful when categories do not have an inherent order.\n",
    "\n",
    "   ```python\n",
    "   df = pd.get_dummies(df, columns=['City'])\n",
    "   ```\n",
    "\n",
    "3. **Categorical Data Type**:\n",
    "   Pandas provides `Categorical` type for memory efficiency and faster operations on categorical columns.\n",
    "   ```python\n",
    "   df['City'] = pd.Categorical(df['City'])\n",
    "   ```\n",
    "\n",
    "#### **c. Mapping and Replacing Values**\n",
    "\n",
    "You can map or replace values in columns using dictionaries or custom functions.\n",
    "\n",
    "1. **Using a Dictionary for Mapping**:\n",
    "\n",
    "   ```python\n",
    "   city_map = {'New York': 1, 'Los Angeles': 2, 'Chicago': 3}\n",
    "   df['City_mapped'] = df['City'].map(city_map)\n",
    "   ```\n",
    "\n",
    "2. **Using `.replace()` for Substitution**:\n",
    "   Replace specific values in a column.\n",
    "   ```python\n",
    "   df['Gender'] = df['Gender'].replace({'M': 'Male', 'F': 'Female'})\n",
    "   ```\n",
    "\n",
    "#### **d. Aggregation and Grouping**\n",
    "\n",
    "Aggregation refers to summarizing data (e.g., finding mean, sum, count, etc.) based on specific groups.\n",
    "\n",
    "1. **Group By**:\n",
    "   Group data by a specific column and perform aggregation.\n",
    "\n",
    "   ```python\n",
    "   grouped = df.groupby('City')['Age'].mean()  # Group by 'City' and find the mean of 'Age'\n",
    "   ```\n",
    "\n",
    "2. **Multiple Aggregations**:\n",
    "   You can perform multiple aggregation functions at once using `.agg()`.\n",
    "\n",
    "   ```python\n",
    "   grouped = df.groupby('City').agg({'Age': ['mean', 'min', 'max']})\n",
    "   ```\n",
    "\n",
    "3. **Custom Aggregations**:\n",
    "   You can define your custom aggregation function using `agg()` with a lambda function or pre-defined function.\n",
    "\n",
    "   ```python\n",
    "   grouped = df.groupby('City')['Age'].agg(lambda x: x.max() - x.min())  # Range of Age per City\n",
    "   ```\n",
    "\n",
    "4. **Aggregation with `pivot_table()`**:\n",
    "   Pivot tables allow you to reshape data and perform aggregation.\n",
    "   ```python\n",
    "   pivot = df.pivot_table(values='Age', index='City', columns='Gender', aggfunc='mean')\n",
    "   ```\n",
    "\n",
    "#### **e. Reshaping Data**\n",
    "\n",
    "Reshaping refers to changing the layout or structure of a DataFrame to better fit the analysis needs.\n",
    "\n",
    "1. **Pivoting**:\n",
    "   The `.pivot()` method is used to reshape data (convert rows into columns).\n",
    "\n",
    "   ```python\n",
    "   df_pivot = df.pivot(index='City', columns='Gender', values='Age')\n",
    "   ```\n",
    "\n",
    "2. **Melting**:\n",
    "   The `.melt()` method is the reverse of pivoting; it unpivots (converts columns into rows).\n",
    "\n",
    "   ```python\n",
    "   df_melted = df.melt(id_vars=['City'], value_vars=['Age', 'Gender'])\n",
    "   ```\n",
    "\n",
    "3. **Stacking and Unstacking**:\n",
    "\n",
    "   - `.stack()` converts columns into rows (creating a MultiIndex).\n",
    "   - `.unstack()` does the reverse (converts rows back into columns).\n",
    "\n",
    "   ```python\n",
    "   stacked = df.stack()\n",
    "   unstacked = stacked.unstack()\n",
    "   ```\n",
    "\n",
    "4. **Transpose**:\n",
    "   Transpose swaps rows and columns.\n",
    "   ```python\n",
    "   df_transposed = df.T\n",
    "   ```\n",
    "\n",
    "#### **f. String Transformation**\n",
    "\n",
    "Sometimes the data is in a string format that requires transformation, especially in textual data cleaning or feature engineering.\n",
    "\n",
    "1. **String Manipulation**:\n",
    "   Pandas provides `.str` accessor to perform string operations such as:\n",
    "\n",
    "   - `.str.lower()`: Converts text to lowercase.\n",
    "   - `.str.upper()`: Converts text to uppercase.\n",
    "   - `.str.strip()`: Removes leading and trailing whitespaces.\n",
    "   - `.str.replace()`: Replaces substrings.\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```python\n",
    "   df['City'] = df['City'].str.lower()  # Convert 'City' to lowercase\n",
    "   df['Name'] = df['Name'].str.strip()  # Remove extra spaces\n",
    "   df['City'] = df['City'].str.replace('new york', 'NYC')  # Replace values\n",
    "   ```\n",
    "\n",
    "2. **Extracting Patterns**:\n",
    "   Use `.str.extract()` to extract regular expression patterns from strings.\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```python\n",
    "   df['Year'] = df['Date'].str.extract(r'(\\d{4})')  # Extract year from 'Date'\n",
    "   ```\n",
    "\n",
    "#### **g. Applying Functions (map, apply, applymap)**\n",
    "\n",
    "1. **Using `map()`**:\n",
    "   Apply a function to a single column or Series.\n",
    "\n",
    "   ```python\n",
    "   df['Age'] = df['Age'].map(lambda x: x + 1)  # Increment age by 1\n",
    "   ```\n",
    "\n",
    "2. **Using `apply()`**:\n",
    "   Apply a function along the axis of a DataFrame (i.e., either rows or columns).\n",
    "\n",
    "   ```python\n",
    "   df['Age'] = df.apply(lambda row: row['Age'] + 1, axis=1)  # Apply function on rows\n",
    "   ```\n",
    "\n",
    "3. **Using `applymap()`**:\n",
    "   Apply a function element-wise on the entire DataFrame.\n",
    "   ```python\n",
    "   df = df.applymap(lambda x: len(str(x)))  # Apply a function to every element\n",
    "   ```\n",
    "\n",
    "#### **h. Window Functions and Rolling Operations**\n",
    "\n",
    "1. **Rolling Window Operations**:\n",
    "   You can perform operations over a sliding window of values, such as calculating the moving average.\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```python\n",
    "   df['Rolling_Mean'] = df['Age'].rolling(window=3).mean()  # 3-period moving average\n",
    "   ```\n",
    "\n",
    "2. **Expanding Window Operations**:\n",
    "   Expanding functions allow cumulative calculations.\n",
    "   ```python\n",
    "   df['Cumulative_Sum'] = df['Age'].expanding().sum()  # Cumulative sum of Age\n",
    "   ```\n",
    "\n",
    "#### **i. Conditional Transformation**\n",
    "\n",
    "1. **Using `apply()` with Conditions**:\n",
    "   You can apply conditional transformations based on column values.\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```python\n",
    "   df['Age'] = df['Age'].apply(lambda x: 0 if x < 18 else x)  # Set Age to 0 if less than 18\n",
    "   ```\n",
    "\n",
    "2. **Using `np.where()` for Conditional Transformation**:\n",
    "   `np.where()` can be used for conditional replacement or transformations.\n",
    "   ```python\n",
    "   df['Age'] = np.where(df['Age'] < 18, 0, df['Age'])  # Set Age to 0 if less than 18\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Conclusion**\n",
    "\n",
    "Data transformation is a vital step in data preprocessing that ensures your data is in the right form for analysis or machine learning tasks. In **Pandas**, you have a wide range of functions for transforming data, including scaling, encoding, aggregating, reshaping, and applying conditional operations. These tools allow you to modify and clean your data to fit your specific needs and prepare it for analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aggregation** and **Grouping** are crucial concepts in **data analysis** that allow you to summarize, analyze, and understand data by applying operations like sum, mean, count, etc., to subsets of the data. **Pandas** provides powerful tools for grouping and aggregating data in a **DataFrame** using the `groupby()` method.\n",
    "\n",
    "Here's a detailed breakdown of the concepts and theory behind **aggregation** and **grouping** in Pandas.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. What is Grouping and Aggregation?**\n",
    "\n",
    "- **Grouping**: The process of splitting data into subsets based on specific criteria. It allows you to perform operations on each group separately and then combine the results.\n",
    "- **Aggregation**: The process of applying a function (like sum, mean, etc.) to the groups to produce a summarized result.\n",
    "\n",
    "In **Pandas**, the `groupby()` method is used for both grouping and aggregation, enabling efficient data manipulation and analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. `groupby()` in Pandas**\n",
    "\n",
    "The `groupby()` function in Pandas is used to split the data into groups based on certain criteria (like column values) and apply aggregation functions on these groups.\n",
    "\n",
    "#### **Syntax:**\n",
    "\n",
    "```python\n",
    "df.groupby(by=<column(s)>)  # Group data by one or more columns\n",
    "```\n",
    "\n",
    "- `by`: The column(s) you want to group by. It can be a single column, a list of columns, or a function that defines the grouping.\n",
    "\n",
    "#### **Example:**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'City': ['New York', 'Los Angeles', 'Chicago', 'New York', 'Chicago', 'Los Angeles'],\n",
    "        'Age': [23, 25, 30, 22, 32, 29],\n",
    "        'Income': [60000, 70000, 80000, 65000, 75000, 72000]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Group by 'City' and get mean of the 'Age' and 'Income'\n",
    "grouped = df.groupby('City').mean()\n",
    "print(grouped)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "              Age   Income\n",
    "City\n",
    "Chicago       31.0  76500.0\n",
    "Los Angeles   27.0  71000.0\n",
    "New York      22.5  62500.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Aggregation Functions**\n",
    "\n",
    "Once the data is grouped, you can apply **aggregation functions** to perform operations like **sum**, **mean**, **count**, etc., on each group.\n",
    "\n",
    "#### **a. Common Aggregation Functions:**\n",
    "\n",
    "- **sum()**: Sum of values in each group.\n",
    "- **mean()**: Mean (average) of values in each group.\n",
    "- **median()**: Median value in each group.\n",
    "- **min()**: Minimum value in each group.\n",
    "- **max()**: Maximum value in each group.\n",
    "- **count()**: Number of non-null values in each group.\n",
    "- **std()**: Standard deviation of values in each group.\n",
    "- **var()**: Variance of values in each group.\n",
    "- **first()**: First non-null value in each group.\n",
    "- **last()**: Last non-null value in each group.\n",
    "- **sum()**, **prod()**, **quantile()**, **apply()** (for custom aggregation).\n",
    "\n",
    "#### **Example**:\n",
    "\n",
    "```python\n",
    "# Apply aggregation functions to 'Age' and 'Income' columns\n",
    "grouped = df.groupby('City').agg({'Age': 'mean', 'Income': 'sum'})\n",
    "print(grouped)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "              Age  Income\n",
    "City\n",
    "Chicago       31.0  151000\n",
    "Los Angeles   27.0  143000\n",
    "New York      22.5  127000\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Aggregating Multiple Columns with Different Functions**\n",
    "\n",
    "You can apply different aggregation functions to different columns by passing a dictionary to the `agg()` method.\n",
    "\n",
    "#### **Example:**\n",
    "\n",
    "```python\n",
    "# Applying different aggregation functions to different columns\n",
    "grouped = df.groupby('City').agg({'Age': 'mean', 'Income': 'sum'})\n",
    "print(grouped)\n",
    "```\n",
    "\n",
    "This gives the same result as before but allows flexibility when aggregating different columns using different functions.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Grouping by Multiple Columns**\n",
    "\n",
    "You can group by multiple columns to get more granular data breakdowns.\n",
    "\n",
    "#### **Example:**\n",
    "\n",
    "```python\n",
    "# Group by both 'City' and 'Age'\n",
    "df['Age_group'] = df['Age'].apply(lambda x: 'Young' if x < 30 else 'Old')\n",
    "grouped = df.groupby(['City', 'Age_group']).agg({'Income': 'sum', 'Age': 'mean'})\n",
    "print(grouped)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "                    Age  Income\n",
    "City        Age_group\n",
    "Chicago     Old       31.5   151000\n",
    "            Young     30.0    76500\n",
    "Los Angeles Old       29.0   72000\n",
    "            Young     25.5   140000\n",
    "New York    Old       22.5    62500\n",
    "            Young     23.0    64500\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Custom Aggregation Functions with `apply()`**\n",
    "\n",
    "If you need custom aggregation, you can use `apply()` to define a function to apply to each group.\n",
    "\n",
    "#### **Example (Custom Aggregation)**:\n",
    "\n",
    "```python\n",
    "# Define a custom aggregation function to calculate range (max - min) of 'Age'\n",
    "grouped = df.groupby('City').agg({'Age': lambda x: x.max() - x.min()})\n",
    "print(grouped)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "              Age\n",
    "City\n",
    "Chicago       10\n",
    "Los Angeles   4\n",
    "New York      1\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Advanced Grouping Techniques**\n",
    "\n",
    "#### **a. Grouping with `.transform()`**\n",
    "\n",
    "While `groupby()` with aggregation reduces the size of the data (returns one row per group), you might want to keep the original shape of the data. In this case, you can use the `.transform()` method to apply a function to each group while keeping the original number of rows.\n",
    "\n",
    "#### **Example:**\n",
    "\n",
    "```python\n",
    "# Using transform to calculate the mean 'Age' for each group and keep original data shape\n",
    "df['Age_mean'] = df.groupby('City')['Age'].transform('mean')\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "          City  Age  Income  Age_mean\n",
    "0     New York   23   60000      22.5\n",
    "1  Los Angeles   25   70000      27.0\n",
    "2     Chicago   30   80000      31.0\n",
    "3     New York   22   65000      22.5\n",
    "4     Chicago   32   75000      31.0\n",
    "5  Los Angeles   29   72000      27.0\n",
    "```\n",
    "\n",
    "#### **b. Grouping with `.filter()`**\n",
    "\n",
    "`.filter()` allows you to filter groups based on a condition. It returns only groups that meet the condition.\n",
    "\n",
    "#### **Example (Filtering groups):**\n",
    "\n",
    "```python\n",
    "# Filter groups where the mean 'Age' is greater than 25\n",
    "filtered = df.groupby('City').filter(lambda x: x['Age'].mean() > 25)\n",
    "print(filtered)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "          City  Age  Income\n",
    "2     Chicago   30   80000\n",
    "4     Chicago   32   75000\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Pivot Tables**\n",
    "\n",
    "A **pivot table** is a way of summarizing data by creating a cross-tabulation of data. It's useful for getting a matrix-style summary, where one axis contains the rows, and another contains the columns.\n",
    "\n",
    "#### **Example (Pivot Table):**\n",
    "\n",
    "```python\n",
    "# Create a pivot table to get mean of 'Age' and 'Income' based on 'City' and 'Age_group'\n",
    "pivot = df.pivot_table(values=['Age', 'Income'], index='City', columns='Age_group', aggfunc='mean')\n",
    "print(pivot)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "              Age               Income\n",
    "Age_group     Old Young      Old    Young\n",
    "City\n",
    "Chicago     31.0  30.0  151000   76500\n",
    "Los Angeles 29.0  25.5  72000  140000\n",
    "New York    22.5  23.0  62500   64500\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Handling Missing Data with Grouping**\n",
    "\n",
    "When working with groups, missing data in any of the columns can affect the result. You can handle missing data before applying groupby operations using `.fillna()` or `.dropna()`.\n",
    "\n",
    "#### **Example:**\n",
    "\n",
    "```python\n",
    "# Replace missing values in 'Income' with 0 before applying aggregation\n",
    "df['Income'] = df['Income'].fillna(0)\n",
    "grouped = df.groupby('City')['Income'].sum()\n",
    "print(grouped)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Conclusion**\n",
    "\n",
    "- **Grouping** and **Aggregation** are powerful techniques in Pandas that allow you to efficiently analyze and summarize large datasets.\n",
    "- The `groupby()` method allows you to group data based on one or more columns and apply aggregation functions like sum, mean, count, etc., to each group.\n",
    "- You can apply **multiple aggregation functions**, use **custom functions**, and reshape the data using techniques like **pivot tables** and **transform**.\n",
    "- Grouping and aggregation can also be combined with filtering and handling missing values for more comprehensive data analysis.\n",
    "\n",
    "These concepts form the foundation for analyzing large datasets, particularly when you need to extract meaningful insights from subsets of your data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pivoting** and **reshaping** are important techniques in **data analysis** that help reorganize data into a different format for easier analysis or visualization. In **Pandas**, pivoting refers to reshaping data from a long format to a wide format, and reshaping encompasses various techniques to change the structure of a **DataFrame**.\n",
    "\n",
    "Here's a comprehensive breakdown of **pivoting** and **reshaping** concepts and methods in **Pandas**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. What is Pivoting and Reshaping?**\n",
    "\n",
    "- **Pivoting**: Pivoting involves reshaping data, typically from a long format (where each row represents an observation) to a wide format (where data is summarized, with unique column values). It’s especially useful when you want to convert categories into separate columns.\n",
    "\n",
    "- **Reshaping**: Reshaping refers to transforming the structure or shape of the dataset, such as changing the way rows and columns are organized. This can involve **pivoting**, **melting**, **stacking**, **unstacking**, and **transposing**.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Pivoting in Pandas**\n",
    "\n",
    "Pivoting in **Pandas** is done using the `.pivot()` and `.pivot_table()` functions. Pivoting is useful when you want to restructure data based on a categorical column to create summary tables.\n",
    "\n",
    "#### **a. Using `.pivot()`**\n",
    "\n",
    "The `.pivot()` function reshapes data based on column values, turning unique values from one column into multiple columns.\n",
    "\n",
    "#### **Syntax:**\n",
    "\n",
    "```python\n",
    "df.pivot(index=<index>, columns=<columns>, values=<values>)\n",
    "```\n",
    "\n",
    "- `index`: The column to use as the index (rows).\n",
    "- `columns`: The column to turn into new columns.\n",
    "- `values`: The column whose values will fill the table.\n",
    "\n",
    "#### **Example**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'City': ['New York', 'Los Angeles', 'Chicago', 'New York', 'Chicago', 'Los Angeles'],\n",
    "        'Age': [23, 25, 30, 22, 32, 29],\n",
    "        'Income': [60000, 70000, 80000, 65000, 75000, 72000]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Pivot: Create a table with 'City' as the index and 'Age' and 'Income' as columns\n",
    "pivoted_df = df.pivot(index='City', columns='Age', values='Income')\n",
    "print(pivoted_df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Age            22    23    25    29    30    32\n",
    "City\n",
    "Chicago        NaN   NaN   NaN  75000  80000  75000\n",
    "Los Angeles    NaN   NaN  70000  72000   NaN   NaN\n",
    "New York      65000 60000   NaN   NaN   NaN   NaN\n",
    "```\n",
    "\n",
    "- **Note**: If there are multiple entries for the same combination of `index` and `columns`, `.pivot()` will raise a `ValueError`. For such cases, you should use `.pivot_table()`.\n",
    "\n",
    "#### **b. Using `.pivot_table()`**\n",
    "\n",
    "The `.pivot_table()` method is more flexible than `.pivot()`. It can handle duplicate entries by applying aggregation functions like `mean`, `sum`, `count`, etc., to the duplicate values.\n",
    "\n",
    "#### **Syntax:**\n",
    "\n",
    "```python\n",
    "df.pivot_table(index=<index>, columns=<columns>, values=<values>, aggfunc=<aggregation function>)\n",
    "```\n",
    "\n",
    "- `aggfunc`: The aggregation function to apply in case of duplicate entries (default is `mean`).\n",
    "\n",
    "#### **Example (Pivot Table)**:\n",
    "\n",
    "```python\n",
    "# Pivot table with aggregation (e.g., mean) for duplicate entries\n",
    "pivot_table_df = df.pivot_table(index='City', columns='Age', values='Income', aggfunc='mean')\n",
    "print(pivot_table_df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Age            22    23    25    29    30    32\n",
    "City\n",
    "Chicago      65000  60000   NaN  75000  80000  75000\n",
    "Los Angeles  65000  70000  70000  72000   NaN   NaN\n",
    "New York     65000  60000   NaN   NaN   NaN   NaN\n",
    "```\n",
    "\n",
    "- The table now handles duplicate entries (i.e., multiple rows for `City = 'New York'` with the same `Age = 23`) by taking the mean of the `Income` column.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Reshaping Methods in Pandas**\n",
    "\n",
    "Pandas provides several functions to reshape data, depending on how you need to reorganize the DataFrame. The most common reshaping methods include **melt**, **stack**, **unstack**, **transpose**, and **pivoting**.\n",
    "\n",
    "#### **a. Melting (`melt()`)**\n",
    "\n",
    "The `melt()` function is used to convert a wide DataFrame into a long (or tidy) format. This is useful when you want to convert columns into rows, making it easier to work with the data in a format suitable for analysis or visualization.\n",
    "\n",
    "#### **Syntax:**\n",
    "\n",
    "```python\n",
    "df.melt(id_vars=<columns to keep>, value_vars=<columns to unpivot>)\n",
    "```\n",
    "\n",
    "- `id_vars`: Columns that should remain as they are (e.g., grouping columns).\n",
    "- `value_vars`: Columns that should be \"melted\" into rows.\n",
    "\n",
    "#### **Example**:\n",
    "\n",
    "```python\n",
    "# Melt the DataFrame to turn columns into rows\n",
    "melted_df = df.melt(id_vars='City', value_vars=['Age', 'Income'])\n",
    "print(melted_df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "          City variable  value\n",
    "0     New York      Age     23\n",
    "1  Los Angeles      Age     25\n",
    "2     Chicago      Age     30\n",
    "3     New York      Age     22\n",
    "4     Chicago      Age     32\n",
    "5  Los Angeles      Age     29\n",
    "6     New York    Income  60000\n",
    "7  Los Angeles    Income  70000\n",
    "8     Chicago    Income  80000\n",
    "9     New York    Income  65000\n",
    "10    Chicago    Income  75000\n",
    "11  Los Angeles    Income  72000\n",
    "```\n",
    "\n",
    "Here, the `Age` and `Income` columns were converted into a single column, with the corresponding values for each city.\n",
    "\n",
    "#### **b. Stacking and Unstacking (`stack()` and `unstack()`)**\n",
    "\n",
    "- **Stacking**: Converts columns to rows, creating a **MultiIndex**.\n",
    "- **Unstacking**: Converts rows back to columns, removing the **MultiIndex**.\n",
    "\n",
    "#### **Syntax for `stack()`**:\n",
    "\n",
    "```python\n",
    "df.stack()\n",
    "```\n",
    "\n",
    "#### **Syntax for `unstack()`**:\n",
    "\n",
    "```python\n",
    "df.unstack()\n",
    "```\n",
    "\n",
    "#### **Example**:\n",
    "\n",
    "```python\n",
    "# Stack: Convert columns to rows\n",
    "stacked_df = df.set_index(['City', 'Age']).stack()\n",
    "print(stacked_df)\n",
    "\n",
    "# Unstack: Convert rows back to columns\n",
    "unstacked_df = stacked_df.unstack()\n",
    "print(unstacked_df)\n",
    "```\n",
    "\n",
    "**Output (Stacked):**\n",
    "\n",
    "```\n",
    "City        Age\n",
    "Chicago     30    Income    80000\n",
    "            32    Income    75000\n",
    "Los Angeles 25    Income    70000\n",
    "            29    Income    72000\n",
    "New York    22    Income    65000\n",
    "            23    Income    60000\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "**Output (Unstacked):**\n",
    "\n",
    "```\n",
    "Age            22    23    25    29    30    32\n",
    "City\n",
    "Chicago      65000  60000   NaN  75000  80000  75000\n",
    "Los Angeles  65000  70000  70000  72000   NaN   NaN\n",
    "New York     65000  60000   NaN   NaN   NaN   NaN\n",
    "```\n",
    "\n",
    "#### **c. Transpose (`T`)**\n",
    "\n",
    "The `.T` attribute is used to transpose a DataFrame, switching rows and columns.\n",
    "\n",
    "#### **Example**:\n",
    "\n",
    "```python\n",
    "# Transpose the DataFrame\n",
    "transposed_df = df.T\n",
    "print(transposed_df)\n",
    "```\n",
    "\n",
    "**Output (Transposed):**\n",
    "\n",
    "```\n",
    "               0             1         2         3        4         5\n",
    "City     New York  Los Angeles  Chicago  New York  Chicago  Los Angeles\n",
    "Age            23            25       30        22       32            29\n",
    "Income     60000         70000     80000     65000     75000         72000\n",
    "```\n",
    "\n",
    "#### **d. `.pivot()` vs. `.pivot_table()`**\n",
    "\n",
    "- **`.pivot()`** is used for simple reshaping where there's no aggregation.\n",
    "- **`.pivot_table()`** is more powerful because it allows for **aggregation** of duplicate values (using functions like `mean`, `sum`, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Conclusion**\n",
    "\n",
    "Pivoting and reshaping are key techniques for transforming data into the right format for analysis or visualization. Here's a summary of key methods:\n",
    "\n",
    "- **Pivoting**:\n",
    "\n",
    "  - **`.pivot()`**: Turns unique column values into separate columns.\n",
    "  - **`.pivot_table()`**: Similar to `.pivot()` but can handle duplicates and supports aggregation.\n",
    "\n",
    "- **Reshaping**:\n",
    "  - **`.melt()`**: Converts wide format into long format by melting columns into rows.\n",
    "  - **`.stack()` and `.unstack()`**: Convert rows to columns (stack) and columns to rows (unstack).\n",
    "  - **`.T`**: Transposes the DataFrame by switching rows and columns.\n",
    "\n",
    "These techniques help you structure and manipulate data to fit your analytical needs, making data processing and visualization much more efficient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Creating DataFrames in Pandas: A Complete Guide with Syntax**\n",
    "\n",
    "Pandas DataFrames are 2-dimensional labeled data structures that are fundamental to data analysis in Python. Here's a comprehensive guide to creating DataFrames with various methods:\n",
    "\n",
    "## **1. Basic DataFrame Creation**\n",
    "\n",
    "### **From a Dictionary**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'City': ['NY', 'LA', 'Chicago']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "      Name  Age     City\n",
    "0    Alice   25       NY\n",
    "1      Bob   30       LA\n",
    "2  Charlie   35  Chicago\n",
    "```\n",
    "\n",
    "### **From Lists of Lists**\n",
    "\n",
    "```python\n",
    "data = [\n",
    "    ['Alice', 25, 'NY'],\n",
    "    ['Bob', 30, 'LA'],\n",
    "    ['Charlie', 35, 'Chicago']\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Name', 'Age', 'City'])\n",
    "print(df)\n",
    "```\n",
    "\n",
    "## **2. Specialized DataFrame Creation Methods**\n",
    "\n",
    "### **From CSV Files**\n",
    "\n",
    "```python\n",
    "df = pd.read_csv('data.csv')\n",
    "```\n",
    "\n",
    "### **From Excel Files**\n",
    "\n",
    "```python\n",
    "df = pd.read_excel('data.xlsx', sheet_name='Sheet1')\n",
    "```\n",
    "\n",
    "### **From JSON**\n",
    "\n",
    "```python\n",
    "df = pd.read_json('data.json')\n",
    "```\n",
    "\n",
    "### **From SQL Database**\n",
    "\n",
    "```python\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('database.db')\n",
    "df = pd.read_sql('SELECT * FROM table_name', conn)\n",
    "```\n",
    "\n",
    "## **3. Advanced DataFrame Creation**\n",
    "\n",
    "### **From NumPy Arrays**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "arr = np.array([\n",
    "    [1, 'Alice', 25],\n",
    "    [2, 'Bob', 30],\n",
    "    [3, 'Charlie', 35]\n",
    "])\n",
    "\n",
    "df = pd.DataFrame(arr, columns=['ID', 'Name', 'Age'])\n",
    "```\n",
    "\n",
    "### **From List of Dictionaries**\n",
    "\n",
    "```python\n",
    "data = [\n",
    "    {'Name': 'Alice', 'Age': 25, 'City': 'NY'},\n",
    "    {'Name': 'Bob', 'Age': 30, 'City': 'LA'},\n",
    "    {'Name': 'Charlie', 'Age': 35, 'City': 'Chicago'}\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "### **Empty DataFrame**\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame(columns=['Name', 'Age', 'City'])\n",
    "```\n",
    "\n",
    "## **4. DataFrame with Index Control**\n",
    "\n",
    "### **Custom Index**\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame(\n",
    "    data,\n",
    "    index=['A', 'B', 'C']  # Custom row labels\n",
    ")\n",
    "```\n",
    "\n",
    "### **Range Index**\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame(data, index=pd.RangeIndex(start=10, stop=13))\n",
    "```\n",
    "\n",
    "## **5. DataFrame with Different Data Types**\n",
    "\n",
    "### **Mixed Data Types**\n",
    "\n",
    "```python\n",
    "data = {\n",
    "    'Integer': [1, 2, 3],\n",
    "    'Float': [1.1, 2.2, 3.3],\n",
    "    'String': ['A', 'B', 'C'],\n",
    "    'Boolean': [True, False, True],\n",
    "    'Datetime': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03'])\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "## **6. DataFrame from External Sources**\n",
    "\n",
    "### **From Clipboard**\n",
    "\n",
    "```python\n",
    "df = pd.read_clipboard()  # Copies data from Excel/CSV in clipboard\n",
    "```\n",
    "\n",
    "### **From HTML Tables**\n",
    "\n",
    "```python\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_GDP'\n",
    "tables = pd.read_html(url)\n",
    "df = tables[0]  # First table on the page\n",
    "```\n",
    "\n",
    "## **7. DataFrame Manipulation After Creation**\n",
    "\n",
    "### **Adding Columns**\n",
    "\n",
    "```python\n",
    "df['Salary'] = [50000, 60000, 70000]\n",
    "```\n",
    "\n",
    "### **Adding Rows**\n",
    "\n",
    "```python\n",
    "new_row = {'Name': 'David', 'Age': 40, 'City': 'Boston'}\n",
    "df = df.append(new_row, ignore_index=True)\n",
    "```\n",
    "\n",
    "### **Setting Index**\n",
    "\n",
    "```python\n",
    "df.set_index('Name', inplace=True)\n",
    "```\n",
    "\n",
    "## **8. DataFrame Inspection Methods**\n",
    "\n",
    "```python\n",
    "df.head()      # First 5 rows\n",
    "df.tail()      # Last 5 rows\n",
    "df.shape       # (rows, columns)\n",
    "df.dtypes      # Data types of columns\n",
    "df.info()      # Summary info\n",
    "df.describe()  # Statistical summary\n",
    "```\n",
    "\n",
    "## **9. Best Practices**\n",
    "\n",
    "1. **Specify `dtypes` when possible** for memory efficiency:\n",
    "\n",
    "   ```python\n",
    "   dtypes = {'Age': 'int8', 'Salary': 'float32'}\n",
    "   df = pd.DataFrame(data, dtype=dtypes)\n",
    "   ```\n",
    "\n",
    "2. **Use `copy()`** when creating derived DataFrames to avoid SettingWithCopyWarning:\n",
    "\n",
    "   ```python\n",
    "   new_df = df.copy()\n",
    "   ```\n",
    "\n",
    "3. **Set meaningful indexes** for faster lookups:\n",
    "\n",
    "   ```python\n",
    "   df.set_index('ID', inplace=True)\n",
    "   ```\n",
    "\n",
    "4. **Handle missing data** early:\n",
    "   ```python\n",
    "   df = pd.DataFrame(data).dropna()  # Remove rows with missing values\n",
    "   ```\n",
    "\n",
    "This comprehensive guide covers all major ways to create and initialize Pandas DataFrames with proper syntax and examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! **Pandas DataFrames** are powerful for data analysis, transformation, and manipulation. Here’s how you can **modify and analyze** a DataFrame effectively.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Modifying DataFrames**\n",
    "\n",
    "#### 🔹 **Adding Columns**\n",
    "\n",
    "You can add a new column dynamically:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Name': ['Alice', 'Bob'], 'Age': [25, 30]})\n",
    "\n",
    "df['City'] = ['New York', 'Los Angeles']  # Adding a new column\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "#### 🔹 **Updating Values**\n",
    "\n",
    "Modify specific values using `.loc[]`:\n",
    "\n",
    "```python\n",
    "df.loc[1, 'Age'] = 35  # Update Bob's age\n",
    "```\n",
    "\n",
    "#### 🔹 **Deleting Columns or Rows**\n",
    "\n",
    "```python\n",
    "df.drop(columns=['City'], inplace=True)  # Remove a column\n",
    "df.drop(index=[0], inplace=True)  # Remove a row\n",
    "```\n",
    "\n",
    "#### 🔹 **Renaming Columns**\n",
    "\n",
    "```python\n",
    "df.rename(columns={'Age': 'Years'}, inplace=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Analyzing DataFrames**\n",
    "\n",
    "#### 🔹 **Basic Data Overview**\n",
    "\n",
    "```python\n",
    "df.info()  # Summary of the dataset\n",
    "df.describe()  # Statistical summary\n",
    "df.head(3)  # First 3 rows\n",
    "df.tail(3)  # Last 3 rows\n",
    "```\n",
    "\n",
    "#### 🔹 **Filtering Data**\n",
    "\n",
    "```python\n",
    "df[df['Age'] > 25]  # Select rows where Age is greater than 25\n",
    "```\n",
    "\n",
    "#### 🔹 **Sorting Data**\n",
    "\n",
    "```python\n",
    "df.sort_values(by='Age', ascending=False, inplace=True)\n",
    "```\n",
    "\n",
    "#### 🔹 **Grouping & Aggregation**\n",
    "\n",
    "```python\n",
    "df.groupby('City')['Age'].mean()  # Average age per city\n",
    "```\n",
    "\n",
    "#### 🔹 **Handling Missing Values**\n",
    "\n",
    "```python\n",
    "df.dropna(inplace=True)  # Remove rows with missing values\n",
    "df.fillna('Unknown', inplace=True)  # Replace missing values\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping data in pandas is a crucial skill for data analysis and manipulation. It allows you to transform the structure of your DataFrame to better suit your analysis needs. Let's explore the common reshaping operations with code examples.\n",
    "\n",
    "**1. `melt()`: Unpivoting from Wide to Long Format**\n",
    "\n",
    "The `melt()` function is used to transform a DataFrame from a \"wide\" format (where different variables are spread across columns) to a \"long\" format (where variables are stacked into rows).\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {'ID': [1, 2, 3],\n",
    "        'Math': [80, 90, 75],\n",
    "        'Science': [85, 88, 92],\n",
    "        'English': [78, 82, 86]}\n",
    "df_wide = pd.DataFrame(data)\n",
    "print(\"Wide DataFrame:\")\n",
    "print(df_wide)\n",
    "\n",
    "df_long = pd.melt(df_wide,\n",
    "                  id_vars=['ID'],\n",
    "                  value_vars=['Math', 'Science', 'English'],\n",
    "                  var_name='Subject',\n",
    "                  value_name='Score')\n",
    "print(\"\\nLong DataFrame:\")\n",
    "print(df_long)\n",
    "```\n",
    "\n",
    "**Syntax:**\n",
    "\n",
    "```python\n",
    "pd.melt(df, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None, ignore_index=True)\n",
    "```\n",
    "\n",
    "- `df`: The DataFrame to melt.\n",
    "- `id_vars` (optional): Column(s) to use as identifier variables. These columns will remain unchanged.\n",
    "- `value_vars` (optional): Column(s) to unpivot. If not specified, all columns not in `id_vars` will be used.\n",
    "- `var_name` (optional): Name to use for the column representing the variables (default is 'variable').\n",
    "- `value_name` (optional): Name to use for the column representing the values (default is 'value').\n",
    "- `col_level` (optional): If columns are multi-indexed, specifies the level to use.\n",
    "- `ignore_index` (bool, default True): If True, the original index is ignored, and a new default integer index is created.\n",
    "\n",
    "**2. `pivot()`: Pivoting from Long to Wide Format**\n",
    "\n",
    "The `pivot()` function is the inverse of `melt()`. It transforms a DataFrame from a \"long\" format to a \"wide\" format.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data_long = {'ID': [1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
    "             'Subject': ['Math', 'Science', 'English', 'Math', 'Science', 'English', 'Math', 'Science', 'English'],\n",
    "             'Score': [80, 85, 78, 90, 88, 82, 75, 92, 86]}\n",
    "df_long = pd.DataFrame(data_long)\n",
    "print(\"Long DataFrame:\")\n",
    "print(df_long)\n",
    "\n",
    "df_pivot = df_long.pivot(index='ID', columns='Subject', values='Score')\n",
    "print(\"\\nPivot DataFrame:\")\n",
    "print(df_pivot)\n",
    "```\n",
    "\n",
    "**Syntax:**\n",
    "\n",
    "```python\n",
    "df.pivot(index=None, columns=None, values=None)\n",
    "```\n",
    "\n",
    "- `index`: Column to use to make new frame's index.\n",
    "- `columns`: Column to use to make new frame's columns.\n",
    "- `values`: Column(s) to use for populating the new frame's values. If not specified, all remaining columns will be used.\n",
    "\n",
    "**Note:** If there are duplicate entries for the combination of `index` and `columns`, `pivot()` will raise a `ValueError`.\n",
    "\n",
    "**3. `pivot_table()`: Creating Pivot Tables (Handling Duplicates)**\n",
    "\n",
    "The `pivot_table()` function is similar to `pivot()`, but it can handle duplicate entries by allowing you to specify an aggregation function (e.g., mean, sum, count).\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_duplicate = {'ID': [1, 1, 1, 2, 2, 2, 1, 3, 3],\n",
    "                  'Subject': ['Math', 'Science', 'English', 'Math', 'Science', 'English', 'Math', 'Science', 'English'],\n",
    "                  'Score': [80, 85, 78, 90, 88, 82, 82, 92, 86]}\n",
    "df_duplicate = pd.DataFrame(data_duplicate)\n",
    "print(\"DataFrame with Duplicates:\")\n",
    "print(df_duplicate)\n",
    "\n",
    "pivot_table_mean = pd.pivot_table(df_duplicate, index='ID', columns='Subject', values='Score', aggfunc='mean')\n",
    "print(\"\\nPivot Table (Mean):\")\n",
    "print(pivot_table_mean)\n",
    "\n",
    "pivot_table_count = pd.pivot_table(df_duplicate, index='ID', columns='Subject', values='Score', aggfunc='count')\n",
    "print(\"\\nPivot Table (Count):\")\n",
    "print(pivot_table_count)\n",
    "```\n",
    "\n",
    "**Syntax:**\n",
    "\n",
    "```python\n",
    "pd.pivot_table(data, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All', observed=False)\n",
    "```\n",
    "\n",
    "- `data`: The DataFrame to create the pivot table from.\n",
    "- `values` (optional): Column(s) to aggregate.\n",
    "- `index`: Column(s) to group by on the rows of the pivot table.\n",
    "- `columns`: Column(s) to group by on the columns of the pivot table.\n",
    "- `aggfunc` (default 'mean'): Function to use for aggregation (e.g., 'mean', 'sum', 'count', 'min', 'max', a list of functions).\n",
    "- `fill_value` (optional): Value to replace missing values (NaN) in the resulting pivot table.\n",
    "- `margins` (bool, default False): Add all row / column totals.\n",
    "- `dropna` (bool, default True): Do not include columns whose entries are all NaN.\n",
    "- `margins_name` (str, default 'All'): Name of the row/column that will contain the totals when `margins=True`.\n",
    "- `observed` (bool, default False): For categorical groupers, show only observed values.\n",
    "\n",
    "**4. `stack()`: Pivoting from Wide to Long (for MultiIndex)**\n",
    "\n",
    "The `stack()` function is used to move columns from the widest level of a MultiIndex to the innermost level of the index, resulting in a Series or a DataFrame with a MultiIndex.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data_multi = {'ID': [1, 2],\n",
    "              ('Math', '2022'): [80, 90],\n",
    "              ('Math', '2023'): [85, 92],\n",
    "              ('Science', '2022'): [78, 88],\n",
    "              ('Science', '2023'): [82, 95]}\n",
    "df_multi = pd.DataFrame(data_multi)\n",
    "df_multi.columns = pd.MultiIndex.from_tuples(df_multi.columns)\n",
    "print(\"MultiIndex DataFrame:\")\n",
    "print(df_multi)\n",
    "\n",
    "df_stacked = df_multi.stack()\n",
    "print(\"\\nStacked DataFrame:\")\n",
    "print(df_stacked)\n",
    "\n",
    "df_stacked_level0 = df_multi.stack(level=0)\n",
    "print(\"\\nStacked DataFrame (level=0):\")\n",
    "print(df_stacked_level0)\n",
    "```\n",
    "\n",
    "**Syntax:**\n",
    "\n",
    "```python\n",
    "df.stack(level=-1, dropna=True)\n",
    "```\n",
    "\n",
    "- `level` (int, str, list-like, default -1): Level(s) of the column index to stack (can be index name or number).\n",
    "- `dropna` (bool, default True): Whether to drop rows with missing values in the stacked output.\n",
    "\n",
    "**5. `unstack()`: Pivoting from Long to Wide (for MultiIndex)**\n",
    "\n",
    "The `unstack()` function is the inverse of `stack()`. It moves a level from the innermost level of the index to become the new columns.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data_multi = {'ID': [1, 2],\n",
    "              ('Math', '2022'): [80, 90],\n",
    "              ('Math', '2023'): [85, 92],\n",
    "              ('Science', '2022'): [78, 88],\n",
    "              ('Science', '2023'): [82, 95]}\n",
    "df_multi = pd.DataFrame(data_multi)\n",
    "df_multi.columns = pd.MultiIndex.from_tuples(df_multi.columns)\n",
    "df_stacked = df_multi.stack()\n",
    "print(\"Stacked DataFrame:\")\n",
    "print(df_stacked)\n",
    "\n",
    "df_unstacked = df_stacked.unstack()\n",
    "print(\"\\nUnstacked DataFrame:\")\n",
    "print(df_unstacked)\n",
    "\n",
    "df_unstacked_level0 = df_stacked.unstack(level=0)\n",
    "print(\"\\nUnstacked DataFrame (level=0):\")\n",
    "print(df_unstacked_level0)\n",
    "```\n",
    "\n",
    "**Syntax:**\n",
    "\n",
    "```python\n",
    "s.unstack(level=-1, fill_value=None)\n",
    "```\n",
    "\n",
    "- `level` (int, str, list-like, default -1): Level(s) of the index to unstack (can be index name or number).\n",
    "- `fill_value` (scalar, optional): Value to substitute for missing values in the unstacked result.\n",
    "\n",
    "**6. `explode()`: Transforming List-like or Tuple-like Entries to Rows**\n",
    "\n",
    "The `explode()` function transforms each element of a list-like or tuple-like entry in a DataFrame's column into a separate row, replicating the other column values.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data_list = {'ID': [1, 2, 3],\n",
    "             'Subjects': [['Math', 'Science'], ['English'], ['Physics', 'Chemistry', 'Biology']]}\n",
    "df_list = pd.DataFrame(data_list)\n",
    "print(\"DataFrame with List Entries:\")\n",
    "print(df_list)\n",
    "\n",
    "df_exploded = df_list.explode('Subjects')\n",
    "print(\"\\nExploded DataFrame:\")\n",
    "print(df_exploded)\n",
    "\n",
    "data_tuple = {'ID': [4, 5],\n",
    "              'Coordinates': [(10, 20), (30, 40, 50)]}\n",
    "df_tuple = pd.DataFrame(data_tuple)\n",
    "print(\"\\nDataFrame with Tuple Entries:\")\n",
    "print(df_tuple)\n",
    "\n",
    "df_exploded_tuple = df_tuple.explode('Coordinates')\n",
    "print(\"\\nExploded DataFrame (Tuple):\")\n",
    "print(df_exploded_tuple)\n",
    "```\n",
    "\n",
    "**Syntax:**\n",
    "\n",
    "```python\n",
    "df.explode(column, ignore_index=False)\n",
    "```\n",
    "\n",
    "- `column`: The column to explode. The entries in this column must be list-like (lists, tuples, Series) or ndarray.\n",
    "- `ignore_index` (bool, default False): If True, the resulting index will be labeled 0, 1, …, n-1.\n",
    "\n",
    "These are the fundamental reshaping techniques in pandas. Understanding and applying these methods will significantly enhance your ability to manipulate and analyze data effectively. Do you have any specific reshaping task in mind that you'd like to explore further?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the `pd.concat()` function in pandas. It's your go-to tool for combining pandas objects (Series or DataFrames) along a particular axis. Here's the syntax and various code examples to illustrate its power.\n",
    "\n",
    "**Syntax:**\n",
    "\n",
    "```python\n",
    "pd.concat(objs, axis=0, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, sort=False, copy=True)\n",
    "```\n",
    "\n",
    "Let's break down the key parameters:\n",
    "\n",
    "- **`objs`**: This is a sequence (like a list or tuple) of pandas objects you want to concatenate. **This is the only required argument.**\n",
    "- **`axis`**: Specifies the axis along which to concatenate.\n",
    "  - `0` or `'index'` (default): Concatenate along the rows (vertically).\n",
    "  - `1` or `'columns'`: Concatenate along the columns (horizontally).\n",
    "- **`join`**: How to handle indexes on the other axis(es).\n",
    "  - `'outer'` (default): Use a union of all indexes. Missing values will be filled with `NaN`.\n",
    "  - `'inner'`: Use the intersection of the indexes. Only rows/columns with labels present in all input objects will be included.\n",
    "- **`ignore_index`**: If `True`, do not use the index values along the concatenation axis. The resulting axis will be labeled `0, 1, ..., n-1`. This is useful when you have misaligned or irrelevant indexes.\n",
    "- **`keys`**: Sequence of values (e.g., a list) to associate with each of the passed objects along the concatenation axis. These values will form a level in a hierarchical index (MultiIndex).\n",
    "- **`levels`**: Specific levels (unique values from `keys`) to be used for constructing a MultiIndex. Otherwise, the levels will be inferred from the `keys`.\n",
    "- **`names`**: List of names for the created hierarchical index levels if `keys` or `levels` are provided.\n",
    "- **`verify_integrity`**: If `True`, check whether the new concatenated axis contains duplicates. If it does, raise a `ValueError`.\n",
    "- **`sort`**: If `True`, sort the non-concatenation axis if it is not already aligned. This can be useful for consistent results. (Added in pandas 0.23.0)\n",
    "- **`copy`**: If `False`, try to avoid unnecessary copying of data. Note that this might still result in copies under certain circumstances.\n",
    "\n",
    "Now, let's see these parameters in action with code examples:\n",
    "\n",
    "**Example 1: Concatenating DataFrames Vertically (along rows)**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "df2 = pd.DataFrame({'A': [7, 8], 'B': [9, 10]})\n",
    "\n",
    "df_concat_vertical = pd.concat([df1, df2])\n",
    "print(\"Vertical Concatenation:\\n\", df_concat_vertical)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Vertical Concatenation:\n",
    "    A   B\n",
    "0  1   4\n",
    "1  2   5\n",
    "2  3   6\n",
    "0  7   9\n",
    "1  8  10\n",
    "```\n",
    "\n",
    "Notice that the index is preserved from the original DataFrames.\n",
    "\n",
    "**Example 2: Concatenating DataFrames Vertically and Resetting the Index**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "df2 = pd.DataFrame({'A': [7, 8], 'B': [9, 10]})\n",
    "\n",
    "df_concat_ignore_index = pd.concat([df1, df2], ignore_index=True)\n",
    "print(\"\\nVertical Concatenation with Reset Index:\\n\", df_concat_ignore_index)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Vertical Concatenation with Reset Index:\n",
    "    A   B\n",
    "0  1   4\n",
    "1  2   5\n",
    "2  3   6\n",
    "3  7   9\n",
    "4  8  10\n",
    "```\n",
    "\n",
    "Here, `ignore_index=True` created a new sequential index.\n",
    "\n",
    "**Example 3: Concatenating DataFrames Horizontally (along columns)**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df3 = pd.DataFrame({'C': [11, 12, 13], 'D': [14, 15, 16]})\n",
    "df4 = pd.DataFrame({'E': [17, 18], 'F': [19, 20]})\n",
    "\n",
    "df_concat_horizontal = pd.concat([df1, df3], axis=1)\n",
    "print(\"\\nHorizontal Concatenation (Different Columns):\\n\", df_concat_horizontal)\n",
    "\n",
    "df_concat_horizontal_aligned = pd.concat([df1, df2], axis=1)\n",
    "print(\"\\nHorizontal Concatenation (Same Index):\\n\", df_concat_horizontal_aligned)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Horizontal Concatenation (Different Columns):\n",
    "    A   B   C   D\n",
    "0  1   4  11  14\n",
    "1  2   5  12  15\n",
    "2  3   6  13  16\n",
    "\n",
    "Horizontal Concatenation (Same Index):\n",
    "    A    B    A    B\n",
    "0  1.0  4.0  7.0  9.0\n",
    "1  2.0  5.0  8.0 10.0\n",
    "2  3.0  6.0  NaN  NaN\n",
    "```\n",
    "\n",
    "When concatenating horizontally with different indexes, pandas performs an outer join by default, filling missing values with `NaN`.\n",
    "\n",
    "**Example 4: Using `join='inner'` for Horizontal Concatenation**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df5 = pd.DataFrame({'G': [21, 22, 23], 'H': [24, 25, 26]}, index=[0, 1, 2])\n",
    "df6 = pd.DataFrame({'I': [27, 28], 'J': [29, 30]}, index=[1, 2])\n",
    "\n",
    "df_concat_inner_horizontal = pd.concat([df5, df6], axis=1, join='inner')\n",
    "print(\"\\nHorizontal Concatenation with Inner Join:\\n\", df_concat_inner_horizontal)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Horizontal Concatenation with Inner Join:\n",
    "    G   H   I   J\n",
    "1  22  25  27  29\n",
    "2  23  26  28  30\n",
    "```\n",
    "\n",
    "Only the rows with indexes present in both `df5` and `df6` are included.\n",
    "\n",
    "**Example 5: Adding a Hierarchical Index with `keys`**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df7 = pd.DataFrame({'K': [31, 32], 'L': [33, 34]})\n",
    "df8 = pd.DataFrame({'K': [35, 36, 37], 'L': [38, 39, 40]})\n",
    "\n",
    "df_concat_keys = pd.concat([df7, df8], keys=['first', 'second'])\n",
    "print(\"\\nConcatenation with Keys (Hierarchical Index):\\n\", df_concat_keys)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Concatenation with Keys (Hierarchical Index):\n",
    "          K   L\n",
    "first  0  31  33\n",
    "       1  32  34\n",
    "second 0  35  38\n",
    "       1  36  39\n",
    "       2  37  40\n",
    "```\n",
    "\n",
    "The `keys` argument created a MultiIndex, allowing you to easily identify the origin of each part of the concatenated DataFrame.\n",
    "\n",
    "**Example 6: Naming the Levels of the Hierarchical Index with `names`**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df9 = pd.DataFrame({'M': [41, 42], 'N': [43, 44]})\n",
    "df10 = pd.DataFrame({'M': [45, 46], 'N': [47, 48]})\n",
    "\n",
    "df_concat_named_index = pd.concat([df9, df10], keys=['group1', 'group2'], names=['Group', 'Row'])\n",
    "print(\"\\nConcatenation with Named Hierarchical Index:\\n\", df_concat_named_index)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Concatenation with Named Hierarchical Index:\n",
    "              M   N\n",
    "Group  Row\n",
    "group1 0   41  43\n",
    "       1   42  44\n",
    "group2 0   45  47\n",
    "       1   46  48\n",
    "```\n",
    "\n",
    "Here, we provided names for the levels of our MultiIndex.\n",
    "\n",
    "**Example 7: Concatenating Series**\n",
    "\n",
    "`pd.concat()` also works seamlessly with pandas Series objects.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s1 = pd.Series([51, 52], name='col_s')\n",
    "s2 = pd.Series([53, 54], name='col_t', index=[1, 2])\n",
    "\n",
    "concat_series_vertical = pd.concat([s1, s2])\n",
    "print(\"\\nVertical Concatenation of Series:\\n\", concat_series_vertical)\n",
    "\n",
    "concat_series_horizontal = pd.concat([s1, s2], axis=1)\n",
    "print(\"\\nHorizontal Concatenation of Series:\\n\", concat_series_horizontal)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Vertical Concatenation of Series:\n",
    " 0    51\n",
    "1    52\n",
    "1    53\n",
    "2    54\n",
    "Name: col_s, dtype: int64\n",
    "\n",
    "Horizontal Concatenation of Series:\n",
    "    col_s  col_t\n",
    "0   51.0    NaN\n",
    "1   52.0   53.0\n",
    "2    NaN   54.0\n",
    "```\n",
    "\n",
    "When concatenating Series horizontally, they become columns in a DataFrame, and alignment is based on their indexes.\n",
    "\n",
    "These examples cover the most common use cases of `pd.concat()`. Remember to choose the appropriate parameters based on how you want to combine your pandas objects and handle their indexes. Let me know if you have any specific concatenation scenarios you'd like to explore!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the `df.sort_values()` method in pandas, which is essential for arranging the rows of your DataFrame based on the values in one or more columns.\n",
    "\n",
    "**Syntax:**\n",
    "\n",
    "```python\n",
    "df.sort_values(by, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False, key=None)\n",
    "```\n",
    "\n",
    "Here's a breakdown of the key parameters:\n",
    "\n",
    "- **`by`**: This is the most important parameter. It specifies the column(s) to use for sorting.\n",
    "  - You can provide a single column label (string) to sort by one column.\n",
    "  - You can provide a list of column labels (strings) to sort by multiple columns. In this case, the sorting will be done lexicographically, meaning the DataFrame will be sorted by the first column in the list, then within those groups, it will be sorted by the second column, and so on.\n",
    "- **`axis`**: Specifies the axis to be sorted.\n",
    "  - `0` or `'index'` (default): Sort rows based on column values.\n",
    "  - `1` or `'columns'`: Sort columns based on row values (less common).\n",
    "- **`ascending`**: Determines the sorting order.\n",
    "  - `True` (default): Sort in ascending order (e.g., A to Z, 1 to 9).\n",
    "  - `False`: Sort in descending order (e.g., Z to A, 9 to 1).\n",
    "  - You can provide a list of booleans if sorting by multiple columns to specify the sorting order for each column (e.g., `[True, False]` to sort the first column ascending and the second descending).\n",
    "- **`inplace`**: If `True`, the sorting will be performed directly on the DataFrame, modifying the original DataFrame. If `False` (default), the method will return a new sorted DataFrame, leaving the original unchanged.\n",
    "- **`kind`**: The sorting algorithm to use. Options include `'quicksort'` (default), `'mergesort'`, and `'heapsort'`. While the default is usually efficient, you might choose a different algorithm for specific performance characteristics or stability.\n",
    "- **`na_position`**: Specifies how to handle missing values (`NaN`).\n",
    "  - `'last'` (default): Put `NaN` values at the end.\n",
    "  - `'first'`: Put `NaN` values at the beginning.\n",
    "- **`ignore_index`**: If `True`, the resulting index will be labeled `0, 1, ..., n-1`.\n",
    "- **`key`**: Apply a function to the values _before_ sorting. This can be useful for custom sorting logic (e.g., sorting strings by their length). The function should be vectorized (operate on a Series).\n",
    "\n",
    "Now, let's illustrate these with some code examples:\n",
    "\n",
    "**Example 1: Sorting by a Single Column (Ascending Order)**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "        'Age': [25, 30, 22, 28],\n",
    "        'Score': [85, 92, 78, 88]}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "\n",
    "df_sorted_age = df.sort_values(by='Age')\n",
    "print(\"\\nSorted by Age (Ascending):\\n\", df_sorted_age)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original DataFrame:\n",
    "       Name  Age  Score\n",
    "0    Alice   25     85\n",
    "1      Bob   30     92\n",
    "2  Charlie   22     78\n",
    "3    David   28     88\n",
    "\n",
    "Sorted by Age (Ascending):\n",
    "       Name  Age  Score\n",
    "2  Charlie   22     78\n",
    "0    Alice   25     85\n",
    "3    David   28     88\n",
    "1      Bob   30     92\n",
    "```\n",
    "\n",
    "**Example 2: Sorting by a Single Column (Descending Order)**\n",
    "\n",
    "```python\n",
    "df_sorted_score_desc = df.sort_values(by='Score', ascending=False)\n",
    "print(\"\\nSorted by Score (Descending):\\n\", df_sorted_score_desc)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Sorted by Score (Descending):\n",
    "       Name  Age  Score\n",
    "1      Bob   30     92\n",
    "3    David   28     88\n",
    "0    Alice   25     85\n",
    "2  Charlie   22     78\n",
    "```\n",
    "\n",
    "**Example 3: Sorting by Multiple Columns**\n",
    "\n",
    "```python\n",
    "data_multi_sort = {'City': ['Dhaka', 'Chittagong', 'Dhaka', 'Chittagong', 'Dhaka'],\n",
    "                   'Population': [10, 5, 12, 6, 9],\n",
    "                   'Area': [300, 200, 350, 250, 280]}\n",
    "df_multi = pd.DataFrame(data_multi_sort)\n",
    "print(\"\\nOriginal Multi-Sort DataFrame:\\n\", df_multi)\n",
    "\n",
    "df_sorted_multi = df_multi.sort_values(by=['City', 'Population'])\n",
    "print(\"\\nSorted by City (Ascending) then Population (Ascending):\\n\", df_sorted_multi)\n",
    "\n",
    "df_sorted_multi_mixed = df_multi.sort_values(by=['City', 'Population'], ascending=[True, False])\n",
    "print(\"\\nSorted by City (Ascending) then Population (Descending):\\n\", df_sorted_multi_mixed)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original Multi-Sort DataFrame:\n",
    "         City  Population  Area\n",
    "0       Dhaka          10   300\n",
    "1  Chittagong           5   200\n",
    "2       Dhaka          12   350\n",
    "3  Chittagong           6   250\n",
    "4       Dhaka           9   280\n",
    "\n",
    "Sorted by City (Ascending) then Population (Ascending):\n",
    "         City  Population  Area\n",
    "1  Chittagong           5   200\n",
    "3  Chittagong           6   250\n",
    "4       Dhaka           9   280\n",
    "0       Dhaka          10   300\n",
    "2       Dhaka          12   350\n",
    "\n",
    "Sorted by City (Ascending) then Population (Descending):\n",
    "         City  Population  Area\n",
    "3  Chittagong           6   250\n",
    "1  Chittagong           5   200\n",
    "2       Dhaka          12   350\n",
    "0       Dhaka          10   300\n",
    "4       Dhaka           9   280\n",
    "```\n",
    "\n",
    "**Example 4: Sorting with `inplace=True`**\n",
    "\n",
    "```python\n",
    "df_to_sort_inplace = df.copy()\n",
    "print(\"\\nDataFrame before inplace sort:\\n\", df_to_sort_inplace)\n",
    "\n",
    "df_to_sort_inplace.sort_values(by='Age', inplace=True)\n",
    "print(\"\\nDataFrame after inplace sort:\\n\", df_to_sort_inplace)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "DataFrame before inplace sort:\n",
    "       Name  Age  Score\n",
    "0    Alice   25     85\n",
    "1      Bob   30     92\n",
    "2  Charlie   22     78\n",
    "3    David   28     88\n",
    "\n",
    "DataFrame after inplace sort:\n",
    "       Name  Age  Score\n",
    "2  Charlie   22     78\n",
    "0    Alice   25     85\n",
    "3    David   28     88\n",
    "1      Bob   30     92\n",
    "```\n",
    "\n",
    "The original `df_to_sort_inplace` DataFrame is now modified.\n",
    "\n",
    "**Example 5: Handling Missing Values (`na_position`)**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "data_na = {'Value': [10, np.nan, 5, 8, np.nan]}\n",
    "df_na = pd.DataFrame(data_na)\n",
    "print(\"\\nDataFrame with NaN values:\\n\", df_na)\n",
    "\n",
    "df_na_last = df_na.sort_values(by='Value', na_position='last')\n",
    "print(\"\\nNaN at the end (default):\\n\", df_na_last)\n",
    "\n",
    "df_na_first = df_na.sort_values(by='Value', na_position='first')\n",
    "print(\"\\nNaN at the beginning:\\n\", df_na_first)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "DataFrame with NaN values:\n",
    "    Value\n",
    "0   10.0\n",
    "1    NaN\n",
    "2    5.0\n",
    "3    8.0\n",
    "4    NaN\n",
    "\n",
    "NaN at the end (default):\n",
    "   Value\n",
    "2    5.0\n",
    "3    8.0\n",
    "0   10.0\n",
    "1    NaN\n",
    "4    NaN\n",
    "\n",
    "NaN at the beginning:\n",
    "   Value\n",
    "1    NaN\n",
    "4    NaN\n",
    "2    5.0\n",
    "3    8.0\n",
    "0   10.0\n",
    "```\n",
    "\n",
    "**Example 6: Sorting by Index**\n",
    "\n",
    "While `sort_values` sorts by column values, you can sort by the index using `df.sort_index()`.\n",
    "\n",
    "```python\n",
    "df_indexed = df.set_index('Name')\n",
    "print(\"\\nDataFrame with Name as Index:\\n\", df_indexed)\n",
    "\n",
    "df_sorted_index = df_indexed.sort_index()\n",
    "print(\"\\nSorted by Index (Ascending):\\n\", df_sorted_index)\n",
    "\n",
    "df_sorted_index_desc = df_indexed.sort_index(ascending=False)\n",
    "print(\"\\nSorted by Index (Descending):\\n\", df_sorted_index_desc)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "DataFrame with Name as Index:\n",
    "          Age  Score\n",
    "Name\n",
    "Alice     25     85\n",
    "Bob       30     92\n",
    "Charlie   22     78\n",
    "David     28     88\n",
    "\n",
    "Sorted by Index (Ascending):\n",
    "          Age  Score\n",
    "Name\n",
    "Alice     25     85\n",
    "Bob       30     92\n",
    "Charlie   22     78\n",
    "David     28     88\n",
    "\n",
    "Sorted by Index (Descending):\n",
    "          Age  Score\n",
    "Name\n",
    "David     28     88\n",
    "Charlie   22     78\n",
    "Bob       30     92\n",
    "Alice     25     85\n",
    "```\n",
    "\n",
    "**Example 7: Using the `key` Parameter for Custom Sorting**\n",
    "\n",
    "Let's sort the 'Name' column by the length of the names.\n",
    "\n",
    "```python\n",
    "df_key_sort = df.copy()\n",
    "print(\"\\nOriginal DataFrame for key sort:\\n\", df_key_sort)\n",
    "\n",
    "df_sorted_by_name_length = df_key_sort.sort_values(by='Name', key=lambda x: x.str.len())\n",
    "print(\"\\nSorted by Name Length:\\n\", df_sorted_by_name_length)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original DataFrame for key sort:\n",
    "       Name  Age  Score\n",
    "0    Alice   25     85\n",
    "1      Bob   30     92\n",
    "2  Charlie   22     78\n",
    "3    David   28     88\n",
    "\n",
    "Sorted by Name Length:\n",
    "     Name  Age  Score\n",
    "1     Bob   30     92\n",
    "0   Alice   25     85\n",
    "3   David   28     88\n",
    "2 Charlie   22     78\n",
    "```\n",
    "\n",
    "The `key=lambda x: x.str.len()` applies the `len()` function to each string in the 'Name' column before sorting.\n",
    "\n",
    "`df.sort_values()` is a versatile tool for ordering your data in pandas. By understanding its parameters, you can achieve various sorting requirements for effective data analysis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
